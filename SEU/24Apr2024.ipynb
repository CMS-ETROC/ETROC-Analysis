{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# zlib License\n",
    "#\n",
    "# (C) 2024 Cristóvão Beirão da Cruz e Silva <cbeiraod@cern.ch>\n",
    "#\n",
    "# This software is provided 'as-is', without any express or implied\n",
    "# warranty.  In no event will the authors be held liable for any damages\n",
    "# arising from the use of this software.\n",
    "#\n",
    "# Permission is granted to anyone to use this software for any purpose,\n",
    "# including commercial applications, and to alter it and redistribute it\n",
    "# freely, subject to the following restrictions:\n",
    "#\n",
    "# 1. The origin of this software must not be misrepresented; you must not\n",
    "#    claim that you wrote the original software. If you use this software\n",
    "#    in a product, an acknowledgment in the product documentation would be\n",
    "#    appreciated but is not required.\n",
    "# 2. Altered source versions must be plainly marked as such, and must not be\n",
    "#    misrepresented as being the original software.\n",
    "# 3. This notice may not be removed or altered from any source distribution.\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sqlite3\n",
    "import pandas\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import mplhep\n",
    "from math import floor\n",
    "\n",
    "from SEUhelper import *\n",
    "\n",
    "import sys, os\n",
    "path2add = os.path.normpath(os.path.abspath(os.path.join(os.path.curdir, os.path.pardir, 'TestBeam')))\n",
    "if (not (path2add in sys.path)) :\n",
    "    sys.path.append(path2add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is for analysing the data from the 24th of April 2024, the SEU testing performed at UCLouvain w/ KULeuven\n",
    "\n",
    "# One board was used for this testing: ET2_Bare_5\n",
    "\n",
    "# start_time = datetime.datetime(2024, 4, 24, h, m, s)\n",
    "# end_time = datetime.datetime(2024, 4, 25, h, m, s)\n",
    "\n",
    "start_time = datetime.datetime(2024, 4, 23, 9, 0, 0)\n",
    "end_time = datetime.datetime(2024, 4, 23, 23, 0, 0)\n",
    "\n",
    "base_directory = Path(\"/media/daq/X9/SEUApril2024/\")\n",
    "power_file = Path(\"/home/daq/ETROC2/i2c_gui\")/\"PowerHistoryTest_v2.sqlite\" ## Change the name of the file\n",
    "config_directory = base_directory/\"ETROC-Data/ChipConfig\"\n",
    "\n",
    "output_dir = base_directory/\"AnalysisOutput\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "chip_names = [\n",
    "    \"ET2p01_Bare_5\",\n",
    "]\n",
    "\n",
    "power_connections = {\n",
    "    \"ET2.01 Bare Board 5\": {\n",
    "        \"Analog\": \"Analog\",\n",
    "        \"Digital\": \"Digital\",\n",
    "    },\n",
    "}\n",
    "\n",
    "run_info = [\n",
    "    {\n",
    "        \"name\": \"Run_Apr23_Prep_4\", ## This should be the same as directory name\n",
    "        \"extra_begin\": datetime.datetime(2024, 4, 23, 18, 0, 0),  # Used if we want to add an additional time for the per run plotting\n",
    "        \"start\": datetime.datetime(2024, 4, 23, 18, 4, 35),\n",
    "        \"stop\": datetime.datetime(2024, 4, 23, 18, 7, 00),\n",
    "        \"boards\": [\"ET2.01 Bare Board 5\"],\n",
    "        \"board_channels\": [0],\n",
    "        \"pre_config_times\": [datetime.datetime(2024, 4, 23, 18, 4, 35)],\n",
    "        \"post_config_times\": [datetime.datetime(2024, 4, 23, 18, 7, 00)],\n",
    "        \"config_before\": True,\n",
    "        \"fluence\": 1.13E+10,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Run_Apr23_Prep_5\", ## This should be the same as directory name\n",
    "        \"extra_begin\": datetime.datetime(2024, 4, 23, 18, 9, 14),  # Used if we want to add an additional time for the per run plotting\n",
    "        \"start\": datetime.datetime(2024, 4, 23, 18, 9, 14),\n",
    "        \"stop\": datetime.datetime(2024, 4, 23, 18, 25, 54),\n",
    "        \"boards\": [\"ET2.01 Bare Board 5\"],\n",
    "        \"board_channels\": [0],\n",
    "        \"pre_config_times\": [datetime.datetime(2024, 4, 23, 18, 9, 14)],\n",
    "        \"post_config_times\": [datetime.datetime(2024, 4, 23, 18, 25, 54)],\n",
    "        \"config_before\": True,\n",
    "        \"fluence\": 1.13E+10,\n",
    "    },\n",
    "]\n",
    "\n",
    "test_run_info = [\n",
    "    {\n",
    "        \"name\": \"Run_Apr23_Prep_4\",\n",
    "        \"start\": datetime.datetime(2024, 4, 23, 18, 4, 35) - datetime.timedelta(hours=6),\n",
    "        \"boards\": [\"ET2.01 Bare Board 5\"],\n",
    "        \"board_channels\": [0],\n",
    "        \"pre_config_times\": [None],\n",
    "        \"post_config_times\": [None],\n",
    "        \"config_before\": True,\n",
    "        \"fluence\": 0,\n",
    "    },\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Power Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_directory = output_dir/\"PowerPlots\"\n",
    "power_directory.mkdir(exist_ok=True)\n",
    "\n",
    "with sqlite3.connect(power_file) as sqlite3_connection:\n",
    "    data_df = pandas.read_sql('SELECT * FROM power_v2', sqlite3_connection, index_col=None)\n",
    "    data_df['Time'] = pandas.to_datetime(data_df['timestamp'], format='mixed')\n",
    "\n",
    "    # Remove data that is outside the range of the campaign\n",
    "    data_df = data_df.loc[data_df['Time'] >= start_time]\n",
    "    data_df = data_df.loc[data_df['Time'] <= end_time].copy()\n",
    "\n",
    "    data_df['V'] = data_df['V'].astype(float)\n",
    "    data_df['I'] = data_df['I'].astype(float)\n",
    "\n",
    "    print(\"Timestamps in power database file cover range:\")\n",
    "    print(\"Min:\", data_df['Time'].min())\n",
    "    print(\"Max\", data_df['Time'].max())\n",
    "\n",
    "    #print(data_df)\n",
    "\n",
    "    vref_df = data_df.loc[data_df['Channel'] == 'VRef']\n",
    "    wsana_df = data_df.loc[data_df['Channel'] == 'WSAnalog']\n",
    "    wsdig_df = data_df.loc[data_df['Channel'] == 'WSDigital']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VRef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot VRef over time so we can find the range of times where we can be confident the data is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotVRefPower(vref_df, 'SEU - VRef over Time', power_directory, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find time when the SEE happened on the power supply\n",
    "ps_see_time = vref_df.loc[vref_df[\"V\"] > 0.5][\"Time\"].max()\n",
    "\n",
    "print(f'The SEE hapened on the power supply at {ps_see_time}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ET2 Bare 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = \"ET2.01 Bare Board 5\"\n",
    "plotBoardPower(board, power_connections[board], data_df, f'SEU - {board} Power over Time', power_directory, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waveform Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotWSPower(wsana_df, 'SEU - Waveform Sampler Analog Power over Time', power_directory, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotWSPower(wsdig_df, 'SEU - Waveform Sampler Digital Power over Time', power_directory, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per Run Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_power_dir = power_directory/\"PerRun\"\n",
    "run_power_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for run_idx_to_plot in range(len(run_info)):\n",
    "    if run_idx_to_plot == 0:\n",
    "        makePerRunPlots(\n",
    "            data_df,\n",
    "            run_info[run_idx_to_plot],\n",
    "            run_power_dir,\n",
    "            power_connections,\n",
    "            extra_run_info = None,\n",
    "            test_run_info = test_run_info,\n",
    "        )\n",
    "    else:\n",
    "        makePerRunPlots(\n",
    "            data_df,\n",
    "            run_info[run_idx_to_plot],\n",
    "            run_power_dir,\n",
    "            power_connections,\n",
    "            previous_run_info = run_info[run_idx_to_plot - 1],\n",
    "            extra_run_info = None,\n",
    "            test_run_info = test_run_info,\n",
    "        )\n",
    "\n",
    "# for this_run_info in extra_run_info:\n",
    "#     makePerRunPlots(\n",
    "#         data_df,\n",
    "#         this_run_info,\n",
    "#         run_power_dir,\n",
    "#         power_connections,\n",
    "#         all_run_info = run_info,\n",
    "#         extra_run_info = extra_run_info,\n",
    "#         test_run_info = test_run_info,\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_history_file = base_directory/\"ETROC-History\"/\"BaselineHistory.sqlite\"\n",
    "baseline_directory = output_dir/\"Baselines\"\n",
    "baseline_directory.mkdir(exist_ok=True)\n",
    "\n",
    "col_list = [8, 2, 8, 2]\n",
    "row_list = [0, 0, 2, 2]\n",
    "scan_list = list(zip(row_list, col_list))\n",
    "chip_df = {}\n",
    "\n",
    "times_to_plot = {\n",
    "    #\"PS2 Failed, followed by power cycle\": ps_see_time,\n",
    "}\n",
    "\n",
    "with sqlite3.connect(baseline_history_file) as sqlite3_connection:\n",
    "    baseline_df = pandas.read_sql('SELECT * FROM baselines', sqlite3_connection, index_col=None)\n",
    "    baseline_df['Time'] = pandas.to_datetime(baseline_df['timestamp'], format='mixed')\n",
    "\n",
    "    # Remove data that is outside the range of the campaign\n",
    "    baseline_df = baseline_df.loc[baseline_df['Time'] >= (start_time - datetime.timedelta(minutes=12))]\n",
    "    baseline_df = baseline_df.loc[baseline_df['Time'] <= end_time].copy()\n",
    "\n",
    "    for chip_name in chip_names:\n",
    "        chip_df[chip_name] = baseline_df.loc[baseline_df[\"chip_name\"] == chip_name].copy()\n",
    "\n",
    "        plotPixelsOverTime(chip_df[chip_name], 'baseline', \"Baselines of {}\".format(chip_name.replace(\"_\", \" \")), scan_list, baseline_directory/f\"{chip_name}_Baseline.pdf\", times_to_plot = times_to_plot)\n",
    "        plotPixelsOverTime(chip_df[chip_name], 'noise_width', \"Noise Widths of {}\".format(chip_name.replace(\"_\", \" \")), scan_list, baseline_directory/f\"{chip_name}_NoiseWidth.pdf\", times_to_plot = times_to_plot)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I2C Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "import copy\n",
    "import tempfile\n",
    "import shutil\n",
    "\n",
    "from math import ceil\n",
    "\n",
    "config_compare_dir = output_dir/\"I2CConfiguration\"\n",
    "config_compare_dir.mkdir(exist_ok=True)\n",
    "\n",
    "accumulated_status_map = {}\n",
    "accumulated_config_map = {}\n",
    "accumulated_bitmap = {}\n",
    "\n",
    "base_bitmap = {\n",
    "}\n",
    "for idx in range(32):\n",
    "    base_bitmap[f'PeriCfg{idx}']  = [0 for _ in range(8)]\n",
    "for idx in range(16):\n",
    "    base_bitmap[f'PeriStat{idx}'] = [0 for _ in range(8)]\n",
    "for idx in range(32):\n",
    "    base_bitmap[f'PixCfg{idx}']   = [0 for _ in range(8)]\n",
    "for idx in range(8):\n",
    "    base_bitmap[f'PixStat{idx}']  = [0 for _ in range(8)]\n",
    "\n",
    "extra_bitmap = {}\n",
    "\n",
    "counter = 0\n",
    "for this_run_idx in range(len(run_info)):\n",
    "    counter += 1\n",
    "    #if counter == 2:\n",
    "    #    break\n",
    "    #if counter < 4:\n",
    "    #    continue\n",
    "    this_run_info = run_info[this_run_idx]\n",
    "    this_run_name = this_run_info[\"name\"]\n",
    "\n",
    "    this_run_dir = config_compare_dir/this_run_name\n",
    "    this_run_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    for board_idx in range(len(this_run_info[\"boards\"])):\n",
    "        board_name = this_run_info[\"boards\"][board_idx]\n",
    "\n",
    "        if board_name not in accumulated_bitmap:\n",
    "            accumulated_bitmap[board_name] = copy.deepcopy(base_bitmap)\n",
    "\n",
    "        pre_config_time  = this_run_info[ \"pre_config_times\"][board_idx]\n",
    "        post_config_time = this_run_info[\"post_config_times\"][board_idx]\n",
    "\n",
    "        if post_config_time is None:\n",
    "            print(f'No post config time for board {board_name} for run {this_run_name}')\n",
    "            continue\n",
    "\n",
    "        if pre_config_time is None:\n",
    "            if \"config_before\" in this_run_info and not this_run_info[\"config_before\"]:\n",
    "                for offset in range(this_run_idx):\n",
    "                    previous_run_info = run_info[this_run_idx - 1 - offset]\n",
    "\n",
    "                    previous_board_idx = None\n",
    "                    for idx in range(len(previous_run_info[\"boards\"])):\n",
    "                        if board_name == previous_run_info[\"boards\"][idx]:\n",
    "                            previous_board_idx = idx\n",
    "                            break\n",
    "\n",
    "                    if previous_board_idx is None:\n",
    "                        continue  #  TODO: Perhaps this should be a break\n",
    "\n",
    "                    pre_config_time = previous_run_info[\"post_config_times\"][previous_board_idx]\n",
    "\n",
    "                    if pre_config_time is not None:\n",
    "                        break\n",
    "\n",
    "                    if \"config_before\" in previous_run_info and not previous_run_info[\"config_before\"]:\n",
    "                        continue\n",
    "                    break\n",
    "\n",
    "            if pre_config_time is None:\n",
    "                print(f'No pre config time for board {board_name} for run {this_run_name}')\n",
    "                continue\n",
    "\n",
    "        pre_time_tag  =  pre_config_time.isoformat().replace(\":\", \"-\")\n",
    "        post_time_tag = post_config_time.isoformat().replace(\":\", \"-\")\n",
    "\n",
    "        pre_time_file  = list(config_directory.glob(f'{pre_time_tag}*'))\n",
    "        post_time_file = list(config_directory.glob(f'{post_time_tag}*'))\n",
    "        if len(pre_time_file) == 0:\n",
    "            print(f\"Couldn't find the pre-time configuration file for board {board_name} for run {this_run_name}\")\n",
    "            continue\n",
    "        if len(post_time_file) == 0:\n",
    "            print(f\"Couldn't find the post-time configuration file for board {board_name} for run {this_run_name}\")\n",
    "            continue\n",
    "        if len(pre_time_file) > 1:\n",
    "            print(f\"Found too many pre-time configuration files for board {board_name} for run {this_run_name}\")\n",
    "            continue\n",
    "        if len(post_time_file) > 1:\n",
    "            print(f\"Found too many post-time configuration files for board {board_name} for run {this_run_name}\")\n",
    "            continue\n",
    "        pre_time_file  =  pre_time_file[0]\n",
    "        post_time_file = post_time_file[0]\n",
    "\n",
    "        print(f'{this_run_name} - {board_name}')\n",
    "\n",
    "        changed_registers = diff_chip_configs(pre_time_file, post_time_file)\n",
    "        print(changed_registers)\n",
    "        save_changed_config(changed_registers, this_run_dir, f\"changedRegisters_{board_name.replace(' ', '_')}\")\n",
    "\n",
    "        status_map, config_map = get_pixel_bitflip_map(changed_registers)\n",
    "        plot_map(status_map, f\"Pixel Status Bit Flips on {board_name} during Run {this_run_name}\", 'Bit Flips', this_run_dir/f\"{board_name}_Status.pdf\")\n",
    "        plot_map(config_map, f\"Pixel Config Bit Flips on {board_name} during Run {this_run_name}\", 'Bit Flips', this_run_dir/f\"{board_name}_Config.pdf\")\n",
    "\n",
    "        this_bitmap = copy.deepcopy(base_bitmap)\n",
    "        other_bitmap = {}\n",
    "        fill_bitmap(changed_registers, this_bitmap, other_bitmap)\n",
    "        # save_bitmap_table(this_bitmap, this_run_dir, f\"{board_name}\") ## This function might be an issue because of latex\n",
    "\n",
    "        for key in other_bitmap:\n",
    "            if key not in extra_bitmap:\n",
    "                extra_bitmap[key] = [0 for _ in range(8)]\n",
    "            for idx in range(8):\n",
    "                extra_bitmap[key][idx] += other_bitmap[key][idx]\n",
    "        for key in this_bitmap:\n",
    "            for idx in range(8):\n",
    "                accumulated_bitmap[board_name][key][idx] += this_bitmap[key][idx]\n",
    "\n",
    "        if board_name not in accumulated_status_map:\n",
    "            accumulated_status_map[board_name] = status_map\n",
    "        else:\n",
    "            for row in range(16):\n",
    "                for col in range(16):\n",
    "                    accumulated_status_map[board_name][row][col] += status_map[row][col]\n",
    "        if board_name not in accumulated_config_map:\n",
    "            accumulated_config_map[board_name] = config_map\n",
    "        else:\n",
    "            for row in range(16):\n",
    "                for col in range(16):\n",
    "                    accumulated_config_map[board_name][row][col] += config_map[row][col]\n",
    "\n",
    "#print(extra_bitmap)\n",
    "#print(accumulated_bitmap)\n",
    "\n",
    "if len(extra_bitmap) != 0:\n",
    "    with open(config_compare_dir/(\"extra_registers_bitflips.pickle\"), \"wb\") as file:\n",
    "        pickle.dump(extra_bitmap, file)\n",
    "\n",
    "    with open(config_compare_dir/(\"extra_registers_bitflips.txt\"), \"w\") as file:\n",
    "        file.write(\"The bits in unnamed registers saw the following amount of bit flips:\")\n",
    "        for register in extra_bitmap:\n",
    "            file.write(f\" - {register}: {extra_bitmap[register]}\")\n",
    "\n",
    "# This function might be an issue because of latex\n",
    "total_bitmap = copy.deepcopy(base_bitmap)\n",
    "for board_name in accumulated_bitmap:\n",
    "    save_bitmap_table(accumulated_bitmap[board_name], config_compare_dir, f\"{board_name}\") ## This function might be an issue because of latex\n",
    "    for key in accumulated_bitmap[board_name]:\n",
    "        for idx in range(8):\n",
    "            total_bitmap[key][idx] += accumulated_bitmap[board_name][key][idx]\n",
    "save_bitmap_table(total_bitmap, config_compare_dir, \"Total\") ## This function might be an issue because of latex\n",
    "\n",
    "for board_name in accumulated_status_map:\n",
    "    plot_map(accumulated_status_map[board_name], f\"Pixel Status Bit Flips on {board_name} over all Runs\", 'Bit Flips', config_compare_dir/f\"{board_name}_Status.pdf\")\n",
    "for board_name in accumulated_config_map:\n",
    "    plot_map(accumulated_config_map[board_name], f\"Pixel Config Bit Flips on {board_name} over all Runs\", 'Bit Flips', config_compare_dir/f\"{board_name}_Config.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beamtest_analysis_helper import DecodeBinary\n",
    "from beamtest_analysis_helper import return_hist, return_event_hist, plot_1d_TDC_histograms\n",
    "from natsort import natsorted\n",
    "\n",
    "translated_dir = output_dir/\"Translated\"\n",
    "translated_dir.mkdir(exist_ok=True)\n",
    "plot_dir = output_dir/\"TDCPlots\"\n",
    "plot_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate RAW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translateRun(this_run_info: dict, save_dir: Path):\n",
    "    this_run_name = this_run_info[\"name\"]\n",
    "    this_run_dir: Path = base_directory/\"ETROC-Data\"/this_run_name\n",
    "\n",
    "    if not this_run_dir.is_dir():\n",
    "        raise RuntimeError(f\"The directory for run {this_run_name} does not exist. Expected: {this_run_dir}\")\n",
    "\n",
    "    print(f\"Translating data for run {this_run_name}\")\n",
    "    this_run_files = natsorted(list(this_run_dir.glob(\"loop*/TDC*\")))\n",
    "\n",
    "    decoder = DecodeBinary(\n",
    "        firmware_key=0b0001,\n",
    "        board_id = [0x17f0f, 0x17f0f, 0x17f0f, 0x17f0f],\n",
    "        file_list = this_run_files,\n",
    "        save_nem = None,\n",
    "        skip_filler = True,\n",
    "    )\n",
    "    dataframe, event_dataframe = decoder.decode_files()\n",
    "\n",
    "    print(f\"Saving data for run {this_run_name}\")\n",
    "\n",
    "    #dataframe.to_feather(save_dir/f\"{this_run_name}.feather\")\n",
    "    with sqlite3.connect(save_dir/f\"{this_run_name}.sqlite\") as sqlite3_connection:\n",
    "        dataframe = dataframe.drop(columns=['bcid', 'l1a_counter'])\n",
    "        dataframe.to_sql('hit_data', sqlite3_connection, if_exists='replace', index=False)\n",
    "        event_dataframe.to_sql('event_data', sqlite3_connection, if_exists='replace', index=False)\n",
    "\n",
    "counter = 0\n",
    "for this_run_info in run_info:\n",
    "    translateRun(this_run_info, translated_dir)\n",
    "    counter += 1\n",
    "    #if counter == 2:\n",
    "    #    break\n",
    "\n",
    "# for this_run_info in extra_run_info:\n",
    "#     translateRun(this_run_info, translated_dir)\n",
    "\n",
    "# for this_run_info in test_run_info:\n",
    "#     translateRun(this_run_info, translated_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make per run TDC Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotRunSummary(this_run_info: dict, translated_dir: Path, save_dir: Path, ps_see_time: datetime.datetime | None = None, print_info: bool = False):\n",
    "    this_run_name = this_run_info[\"name\"]\n",
    "    this_run_dir: Path = base_directory/\"ETROC-Data\"/this_run_name\n",
    "    this_run_plot_dir = save_dir/this_run_name\n",
    "    this_run_plot_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    if not this_run_dir.is_dir():\n",
    "        raise RuntimeError(f\"The directory for run {this_run_name} does not exist. Expected: {this_run_dir}\")\n",
    "\n",
    "    #dataframe = pandas.read_feather(translated_dir/f\"{this_run_name}.feather\")\n",
    "    with sqlite3.connect(translated_dir/f\"{this_run_name}.sqlite\") as sqlite3_connection:\n",
    "        dataframe = pandas.read_sql('SELECT * FROM hit_data', sqlite3_connection, index_col=None)\n",
    "        event_dataframe = pandas.read_sql('SELECT * FROM event_data', sqlite3_connection, index_col=None)\n",
    "\n",
    "    if len(dataframe) == 0:\n",
    "        print('dataframe is empty!')\n",
    "        return\n",
    "\n",
    "    filtered_df = dataframe.loc[(dataframe[\"tot\"] - dataframe[\"tot\"].mean()).abs() > 2*dataframe[\"tot\"].std()].copy()\n",
    "    off_peak_hits = len(filtered_df)\n",
    "\n",
    "    if print_info:\n",
    "        print(f\"All hits on all boards: {len(dataframe)}\")\n",
    "        print(f\"Hits not in main TOT peak: {off_peak_hits}\")\n",
    "\n",
    "    board_labels = this_run_info[\"boards\"]\n",
    "    board_names = [i.replace(\" \", \"_\") for i in board_labels]\n",
    "    board_channels = this_run_info[\"board_channels\"]\n",
    "    this_run_hists = return_hist(dataframe, board_names, board_channels, hist_bins=[100, 128, 128])\n",
    "    this_event_hist = return_event_hist(event_dataframe)\n",
    "    filtered_run_hists = return_hist(filtered_df, board_names, board_channels, hist_bins=[100, 128, 128])\n",
    "\n",
    "    for board_idx in range(len(board_labels)):\n",
    "        plot_1d_TDC_histograms(this_run_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=\"inclusive\", fig_tag=\", inclusive\", slide_friendly=False, event_hist=this_event_hist)\n",
    "        plot_1d_TDC_histograms(this_run_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=\"inclusive_logy\", fig_tag=\", inclusive\", slide_friendly=False, do_logy = True, event_hist=this_event_hist)\n",
    "        plot_1d_TDC_histograms(this_run_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=\"inclusive\", fig_tag=\", inclusive\", slide_friendly=True, event_hist=this_event_hist)\n",
    "        plot_1d_TDC_histograms(this_run_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=\"inclusive_logy\", fig_tag=\", inclusive\", slide_friendly=True, do_logy = True, event_hist=this_event_hist)\n",
    "\n",
    "        if off_peak_hits > 0:\n",
    "            plot_1d_TDC_histograms(filtered_run_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=\"filtered_tot_peak\", fig_tag=\", filtered TOT peak\", slide_friendly=False)\n",
    "            plot_1d_TDC_histograms(filtered_run_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=\"filtered_tot_peak_logy\", fig_tag=\", filtered TOT peak\", slide_friendly=False, do_logy = True)\n",
    "            plot_1d_TDC_histograms(filtered_run_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=\"filtered_tot_peak\", fig_tag=\", filtered TOT peak\", slide_friendly=True)\n",
    "            plot_1d_TDC_histograms(filtered_run_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=\"filtered_tot_peak_logy\", fig_tag=\", filtered TOT peak\", slide_friendly=True, do_logy = True)\n",
    "\n",
    "    #counts = event_dataframe['hamming_count'].unique()\n",
    "    #if len(counts) > 1:\n",
    "    #    for hamming_count in counts:\n",
    "    #        filtered_event_df = event_dataframe.loc[event_dataframe['hamming_count'] == hamming_count]\n",
    "\n",
    "    #        print(filtered_event_df)\n",
    "    #        filtered_df = dataframe[dataframe['evt'].isin(filtered_event_df['evt'])].copy()\n",
    "    #        print(filtered_df)\n",
    "\n",
    "    values = dataframe['ea'].unique()\n",
    "    if len(values) > 1:\n",
    "        for hamming_code in values:\n",
    "            filtered_df    = dataframe.loc[dataframe['ea'] == hamming_code].copy()\n",
    "            filtered_hists = return_hist(filtered_df, board_names, board_channels, hist_bins=[100, 128, 128])\n",
    "\n",
    "            for board_idx in range(len(board_labels)):\n",
    "                plot_1d_TDC_histograms(filtered_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=f\"hamming_code_{hamming_code}\", fig_tag=f\", Hamming Code {hamming_code:#04b}\", slide_friendly=False)\n",
    "                plot_1d_TDC_histograms(filtered_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=f\"hamming_code_{hamming_code}_logy\", fig_tag=f\", Hamming Code {hamming_code:#04b}\", slide_friendly=False, do_logy = True)\n",
    "                plot_1d_TDC_histograms(filtered_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=f\"hamming_code_{hamming_code}\", fig_tag=f\", Hamming Code {hamming_code:#04b}\", slide_friendly=True)\n",
    "                plot_1d_TDC_histograms(filtered_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=f\"hamming_code_{hamming_code}_logy\", fig_tag=f\", Hamming Code {hamming_code:#04b}\", slide_friendly=True, do_logy = True)\n",
    "\n",
    "    run_start = this_run_info['start']\n",
    "    run_stop  = this_run_info['stop']\n",
    "\n",
    "    ##   It seems that after the PS SEE, data was no longer being recorded, so it doesn't\n",
    "    ## make sense to filter the events based on the fraction of total events between good\n",
    "    ## events (before PS SEE) and bad events (after PS SEE)\n",
    "    #if ps_see_time > run_start and ps_see_time < run_stop:\n",
    "    #    run_duration = (run_stop - run_start)\n",
    "    #    percentage_good = (ps_see_time - run_start)/run_duration\n",
    "\n",
    "    #    total_rows = len(dataframe)\n",
    "    #    good_rows = floor(total_rows * percentage_good * 0.95)  # Add a 5% safety factor\n",
    "    #    bad_rows = floor(total_rows * (1 - percentage_good) * 0.95)\n",
    "\n",
    "    #    good_df = dataframe.iloc[:good_rows]\n",
    "    #    bad_df = dataframe.iloc[-bad_rows:]\n",
    "\n",
    "    #    good_run_hists = return_hist(good_df, board_names, board_channels, hist_bins=[100, 128, 128])\n",
    "    #    bad_run_hists  = return_hist(bad_df, board_names, board_channels, hist_bins=[100, 128, 128])\n",
    "\n",
    "    #    for board_idx in range(len(board_labels)):\n",
    "    #        #plot_1d_TDC_histograms(good_run_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=\"inclusive_good\", fig_tag=\" good, inclusive\", slide_friendly=False)\n",
    "    #        plot_1d_TDC_histograms(good_run_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=\"inclusive_good\", fig_tag=\" good, inclusive\", slide_friendly=True, event_hist=this_event_hist)\n",
    "    #        plot_1d_TDC_histograms(good_run_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=\"inclusive_logy_good\", fig_tag=\" good, inclusive\", slide_friendly=True, do_logy = True, event_hist=this_event_hist)\n",
    "\n",
    "    #        #plot_1d_TDC_histograms(bad_run_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=\"inclusive_bad\", fig_tag=\" bad, inclusive\", slide_friendly=False)\n",
    "    #        plot_1d_TDC_histograms(bad_run_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=\"inclusive_bad\", fig_tag=\" bad, inclusive\", slide_friendly=True, event_hist=this_event_hist)\n",
    "    #        plot_1d_TDC_histograms(bad_run_hists, board_names[board_idx], board_names[board_idx], board_labels[board_idx], this_run_plot_dir, save=True, tag=\"inclusive_logy_bad\", fig_tag=\" bad, inclusive\", slide_friendly=True, do_logy = True, event_hist=this_event_hist)\n",
    "\n",
    "counter = 0\n",
    "for this_run_info in run_info:\n",
    "    counter += 1\n",
    "    print(f\"\"\"Run {counter} {this_run_info[\"name\"]}\"\"\")\n",
    "    #if counter == 12:\n",
    "    #    break\n",
    "    #if counter < 11:\n",
    "    #    continue\n",
    "    plotRunSummary(this_run_info, translated_dir, plot_dir, None, True)\n",
    "\n",
    "# for this_run_info in extra_run_info:\n",
    "#     plotRunSummary(this_run_info, translated_dir, plot_dir, ps_see_time)\n",
    "\n",
    "# for this_run_info in test_run_info:\n",
    "#     plotRunSummary(this_run_info, translated_dir, plot_dir, ps_see_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Below codes for making slides based on latex, optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slide_dir = output_dir/\"SummarySlides\"\n",
    "slide_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_dir = slide_dir/\"Overall\"\n",
    "overall_dir.mkdir(exist_ok=True)\n",
    "makeOverallSummarySlides(\n",
    "    overall_dir,\n",
    "    start_time,\n",
    "    end_time,\n",
    "    chip_names,\n",
    "    run_info,\n",
    "    extra_run_info,\n",
    "    power_directory,\n",
    "    baseline_directory,\n",
    "    scan_list,\n",
    "    config_compare_dir,\n",
    "    plot_dir,\n",
    "    [ps_see_time],\n",
    "    slide_subtitle = r\"Jan 27, 2024\",\n",
    "                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per Run Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for this_run_info in run_info:\n",
    "    counter += 1\n",
    "    print(f\"Run {counter}\")\n",
    "    #if counter == 12:\n",
    "    #    break\n",
    "    #if counter < 11:\n",
    "    #    continue\n",
    "\n",
    "    this_run_dir = slide_dir/this_run_info[\"name\"]\n",
    "    this_run_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Add call to missing function to create latex slides and convert to pdf\n",
    "\n",
    "for this_run_info in extra_run_info:\n",
    "    this_run_dir = slide_dir/this_run_info[\"name\"]\n",
    "    this_run_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Add call to missing function to create latex slides and convert to pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
