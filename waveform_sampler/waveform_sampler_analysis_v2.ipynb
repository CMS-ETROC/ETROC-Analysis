{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3c44a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mplhep as hep\n",
    "hep.style.use('CMS')\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from pathlib import Path\n",
    "from natsort import natsorted\n",
    "from cycler import cycler\n",
    "color_cycle =  ['#3f90da','#ffa90e','#bd1f01','#94a4a2','#832db6','#a96b59','#e76300','#b9ac70','#717581','#92dadd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fad6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = natsorted(Path('./Run_PTNH1_230_OFF20_RFSel0_longrun_1').glob('*csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731fb3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(files[3])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(22, 11))\n",
    "ax.plot(df['Time [ns]'], df['Dout'], '.-', label='Original Dout')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ed8959",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(files[3])\n",
    "condition = (df['Time Index'] >= 616) & (df['Time Index'] <= 671)\n",
    "reduced_df = df.loc[~condition].reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29c8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = []\n",
    "full_array = []\n",
    "\n",
    "for i in range(1, 9):\n",
    "    input_array.append(reduced_df.loc[reduced_df['Channel'] == i][['Dout_S1', 'Dout_S2']].to_numpy())\n",
    "    full_array.append(df.loc[df['Channel'] == i][['Dout_S1', 'Dout_S2']].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e2ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = np.stack(full_array, axis=1)\n",
    "data = np.stack(input_array, axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d647f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# --- 1. Generate Synthetic Data (Replace with your data loading) ---\n",
    "# Assuming data has shape (number_of_time_steps, number_of_sources, 2)\n",
    "# where the last dimension contains [x1, x2] for each source.\n",
    "# Generate synthetic x1 and x2 data for each source, based on the true data\n",
    "# Add some noise and variations to simulate real-world data\n",
    "\n",
    "# Define some 'true' underlying parameters for the synthetic data generation\n",
    "# These are NOT the parameters we are trying to find with the optimization,\n",
    "# but rather parameters used to create the synthetic data itself.\n",
    "# The optimization will try to recover parameters close to these.\n",
    "\n",
    "num_sources = 8\n",
    "true_a = np.random.uniform(0.8, 1.2, num_sources)\n",
    "true_b = np.random.uniform(0.5, 1.5, num_sources)\n",
    "true_c = np.random.uniform(-0.5, 0.5, num_sources)\n",
    "\n",
    "# --- Replace the above synthetic data generation with loading your actual data ---\n",
    "# Example:\n",
    "# data = np.load('your_data.npy')\n",
    "# or if it's in a CSV:\n",
    "# import pandas as pd\n",
    "# df = pd.read_csv('your_data.csv')\n",
    "# # You'll need to reshape your data into the (num_time_steps, num_sources, 2) format\n",
    "\n",
    "\n",
    "# --- 2. Define the function to compute channel values ---\n",
    "def compute_channel_values(params, data_slice):\n",
    "    \"\"\"\n",
    "    Computes the values for all channels at a single time step.\n",
    "\n",
    "    Args:\n",
    "        params (np.ndarray): Flattened array of parameters [a1..a8, b1..b8, c1..c8].\n",
    "                             Shape (num_sources * 3,).\n",
    "        data_slice (np.ndarray): Data for a single time step. Shape (num_sources, 2).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Computed values for all channels at this time step. Shape (num_sources,).\n",
    "    \"\"\"\n",
    "    num_sources = data_slice.shape[0]\n",
    "    a_params = params[:num_sources]\n",
    "    b_params = params[num_sources:2*num_sources]\n",
    "    c_params = params[2*num_sources:]\n",
    "\n",
    "    x1 = data_slice[:, 0]\n",
    "    x2 = data_slice[:, 1]\n",
    "\n",
    "    # Compute V_i = a_i * (x1_i - b_i * x2_i - c_i)\n",
    "    computed_values = a_params * (x1 - b_params * x2 - c_params)\n",
    "\n",
    "    return computed_values\n",
    "\n",
    "# --- 3. Define the objective function to minimize ---\n",
    "def objective_function(params, data):\n",
    "    \"\"\"\n",
    "    Computes the total 'disagreement' across all channels over all time steps.\n",
    "    We minimize the sum of variances of computed values across channels at each time step.\n",
    "\n",
    "    Args:\n",
    "        params (np.ndarray): Flattened array of parameters [a1..a8, b1..b8, c1..c8].\n",
    "                             Shape (num_sources * 3,).\n",
    "        data (np.ndarray): The full dataset. Shape (num_time_steps, num_sources, 2).\n",
    "\n",
    "    Returns:\n",
    "        float: The total sum of variances across time steps.\n",
    "    \"\"\"\n",
    "    num_time_steps = data.shape[0]\n",
    "    total_variance = 0\n",
    "\n",
    "    for t in range(num_time_steps):\n",
    "        data_slice = data[t, :, :] # Data for all channels at time step t\n",
    "        computed_values_at_t = compute_channel_values(params, data_slice)\n",
    "\n",
    "        # Calculate the variance of the computed values across the 8 channels at time t\n",
    "        variance_at_t = np.var(computed_values_at_t)\n",
    "\n",
    "        total_variance += variance_at_t\n",
    "\n",
    "    return total_variance\n",
    "\n",
    "# --- 4. Set initial guesses for the parameters ---\n",
    "# It's important to provide reasonable initial guesses if possible.\n",
    "# If you have no idea, starting with 1s and 0s can be a starting point,\n",
    "# but better guesses can help the optimizer find the global minimum faster.\n",
    "# The parameters are ordered as [a1..a8, b1..b8, c1..c8]\n",
    "initial_a_guess = np.ones(num_sources)\n",
    "initial_b_guess = np.full_like(initial_a_guess, 0.05/5*8.5)\n",
    "initial_c_guess = np.zeros(num_sources)\n",
    "\n",
    "initial_params = np.concatenate((initial_a_guess, initial_b_guess, initial_c_guess))\n",
    "\n",
    "# --- 5. Run the optimization ---\n",
    "print(\"Starting optimization...\")\n",
    "\n",
    "# Using the 'Nelder-Mead' method, which is a robust direct search method\n",
    "# that doesn't require the gradient of the objective function.\n",
    "# For potentially better performance on larger datasets, other methods like 'L-BFGS-B'\n",
    "# which can use gradients (if provided, or estimated) might be considered,\n",
    "# but Nelder-Mead is a good starting point.\n",
    "result = minimize(objective_function, initial_params, args=(data,), method='Nelder-Mead', options={'disp': True, 'maxiter': 10000})\n",
    "\n",
    "print(\"\\nOptimization finished.\")\n",
    "\n",
    "# --- 6. Present the results ---\n",
    "optimized_params = result.x\n",
    "\n",
    "optimized_a = optimized_params[:num_sources]\n",
    "optimized_b = optimized_params[num_sources:2*num_sources]\n",
    "optimized_c = optimized_params[2*num_sources:]\n",
    "\n",
    "print(\"\\nOptimized Parameters:\")\n",
    "for i in range(num_sources):\n",
    "    print(f\"Channel {i+1}:\")\n",
    "    print(f\"  a = {optimized_a[i]:.4f}\")\n",
    "    print(f\"  b = {optimized_b[i]:.4f}\")\n",
    "    print(f\"  c = {optimized_c[i]:.4f}\")\n",
    "\n",
    "# You can also check the final value of the objective function\n",
    "print(f\"\\nFinal objective function value (sum of variances): {result.fun:.4f}\")\n",
    "print(f\"Optimization successful: {result.success}\")\n",
    "print(f\"Message: {result.message}\")\n",
    "\n",
    "# --- Optional: Verify with synthetic data ---\n",
    "# If you used the synthetic data generation, you can compare the optimized\n",
    "# parameters to the 'true' parameters used to generate the data.\n",
    "if 'true_a' in locals(): # Check if synthetic data variables exist\n",
    "    print(\"\\nComparison with Synthetic Data 'True' Parameters:\")\n",
    "    for i in range(num_sources):\n",
    "        print(f\"Channel {i+1}:\")\n",
    "        print(f\"  Optimized a = {optimized_a[i]:.4f}, True a = {true_a[i]:.4f}\")\n",
    "        print(f\"  Optimized b = {optimized_b[i]:.4f}, True b = {true_b[i]:.4f}\")\n",
    "        print(f\"  Optimized c = {optimized_c[i]:.4f}, True c = {true_c[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68827de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_array = np.array([])\n",
    "for i in range(128):\n",
    "    new_Dout = compute_channel_values(optimized_params, full_data[i, :, :])\n",
    "    tmp_array = np.append(tmp_array, new_Dout)\n",
    "df['new_Dout'] = tmp_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7454bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(22, 11))\n",
    "\n",
    "ax.plot(df['Time [ns]'], df['Dout'], '.-', label='Original Dout')\n",
    "ax.plot(df['Time [ns]'], df['new_Dout'], '.-', label='Recalculated Dout')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d79d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
