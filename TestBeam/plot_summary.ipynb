{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beamtest_analysis_helper import plot_resolution_table, plot_resolution_with_pulls\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_to_analyze = [1,2,3]\n",
    "offsets = [20, 20, 20, 20]\n",
    "chip_names = [\"BAR_4\", \"BAR_12\", \"BAR_13\", \"BB_1-3\"]\n",
    "high_voltages = [260, 120, 120, 210]\n",
    "\n",
    "\n",
    "chip_figtitles = [\n",
    "    f\"Barcelona 4 HV{high_voltages[0]}V OS:{offsets[0]}\",\n",
    "    f\"Barcelona 12 HV{high_voltages[1]}V OS:{offsets[1]}\",\n",
    "    f\"Barcelona 13 HV{high_voltages[2]}V OS:{offsets[2]}\",\n",
    "    f\"BB 1-3 HV{high_voltages[3]}V OS:{offsets[3]}\"\n",
    "]\n",
    "\n",
    "fig_tag=\"| Trigger TOA 250-500\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## final_df: time resolution dataframe\n",
    "final_df = pd.read_csv('file name: resolution_CERNAug2024_4boards_180V_cooling_23C_TOA250to500.csv')\n",
    "\n",
    "## nevt_track_df: number of events dataframe\n",
    "nevt_track_df = pd.read_csv('file name: CERNAug2024_4boards_180V_cooling_23C_nevt_per_track.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(final_df, nevt_track_df, on=['row0', 'col0', 'row1', 'col1', 'row2', 'col2', 'row3', 'col3'])\n",
    "merged_df.sort_values(by=['nevt'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define condition by track pixel combinations from merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = (merged_df['row0'] == merged_df['row1']+1) & \\\n",
    "            (merged_df['col0'] == merged_df['col1']+1) & \\\n",
    "            (merged_df['row1'] == merged_df['row2']+2) & \\\n",
    "            (merged_df['col1'] == merged_df['col2']) & \\\n",
    "            (merged_df['row1'] == merged_df['row3']+1) & \\\n",
    "            (merged_df['col1'] == merged_df['col3'])\n",
    "\n",
    "selected_data = merged_df[condition]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to check if tuple exists as a row\n",
    "# def is_tuple_in_df(t, df):\n",
    "#     return any(row.tolist() == list(t) for _, row in df.iterrows())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col_list, row_list = np.meshgrid(np.arange(16),np.arange(16))\n",
    "# scan_list = list(zip(row_list.flatten(),col_list.flatten()))\n",
    "\n",
    "# satisfy_df = merged_df[condition].sort_values(by=['nevt'], ascending=False).reset_index(drop=True)\n",
    "# non_satisfy_df = merged_df[~condition].sort_values(by=['nevt'], ascending=False).reset_index(drop=True)\n",
    "\n",
    "# # Filter elements not present\n",
    "# missing_pixels_board0 = [item for item in scan_list if not is_tuple_in_df(item, satisfy_df[[f'row{board_to_analyze[0]}', f'col{board_to_analyze[0]}']])]\n",
    "# missing_pixels_board1 = [item for item in scan_list if not is_tuple_in_df(item, satisfy_df[[f'row{board_to_analyze[1]}', f'col{board_to_analyze[1]}']])]\n",
    "# missing_pixels_board2 = [item for item in scan_list if not is_tuple_in_df(item, satisfy_df[[f'row{board_to_analyze[2]}', f'col{board_to_analyze[2]}']])]\n",
    "\n",
    "# missing_pix_dict = {\n",
    "#     board_to_analyze[0]: defaultdict(list),\n",
    "#     board_to_analyze[1]: defaultdict(list),\n",
    "#     board_to_analyze[2]: defaultdict(list),\n",
    "# }\n",
    "\n",
    "# for board_num, missing_pixels in zip(board_to_analyze, [missing_pixels_board0, missing_pixels_board1, missing_pixels_board2]):\n",
    "#     for missing_pixel in missing_pixels:\n",
    "#         board_key = f'board{board_num}'\n",
    "#         row_key = f'row{board_num}'\n",
    "#         col_key = f'col{board_num}'\n",
    "#         res_key = f'res{board_num}'\n",
    "#         err_key = f'err{board_num}'\n",
    "\n",
    "#         tmp_df = non_satisfy_df.loc[(non_satisfy_df[row_key] == missing_pixel[0]) & (non_satisfy_df[col_key] == missing_pixel[1])]\n",
    "#         if not tmp_df.empty:\n",
    "#             missing_pix_dict[board_num]['row'].append(tmp_df.iloc[0][row_key])\n",
    "#             missing_pix_dict[board_num]['col'].append(tmp_df.iloc[0][col_key])\n",
    "#             missing_pix_dict[board_num]['res'].append(tmp_df.iloc[0][res_key])\n",
    "#             missing_pix_dict[board_num]['err'].append(tmp_df.iloc[0][err_key])\n",
    "\n",
    "# id_want_drop = list(set([0,1,2,3]) - set(board_to_analyze))[0]\n",
    "# selected_data = merged_df[condition]\n",
    "# selected_data = selected_data.drop(columns=[f'row{id_want_drop}', f'col{id_want_drop}', 'nevt'])\n",
    "# selected_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "\n",
    "# current_dir = Path('./plot_scripts_for_approval')\n",
    "# output_mother_dir = current_dir / 'etroc_TB_figs'\n",
    "# output_mother_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# ### Now you need change the directory name per campaign\n",
    "# ### Naming rule is this:\n",
    "# ### <TB location>_TB_MonthYear\n",
    "# ### E.g. desy_TB_Apr2024, cern_TB_Sep2023, fnal_TB_Jul2024\n",
    "\n",
    "# output_campaign_dir = output_mother_dir / 'desy_TB_Apr2024'\n",
    "# output_campaign_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_resolution_table(input_df=selected_data, board_ids=board_to_analyze, board_names=chip_names, tb_loc='cern', fig_tag=chip_figtitles,\n",
    "                      min_resolution=10, max_resolution=100, slides_friendly = False, show_number=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_resolution_with_pulls(input_df=selected_data, board_ids=board_to_analyze, board_names=chip_names, tb_loc='cern',\n",
    "                           fig_tag=chip_figtitles, hist_range=[10, 95], hist_bins=50, print_fit_results=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
