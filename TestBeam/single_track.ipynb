{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import beamtest_analysis_helper as helper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "import hist\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import mplhep as hep\n",
    "hep.style.use('CMS')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_read = ['evt', 'board', 'row', 'col', 'toa', 'tot', 'cal']\n",
    "names = [\"ET2_EPIR_Pair1\", \"ET2p01_BAR_4\", \"ET2p01_BAR_5\", \"ET2_EPIR_Pair4\"]\n",
    "\n",
    "high_voltages = [250, 260, 210, 260]\n",
    "offsets = [15, 10, 10, 15]\n",
    "\n",
    "chip_figtitles = [\n",
    "    f\"(Trigger) EPIR Pair1 HV{high_voltages[0]}V OS:{offsets[0]}\",\n",
    "    f\"(DUT1) Barcelona 4 HV{high_voltages[1]}V OS:{offsets[1]}\",\n",
    "    f\"(DUT2) Barcelona 5 HV{high_voltages[2]}V OS:{offsets[2]}\",\n",
    "    f\"(Reference) EPIR Pair4 HV{high_voltages[3]}V OS:{offsets[3]}\"\n",
    "]\n",
    "\n",
    "dut1_id = 1\n",
    "dut2_id = 2\n",
    "ref_id = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = natsorted(glob('DESYFeb2024_Run_3*_feather/*feather'))\n",
    "files[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_evt = 0\n",
    "dataframes = []\n",
    "\n",
    "pixel_buffer = 2\n",
    "single_pixel_row = 7\n",
    "single_pixel_col = 4\n",
    "\n",
    "for idx, ifile in enumerate(tqdm(files)):\n",
    "\n",
    "    tmp_df = pd.read_feather(ifile, columns=columns_to_read)\n",
    "\n",
    "    if tmp_df.empty:\n",
    "        continue\n",
    "\n",
    "    subset_df = tmp_df.loc[ ((tmp_df['board'] == 0) | (tmp_df['board'] == dut1_id) | (tmp_df['board'] == ref_id))\n",
    "                           & ( (tmp_df['row'] >= single_pixel_row-pixel_buffer) & (tmp_df['row'] <= single_pixel_row+pixel_buffer) )\n",
    "                           & ( (tmp_df['col'] >= single_pixel_col-pixel_buffer) & (tmp_df['col'] <= single_pixel_col+pixel_buffer) )\n",
    "                           ]\n",
    "    del tmp_df\n",
    "\n",
    "    event_board_counts = subset_df.groupby(['evt', 'board']).size().unstack(fill_value=0)\n",
    "    event_selection_col = (event_board_counts[0] == 1) & (event_board_counts[dut1_id] == 1) & (event_board_counts[ref_id] == 1)\n",
    "\n",
    "    isolated_df = subset_df.loc[subset_df['evt'].isin(event_board_counts[event_selection_col].index)]\n",
    "    isolated_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    new_df = isolated_df.loc[(isolated_df['row'] == single_pixel_row) & (isolated_df['col'] == single_pixel_col)]\n",
    "\n",
    "    event_board_counts = new_df.groupby(['evt', 'board']).size().unstack(fill_value=0)\n",
    "    event_selection_col = (event_board_counts[0] == 1) & (event_board_counts[dut1_id] == 1) & (event_board_counts[ref_id] == 1)\n",
    "\n",
    "    isolated_df = new_df.loc[new_df['evt'].isin(event_board_counts[event_selection_col].index)]\n",
    "    isolated_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    isolated_df['evt'] = isolated_df.groupby('evt').ngroup().astype('uint64')\n",
    "\n",
    "    if idx > 0:\n",
    "        isolated_df['evt'] += np.uint64(last_evt)\n",
    "\n",
    "    last_evt += np.uint64(isolated_df['evt'].nunique())\n",
    "\n",
    "\n",
    "    dataframes.append(isolated_df)\n",
    "    del isolated_df, new_df, event_board_counts, event_selection_col\n",
    "\n",
    "df = pd.concat(dataframes)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "del dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_inclusive = helper.return_hist(df, chipNames=names, chipLabels=[0,1,2,3], hist_bins=[100, 128, 128])\n",
    "\n",
    "for iboard in [0,1,2,3]:\n",
    "    helper.plot_1d_TDC_histograms(h_inclusive, names[iboard], names[iboard], chip_figtitles[iboard], save=False,\n",
    "                                tag=\"tdc_Selection\", fig_tag=\", TDC cuts\", slide_friendly=True)\n",
    "\n",
    "del h_inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting good hits\n",
    "tdc_cuts = {}\n",
    "for idx in [0,1,3]:\n",
    "    # board ID: [CAL LB, CAL UB, TOA LB, TOA UB, TOT LB, TOT UB]\n",
    "    if idx == 0:\n",
    "        tdc_cuts[idx] = [df.loc[df['board'] == idx]['cal'].mode()[0]-3, df.loc[df['board'] == idx]['cal'].mode()[0]+3,  100, 500, 100, 250]\n",
    "    elif idx == ref_id:\n",
    "        tdc_cuts[idx] = [df.loc[df['board'] == idx]['cal'].mode()[0]-3, df.loc[df['board'] == idx]['cal'].mode()[0]+3,  0, 1100, 100, 200]\n",
    "    else:\n",
    "        tdc_cuts[idx] = [df.loc[df['board'] == idx]['cal'].mode()[0]-3, df.loc[df['board'] == idx]['cal'].mode()[0]+3,  0, 1100, 0, 600]\n",
    "\n",
    "filtered_df = helper.tdc_event_selection(df, tdc_cuts_dict=tdc_cuts, select_by_hit=False)\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_after_tdc = helper.return_hist(filtered_df, chipNames=names, chipLabels=[0,1,2,3], hist_bins=[100, 128, 128])\n",
    "\n",
    "for iboard in [0,1,2,3]:\n",
    "    helper.plot_1d_TDC_histograms(h_after_tdc, names[iboard], names[iboard], chip_figtitles[iboard], save=False,\n",
    "                                tag=\"tdc_Selection\", fig_tag=\", TDC cuts\", slide_friendly=True)\n",
    "\n",
    "del h_after_tdc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_filterd_df = filtered_df.loc[(filtered_df['board'] == 0) | (filtered_df['board'] == ref_id)]\n",
    "helper.plot_TDC_correlation_scatter_matrix(input_df=plot_filterd_df, chip_names=names, single_hit=False, colinear=False, save=False)\n",
    "del plot_filterd_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = filtered_df.loc[filtered_df['board'] == 0]['toa'].reset_index(drop=True)\n",
    "y = filtered_df.loc[filtered_df['board'] == ref_id]['toa'].reset_index(drop=True)\n",
    "\n",
    "params = np.polyfit(x, y, 1)\n",
    "\n",
    "h_test = hist.Hist(\n",
    "    hist.axis.Regular(128, 0, 1024, name='toa_0', label='toa_0'),\n",
    "    hist.axis.Regular(128, 0, 1024, name=f'toa_{ref_id}', label=f'toa_{ref_id}'),\n",
    ")\n",
    "h_test.fill(x.values, y.values)\n",
    "\n",
    "hep.hist2dplot(h_test, norm=colors.LogNorm())\n",
    "\n",
    "# calculate the trendline\n",
    "trendpoly = np.poly1d(params)\n",
    "\n",
    "# plot the trend line\n",
    "plt.plot(x.values, trendpoly(x.values), 'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = filtered_df.loc[filtered_df['board'] == 0]['toa'].reset_index(drop=True)\n",
    "y = filtered_df.loc[filtered_df['board'] == dut1_id]['toa'].reset_index(drop=True)\n",
    "\n",
    "params = np.polyfit(x, y, 1)\n",
    "\n",
    "h_test = hist.Hist(\n",
    "    hist.axis.Regular(128, 0, 1024, name='toa_0', label='toa_0'),\n",
    "    hist.axis.Regular(128, 0, 1024, name=f'toa_{dut1_id}', label=f'toa_{dut1_id}'),\n",
    ")\n",
    "h_test.fill(x.values, y.values)\n",
    "\n",
    "hep.hist2dplot(h_test, norm=colors.LogNorm())\n",
    "\n",
    "# calculate the trendline\n",
    "trendpoly = np.poly1d(params)\n",
    "\n",
    "# plot the trend line\n",
    "plt.plot(x.values, trendpoly(x.values), 'r-')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation cut (distance cut) 1. trig + ref and 2. trig + dut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = filtered_df.loc[filtered_df['board'] == 0]['toa'].reset_index(drop=True)\n",
    "y = filtered_df.loc[filtered_df['board'] == ref_id]['toa'].reset_index(drop=True)\n",
    "\n",
    "trig_ref_params = np.polyfit(x, y, 1)\n",
    "trig_ref_distance = (x*trig_ref_params[0] - y + trig_ref_params[1])/(np.sqrt(trig_ref_params[0]**2 + 1))\n",
    "\n",
    "x = filtered_df.loc[filtered_df['board'] == 0]['toa'].reset_index(drop=True)\n",
    "y = filtered_df.loc[filtered_df['board'] == dut1_id]['toa'].reset_index(drop=True)\n",
    "\n",
    "trig_dut_params = np.polyfit(x, y, 1)\n",
    "trig_dut_distance = (x*trig_dut_params[0] - y + trig_dut_params[1])/(np.sqrt(trig_dut_params[0]**2 + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table = filtered_df.pivot(index=[\"evt\"], columns=[\"board\"], values=[\"row\", \"col\", \"toa\", \"tot\", \"cal\"])\n",
    "pivot_table = pivot_table.reset_index()\n",
    "pivot_table = pivot_table[(trig_ref_distance.abs() < 3*np.std(trig_ref_distance)) & (trig_dut_distance.abs() < 3*np.std(trig_dut_distance))]\n",
    "pivot_table = pivot_table.reset_index(drop=True)\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_to_analyze = [0,1,3]\n",
    "iteration = 100\n",
    "sampling_fraction = 0.75\n",
    "counter = 0\n",
    "sum_arr = defaultdict(float)\n",
    "sum_square_arr = defaultdict(float)\n",
    "final_dict = defaultdict(list)\n",
    "each_res = defaultdict(list)\n",
    "\n",
    "for iloop in tqdm(range(iteration)):\n",
    "\n",
    "    tdc_filtered_df = pivot_table\n",
    "\n",
    "    n = int(sampling_fraction*tdc_filtered_df.shape[0])\n",
    "    indices = np.random.choice(tdc_filtered_df['evt'].unique(), n, replace=False)\n",
    "    tdc_filtered_df = tdc_filtered_df.loc[tdc_filtered_df['evt'].isin(indices)]\n",
    "\n",
    "    if tdc_filtered_df.shape[0] < iteration/(3.*(1-sampling_fraction)):\n",
    "        print('Warning!! Sampling size is too small. Skipping this track')\n",
    "        break\n",
    "\n",
    "    d = {\n",
    "        'evt': tdc_filtered_df['evt'].unique(),\n",
    "    }\n",
    "\n",
    "    for idx in board_to_analyze:\n",
    "        bins = 3125/tdc_filtered_df['cal'][idx].mean()\n",
    "        d[f'toa_b{str(idx)}'] = 12.5 - tdc_filtered_df['toa'][idx] * bins\n",
    "        d[f'tot_b{str(idx)}'] = (2*tdc_filtered_df['tot'][idx] - np.floor(tdc_filtered_df['tot'][idx]/32)) * bins\n",
    "\n",
    "    df_in_time = pd.DataFrame(data=d)\n",
    "    del d, tdc_filtered_df\n",
    "\n",
    "    if(len(board_to_analyze)==3):\n",
    "        corr_toas = helper.three_board_iterative_timewalk_correction(df_in_time, 5, 3, board_list=board_to_analyze)\n",
    "    elif(len(board_to_analyze)==4):\n",
    "        corr_toas = helper.four_board_iterative_timewalk_correction(df_in_time, 5, 3)\n",
    "    else:\n",
    "        print(\"You have less than 3 boards to analyze\")\n",
    "        break\n",
    "\n",
    "    diffs = {}\n",
    "    for board_a in board_to_analyze:\n",
    "        for board_b in board_to_analyze:\n",
    "            if board_b <= board_a:\n",
    "                continue\n",
    "            name = f\"{board_a}{board_b}\"\n",
    "            diffs[name] = np.asarray(corr_toas[f'toa_b{board_a}'] - corr_toas[f'toa_b{board_b}'])\n",
    "\n",
    "    try:\n",
    "        fit_params = {}\n",
    "        for key in diffs.keys():\n",
    "            params = helper.fwhm_based_on_gaussian_mixture_model(diffs[key], n_components=2, each_component=False, plotting=False)\n",
    "            fit_params[key] = float(params[0]/2.355)\n",
    "            # gmm_sigmas.append(params[1])\n",
    "        del params, diffs, corr_toas\n",
    "\n",
    "        resolutions = helper.return_resolution_three_board_fromFWHM(fit_params, var=list(fit_params.keys()), board_list=board_to_analyze)\n",
    "\n",
    "        if any(np.isnan(val) for key, val in resolutions.items()):\n",
    "            print('fit results is not good, skipping this iteration')\n",
    "            continue\n",
    "\n",
    "        for key in resolutions.keys():\n",
    "            each_res[key].append(resolutions[key])\n",
    "            sum_arr[key] += resolutions[key]\n",
    "            sum_square_arr[key] += resolutions[key]**2\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "    except Exception as inst:\n",
    "        print(inst)\n",
    "        del diffs, corr_toas\n",
    "\n",
    "if counter != 0:\n",
    "    for idx in board_to_analyze:\n",
    "        final_dict[f'row{idx}'].append(pivot_table['row'][idx].unique()[0])\n",
    "        final_dict[f'col{idx}'].append(pivot_table['col'][idx].unique()[0])\n",
    "\n",
    "    for key in sum_arr.keys():\n",
    "        mean = sum_arr[key]/counter\n",
    "        std = np.sqrt((1/(counter-1))*(sum_square_arr[key]-counter*(mean**2)))\n",
    "        final_dict[f'res{key}'].append(mean)\n",
    "        final_dict[f'err{key}'].append(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "each_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(each_res[3], bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
