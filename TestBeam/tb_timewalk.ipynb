{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# zlib License\n",
    "#\n",
    "# (C) 2023 Murtaza Safdari <musafdar@cern.ch>, Jongho Lee <jongho.lee@cern.ch>\n",
    "#\n",
    "# This software is provided 'as-is', without any express or implied\n",
    "# warranty.  In no event will the authors be held liable for any damages\n",
    "# arising from the use of this software.\n",
    "#\n",
    "# Permission is granted to anyone to use this software for any purpose,\n",
    "# including commercial applications, and to alter it and redistribute it\n",
    "# freely, subject to the following restrictions:\n",
    "#\n",
    "# 1. The origin of this software must not be misrepresented; you must not\n",
    "#    claim that you wrote the original software. If you use this software\n",
    "#    in a product, an acknowledgment in the product documentation would be\n",
    "#    appreciated but is not required.\n",
    "# 2. Altered source versions must be plainly marked as such, and must not be\n",
    "#    misrepresented as being the original software.\n",
    "# 3. This notice may not be removed or altered from any source distribution.\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beamtest_analysis_helper import etroc2_analysis_helper\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "import hist\n",
    "import mplhep as hep\n",
    "hep.style.use('CMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!!!!!\n",
    "# It is very important to correctly set the chip name, this value is stored with the data\n",
    "\n",
    "chip_names = [\"ET2_W36_IP7_13_HV210V_offset24\",\"ET2_EPIR_1_1_HV210V_offset24\", \"ET2_CNM_1_3_HV210V_offset6\"]\n",
    "chip_fignames = chip_names\n",
    "chip_figtitles = [\"ETROC2 WB W36 IP7-13 HV210V OS:24\",\"(Trigger) ETROC2 BB EPIR 1-1 HV210V OS:24\", \"ETROC2 BB CNM 1-3 HV210V OS:6\"]\n",
    "\n",
    "chip_labels= [\"1\",\"0\",\"3\"]\n",
    "\n",
    "today = datetime.date.today().isoformat()\n",
    "fig_outdir = Path('../../ETROC-figures')\n",
    "fig_outdir = fig_outdir / (today + '_Array_Test_Results')\n",
    "fig_outdir.mkdir(exist_ok=True)\n",
    "fig_path = str(fig_outdir)\n",
    "\n",
    "# path_pattern = f\"*2023-09-21_Array_Test_Results/SelfTrigger_bottom_Readout_topbottom_1\"\n",
    "# path_pattern = f\"./testbeam_sep24/SelfTrigger_ET2_CNM_BATCH_1_3_Readout_ET2_EPIR_BATCH1_1_ET2_W36_IP7_13_ET2_CNM_BATCH1_3_loop_*.pqt\"\n",
    "path_pattern = \"./highpower_offset6/SelfTrigger_ET2_EPIR_BATCH1_1_Readout_ET2_W36_IP7_13_ET2_CNM_BATCH1_3_offset6_highpower_FINALRUN_loop_*.pqt\"\n",
    "\n",
    "helper = etroc2_analysis_helper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(dpi=50, figsize=(5,5))\n",
    "gs = fig.add_gridspec(1,1)\n",
    "\n",
    "ax0 = fig.add_subplot(gs[0,0])\n",
    "ax0.plot([1, 0], [1, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Event selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(path_pattern)\n",
    "files = natsorted(files)\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "for ifile in files:\n",
    "    tmp_df = pd.read_parquet(ifile)\n",
    "    if tmp_df.empty:\n",
    "        continue\n",
    "\n",
    "    # Group the DataFrame by 'evt' and count unique 'board' values in each group\n",
    "    unique_board_counts = tmp_df.groupby('evt')['board'].nunique()\n",
    "\n",
    "    ## event has three unique board ID\n",
    "    event_numbers_with_three_unique_boards = unique_board_counts[unique_board_counts == 3].index\n",
    "    subset_df = tmp_df[tmp_df['evt'].isin(event_numbers_with_three_unique_boards)]\n",
    "    subset_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    del tmp_df\n",
    "    if subset_df.empty: \n",
    "        continue\n",
    "    \n",
    "    dataframes.append(subset_df)\n",
    "\n",
    "df = pd.concat(dataframes)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "del dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_inclusive = helper.return_hist(df, chip_names, chip_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.make_pix_inclusive_plots(h_inclusive, chip_names[0], chip_fignames[0], chip_figtitles[0], fig_path, save=False, show=True, tag=\"inclusive\", title_tag=\", inclusive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.make_pix_inclusive_plots(h_inclusive, chip_names[1], chip_fignames[1], chip_figtitles[1], fig_path, save=False, show=True, tag=\"inclusive\", title_tag=\", inclusive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.make_pix_inclusive_plots(h_inclusive, chip_names[2], chip_fignames[2], chip_figtitles[2], fig_path, save=False, show=True, tag=\"inclusive\", title_tag=\", inclusive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del h_inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.making_heatmap_byPandas(df, chip_labels, chip_figtitles, \"inclusive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.making_3d_heatmap_byPandas(df, chip_labels, chip_figtitles, \"inclusive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Event counter and 2D heatmap based on WB pixel selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_info = [1, 15, 6]\n",
    "simple_filtered_df = helper.find_maximum_event_combination(df, pix_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.making_heatmap_byPandas(simple_filtered_df, chip_labels, chip_figtitles, figtitle_tag=\"WB pixel (15, 6)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del simple_filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pixel ID selection based on the event counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pix_dict = {\n",
    "    # board ID: [row, col]\n",
    "    0: [ 2, 6],\n",
    "    1: [15, 6],\n",
    "    2: [ 0, 0],\n",
    "    3: [ 3, 5],\n",
    "}\n",
    "\n",
    "filtered_group = helper.pixel_filter(df, pix_dict)\n",
    "filtered_group = helper.singlehit_event_clear_func(filtered_group)\n",
    "filtered_group.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_pix_selected = helper.return_hist(filtered_group, chip_names, chip_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.make_pix_inclusive_plots(h_pix_selected, chip_names[0], chip_fignames[0], chip_figtitles[0], fig_path, save=False, show=True, tag=\"inclusive\", title_tag=\", Pixel (15, 6)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.make_pix_inclusive_plots(h_pix_selected, chip_names[1], chip_fignames[1], chip_figtitles[1], fig_path, save=False, show=True, tag=\"inclusive\", title_tag=\", Pixel (2, 6)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.make_pix_inclusive_plots(h_pix_selected, chip_names[2], chip_fignames[2], chip_figtitles[2], fig_path, save=False, show=True, tag=\"inclusive\", title_tag=\", Pixel (3, 5)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del h_pix_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TDC cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom filtering criteria for each board\n",
    "tdc_cuts = {    \n",
    "    # board ID: [CAL LB, CAL UB, TOA LB, TOA UB, TOT LB, TOT UB]\n",
    "    0: [199, 205,   0, 1100,   0, 600],\n",
    "    1: [200, 210, 275,  350,   0, 600],\n",
    "    2: [160, 220,   0, 1100,   0, 600],\n",
    "    3: [189, 195,   0, 1000,   0, 600],\n",
    "}\n",
    "\n",
    "tdc_filtered_df = helper.tdc_event_selection(filtered_group, tdc_cuts)\n",
    "tdc_filtered_df = helper.singlehit_event_clear_func(tdc_filtered_df)\n",
    "tdc_filtered_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del filtered_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_filter(group):\n",
    "    return group.sort_values(by=['board'], ascending=True)\n",
    "\n",
    "def distance_filter(group, distance):\n",
    "    board0_row = group[(group[\"board\"] == 0)]\n",
    "    board3_row = group[(group[\"board\"] == 3)]\n",
    "    board0_col = group[(group[\"board\"] == 0)]\n",
    "    board3_col = group[(group[\"board\"] == 3)]\n",
    "\n",
    "    if not board0_row.empty and not board3_row.empty and not board0_col.empty and not board3_col.empty:\n",
    "        row_index_diff = abs(board0_row[\"row\"].values[0] - board3_row[\"row\"].values[0])\n",
    "        col_index_diff = abs(board0_col[\"col\"].values[0] - board3_col[\"col\"].values[0])\n",
    "        return row_index_diff < distance and col_index_diff < distance\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# tmp_group = selected_subset_df.groupby('evt')\n",
    "# filtered_simple_group = tmp_group.filter(simple_filter, board=1, row=15, col=6)\n",
    "# filtered_simple_group.reset_index(inplace=True, drop=True)\n",
    "# del tmp_group\n",
    "\n",
    "# grouped = filtered_simple_group.groupby('evt')\n",
    "# sorted_filtered_simple_group = grouped.apply(sort_filter)\n",
    "# sorted_filtered_simple_group.reset_index(inplace=True, drop=True)\n",
    "# sorted_filtered_simple_group\n",
    "# del grouped\n",
    "\n",
    "# grouped = sorted_filtered_simple_group.groupby('evt')\n",
    "# dis_simple_group = grouped.filter(distance_filter, distance=2)\n",
    "# dis_simple_group\n",
    "\n",
    "# test_group = dis_simple_group.groupby(['board', 'row', 'col'])\n",
    "# test = test_group.size().reset_index(name='count')\n",
    "# test.to_csv('test.csv', index=False)\n",
    "\n",
    "# del filtered_simple_group,sorted_filtered_simple_group,grouped,dis_simple_group, test_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_tdc_selection = helper.return_hist(tdc_filtered_df, chip_names, chip_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.make_pix_inclusive_plots(h_tdc_selection, chip_names[0], chip_fignames[0], chip_figtitles[0], fig_path, save=False, show=True, tag=\"after_tdc_cut\", title_tag=\", Pixel (15, 6) after TDC cut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.make_pix_inclusive_plots(h_tdc_selection, chip_names[1], chip_fignames[1], chip_figtitles[1], fig_path, save=False, show=True, tag=\"\", title_tag=\", Pixel (2, 6) after TDC cut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.make_pix_inclusive_plots(h_tdc_selection, chip_names[2], chip_fignames[2], chip_figtitles[2], fig_path, save=False, show=True, tag=\"\", title_tag=\", Pixel (2, 5) after TDC cut\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del h_tdc_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert TDC code to TDC time in [ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = tdc_filtered_df\n",
    "\n",
    "pix_rows = []\n",
    "pix_cols = []\n",
    "fit_params = []\n",
    "cal_means = {boardID:{} for boardID in chip_labels}\n",
    "\n",
    "for boardID in chip_labels:\n",
    "    groups = selected_df[selected_df['board'] == int(boardID)].groupby(['row', 'col'])\n",
    "    for (row, col), group in groups:\n",
    "        \n",
    "        cal_mean = group['cal'].mean()\n",
    "        cal_means[boardID][(row, col)] = cal_mean\n",
    "\n",
    "cal_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin0 = (3.125/cal_means[\"0\"][(2, 6)])\n",
    "bin1 = (3.125/cal_means[\"1\"][(15, 6)])\n",
    "bin3 = (3.125/cal_means[\"3\"][(3, 5)])\n",
    "\n",
    "toa_in_time_b0 = 12.5 - selected_df[selected_df['board'] == 0]['toa'] * bin0\n",
    "toa_in_time_b1 = 12.5 - selected_df[selected_df['board'] == 1]['toa'] * bin1\n",
    "toa_in_time_b3 = 12.5 - selected_df[selected_df['board'] == 3]['toa'] * bin3\n",
    "\n",
    "tot_in_time_b0 = (2*selected_df[selected_df['board'] == 0]['tot'] - np.floor(selected_df[selected_df['board'] == 0]['tot']/32)) * bin0\n",
    "tot_in_time_b1 = (2*selected_df[selected_df['board'] == 1]['tot'] - np.floor(selected_df[selected_df['board'] == 1]['tot']/32)) * bin1\n",
    "tot_in_time_b3 = (2*selected_df[selected_df['board'] == 3]['tot'] - np.floor(selected_df[selected_df['board'] == 3]['tot']/32)) * bin3\n",
    "\n",
    "d = {\n",
    "    'evt': selected_df['evt'].unique(),\n",
    "    'toa_b0': toa_in_time_b0.to_numpy(),\n",
    "    'tot_b0': tot_in_time_b0.to_numpy(),\n",
    "    'toa_b1': toa_in_time_b1.to_numpy(),\n",
    "    'tot_b1': tot_in_time_b1.to_numpy(),\n",
    "    'toa_b3': toa_in_time_b3.to_numpy(),\n",
    "    'tot_b3': tot_in_time_b3.to_numpy(),\n",
    "}\n",
    "\n",
    "df_in_time = pd.DataFrame(data=d)\n",
    "del d, selected_df, tdc_filtered_df\n",
    "\n",
    "df_in_time.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Time Walk Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_toa_b0 = (0.5*(df_in_time['toa_b1'] + df_in_time['toa_b3']) - df_in_time['toa_b0']).values\n",
    "del_toa_b1 = (0.5*(df_in_time['toa_b0'] + df_in_time['toa_b3']) - df_in_time['toa_b1']).values\n",
    "del_toa_b3 = (0.5*(df_in_time['toa_b0'] + df_in_time['toa_b1']) - df_in_time['toa_b3']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_b0 = np.polyfit(df_in_time['tot_b0'].values, del_toa_b0, 3)\n",
    "poly_func_b0 = np.poly1d(coeff_b0)\n",
    "\n",
    "coeff_b1 = np.polyfit(df_in_time['tot_b1'].values, del_toa_b1, 3)\n",
    "poly_func_b1 = np.poly1d(coeff_b1)\n",
    "\n",
    "coeff_b3 = np.polyfit(df_in_time['tot_b3'].values, del_toa_b3, 3)\n",
    "poly_func_b3 = np.poly1d(coeff_b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "hep.cms.text(loc=0, ax=axes[0], text=\"Preliminary\", fontsize=25)\n",
    "axes[0].set_title(f'Board 0 Time Walk Correction', loc=\"right\", size=25)\n",
    "axes[0].scatter(df_in_time['tot_b0'].values,  del_toa_b0, label='data')\n",
    "axes[0].plot(df_in_time['tot_b0'].values, poly_func_b0(df_in_time['tot_b0'].values), 'r.', label='fit')\n",
    "axes[0].set_xlabel('TOT time [ns]')\n",
    "axes[0].set_ylabel(r'$(TOA_{i} + TOA_{j})/2 - TOA$ [ns]' )\n",
    "axes[0].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[1], text=\"Preliminary\", fontsize=25)    \n",
    "axes[1].set_title(f'Board 1 Time Walk Correction', loc=\"right\", size=25)\n",
    "axes[1].scatter(df_in_time['tot_b1'].values,  del_toa_b1, label='data')\n",
    "axes[1].plot(df_in_time['tot_b1'].values, poly_func_b1(df_in_time['tot_b1'].values), 'r.', label='fit')\n",
    "axes[1].set_xlabel('TOT time [ns]')\n",
    "axes[1].set_ylabel(r'$(TOA_{i} + TOA_{j})/2 - TOA$ [ns]')\n",
    "axes[1].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[2], text=\"Preliminary\", fontsize=25)\n",
    "axes[2].set_title(f'Board 3 Time Walk Correction', loc=\"right\", size=25)\n",
    "axes[2].scatter(df_in_time['tot_b3'].values,  del_toa_b3, label='data')\n",
    "axes[2].plot(df_in_time['tot_b3'].values, poly_func_b3(df_in_time['tot_b3'].values), 'r.', label='fit')\n",
    "axes[2].set_xlabel('TOT time [ns]')\n",
    "axes[2].set_ylabel(r'$(TOA_{i} + TOA_{j})/2 - TOA$ [ns]')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffs, corr_toas = helper.iterative_timewalk_correction(df_in_time, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_func_b0 = np.poly1d(coeffs[0])\n",
    "poly_func_b1 = np.poly1d(coeffs[1])\n",
    "poly_func_b3 = np.poly1d(coeffs[2])\n",
    "\n",
    "nth_del_toa_b0 = (0.5*(corr_toas[1] + corr_toas[2]) - corr_toas[0])\n",
    "nth_del_toa_b1 = (0.5*(corr_toas[0] + corr_toas[2]) - corr_toas[1])\n",
    "nth_del_toa_b3 = (0.5*(corr_toas[0] + corr_toas[1]) - corr_toas[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "hep.cms.text(loc=0, ax=axes[0], text=\"Preliminary\", fontsize=25)\n",
    "axes[0].set_title(f'Board 0 Time Walk Correction', loc=\"right\", size=25)\n",
    "axes[0].scatter(df_in_time['tot_b0'].values,  nth_del_toa_b0, label='data')\n",
    "axes[0].plot(df_in_time['tot_b0'].values, poly_func_b0(df_in_time['tot_b0'].values), 'r.', label='fit')\n",
    "axes[0].set_xlabel('TOT time [ns]')\n",
    "axes[0].set_ylabel(r'$(TOA_{i} + TOA_{j})/2 - TOA$ [ns]' )\n",
    "axes[0].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[1], text=\"Preliminary\", fontsize=25)    \n",
    "axes[1].set_title(f'Board 1 Time Walk Correction', loc=\"right\", size=25)\n",
    "axes[1].scatter(df_in_time['tot_b1'].values,  nth_del_toa_b1, label='data')\n",
    "axes[1].plot(df_in_time['tot_b1'].values, poly_func_b1(df_in_time['tot_b1'].values), 'r.', label='fit')\n",
    "axes[1].set_xlabel('TOT time [ns]')\n",
    "axes[1].set_ylabel(r'$(TOA_{i} + TOA_{j})/2 - TOA$ [ns]')\n",
    "axes[1].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[2], text=\"Preliminary\", fontsize=25)\n",
    "axes[2].set_title(f'Board 3 Time Walk Correction', loc=\"right\", size=25)\n",
    "axes[2].scatter(df_in_time['tot_b3'].values,  nth_del_toa_b3, label='data')\n",
    "axes[2].plot(df_in_time['tot_b3'].values, poly_func_b3(df_in_time['tot_b3'].values), 'r.', label='fit')\n",
    "axes[2].set_xlabel('TOT time [ns]')\n",
    "axes[2].set_ylabel(r'$(TOA_{i} + TOA_{j})/2 - TOA$ [ns]')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrTOA_b0 = hist.Hist(hist.axis.Regular(60, 0, 12, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "corrTOA_b1 = hist.Hist(hist.axis.Regular(60, 0, 12, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "corrTOA_b3 = hist.Hist(hist.axis.Regular(60, 0, 12, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "\n",
    "corrTOA_b0.fill(corr_toas[0])\n",
    "corrTOA_b1.fill(corr_toas[1])\n",
    "corrTOA_b3.fill(corr_toas[2])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "hep.cms.text(loc=0, ax=axes[0], text=\"Preliminary\", fontsize=25)\n",
    "axes[0].set_title(f'Board 0 Time Walk Correction', loc=\"right\", size=25)\n",
    "hep.histplot(corrTOA_b0, ax=axes[0], lw=2)\n",
    "axes[0].set_xlabel('Time Walk Corrected TOA [ns]')\n",
    "axes[0].set_ylabel('Entries')\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[1], text=\"Preliminary\", fontsize=25)\n",
    "axes[1].set_title(f'Board 1 Time Walk Correction', loc=\"right\", size=25)\n",
    "hep.histplot(corrTOA_b1, ax=axes[1], lw=2)\n",
    "axes[1].set_xlabel('Time Walk Corrected TOA [ns]')\n",
    "axes[1].set_ylabel('Entries')\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[2], text=\"Preliminary\", fontsize=25)\n",
    "axes[2].set_title(f'Board 3 Time Walk Correction', loc=\"right\", size=25)\n",
    "hep.histplot(corrTOA_b3, ax=axes[2], lw=2)\n",
    "axes[2].set_xlabel('Time Walk Corrected TOA [ns]')\n",
    "axes[2].set_ylabel('Entries')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_dict = {\n",
    "    'evt': df_in_time['evt'].values,\n",
    "    'corr_toa_b0': corr_toas[0],\n",
    "    'corr_toa_b1': corr_toas[1],\n",
    "    'corr_toa_b3': corr_toas[2],\n",
    "}\n",
    "\n",
    "df_in_time_corr = pd.DataFrame(tmp_dict)\n",
    "del tmp_dict\n",
    "df_in_time_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_b01 = df_in_time_corr['corr_toa_b0'] - df_in_time_corr['corr_toa_b1']\n",
    "diff_b03 = df_in_time_corr['corr_toa_b0'] - df_in_time_corr['corr_toa_b3']\n",
    "diff_b13 = df_in_time_corr['corr_toa_b1'] - df_in_time_corr['corr_toa_b3']\n",
    "\n",
    "dTOA_b01 = hist.Hist(hist.axis.Regular(64, diff_b01.mean().round(2)-0.8, diff_b01.mean().round(2)+0.8, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "dTOA_b03 = hist.Hist(hist.axis.Regular(64, diff_b03.mean().round(2)-0.8, diff_b03.mean().round(2)+0.8, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "dTOA_b13 = hist.Hist(hist.axis.Regular(64, diff_b13.mean().round(2)-0.8, diff_b13.mean().round(2)+0.8, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "\n",
    "## These cuts only for a good fitting\n",
    "diff_b01 = diff_b01[(diff_b01 > diff_b01.mean().round(2)-0.8) & (diff_b01 < diff_b01.mean().round(2)+0.8)]\n",
    "diff_b03 = diff_b03[(diff_b03 > diff_b03.mean().round(2)-0.8) & (diff_b03 < diff_b03.mean().round(2)+0.8)]\n",
    "diff_b13 = diff_b13[(diff_b13 > diff_b13.mean().round(2)-0.8) & (diff_b13 < diff_b13.mean().round(2)+0.8)]\n",
    "\n",
    "dTOA_b01.fill(diff_b01)\n",
    "dTOA_b03.fill(diff_b03)\n",
    "dTOA_b13.fill(diff_b13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit using exponnorm in scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import exponnorm\n",
    "\n",
    "fit_params_exponnorm = []\n",
    "\n",
    "range1 = (diff_b01.mean().round(2)-0.8, diff_b01.mean().round(2)+0.8)\n",
    "range2 = (diff_b03.mean().round(2)-0.8, diff_b03.mean().round(2)+0.8)\n",
    "range3 = (diff_b13.mean().round(2)-0.8, diff_b13.mean().round(2)+0.8)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[0], text=\"Preliminary\", fontsize=25)\n",
    "axes[0].set_title(f'Board 0 - Board 1', loc=\"right\", size=25)\n",
    "hep.histplot(dTOA_b01, ax=axes[0], density=True, lw=2)\n",
    "params = exponnorm.fit(diff_b01)\n",
    "fit_params_exponnorm.append(params)\n",
    "x_range = np.linspace(range1[0], range1[1], 500)\n",
    "axes[0].plot(x_range, exponnorm.pdf(x_range, *params), 'r--', lw=2, label=fr'$\\mu:{params[1]:.3f}, \\sigma: {abs(params[2]):.3f}$')\n",
    "axes[0].set_xlabel(r'Time Walk Corrected $\\Delta$TOA [ns]')\n",
    "axes[0].set_ylabel('Arbitrary Units')\n",
    "axes[0].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[1], text=\"Preliminary\", fontsize=25)\n",
    "axes[1].set_title(f'Board 0 - Board 3', loc=\"right\", size=25)\n",
    "hep.histplot(dTOA_b03, ax=axes[1], density=True, lw=2)\n",
    "params = exponnorm.fit(diff_b03)\n",
    "fit_params_exponnorm.append(params)\n",
    "x_range = np.linspace(range2[0], range2[1], 500)\n",
    "axes[1].plot(x_range, exponnorm.pdf(x_range, *params), 'r--', lw=2, label=fr'$\\mu:{params[1]:.3f}, \\sigma: {abs(params[2]):.3f}$')\n",
    "axes[1].set_xlabel(r'Time Walk Corrected $\\Delta$TOA [ns]')\n",
    "axes[1].set_ylabel('Arbitrary Units')\n",
    "axes[1].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[2], text=\"Preliminary\", fontsize=25)\n",
    "axes[2].set_title(f'Board 1 - Board 3', loc=\"right\", size=25)\n",
    "hep.histplot(dTOA_b13, ax=axes[2], density=True, lw=2)\n",
    "params = exponnorm.fit(diff_b13)\n",
    "fit_params_exponnorm.append(params)\n",
    "x_range = np.linspace(range3[0], range3[1], 500)\n",
    "axes[2].plot(x_range, exponnorm.pdf(x_range, *params), 'r--', lw=2, label=fr'$\\mu:{params[1]:.3f}, \\sigma: {abs(params[2]):.3f}$')\n",
    "axes[2].set_xlabel(r'Time Walk Corrected $\\Delta$TOA [ns]')\n",
    "axes[2].set_ylabel('Arbitrary Units')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_b3,err_b3 = helper.return_resolution_ps(fit_params_exponnorm[1][2], 0,\n",
    "                                            fit_params_exponnorm[2][2], 0,\n",
    "                                            fit_params_exponnorm[0][2], 0)\n",
    "res_b1,err_b1 = helper.return_resolution_ps(fit_params_exponnorm[0][2], 0,\n",
    "                                            fit_params_exponnorm[2][2], 0,\n",
    "                                            fit_params_exponnorm[1][2], 0)\n",
    "res_b0,err_b0 = helper.return_resolution_ps(fit_params_exponnorm[0][2], 0,\n",
    "                                            fit_params_exponnorm[1][2], 0,\n",
    "                                            fit_params_exponnorm[2][2], 0)\n",
    "\n",
    "print(f'Board 0: {res_b0:.2f} ps, error: {err_b0:.2f} ps')\n",
    "print(f'Board 1: {res_b1:.2f} ps, error: {err_b1:.2f} ps')\n",
    "print(f'Board 3: {res_b3:.2f} ps, error: {err_b3:.2f} ps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit using lmfit ExponentialGaussianModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit.models import ExponentialGaussianModel\n",
    "\n",
    "fit_params_lmfit = []\n",
    "\n",
    "# Create a CrystalBallModel object\n",
    "mod = ExponentialGaussianModel()\n",
    "fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "\n",
    "\n",
    "edges = 0.5*(dTOA_b01.axes[0].edges[1:] + dTOA_b01.axes[0].edges[:-1])\n",
    "pars = mod.guess(dTOA_b01.values(), x=edges)\n",
    "out = mod.fit(dTOA_b01.values(), pars, x=edges)\n",
    "fit_params_lmfit.append([out.params['sigma'].value, out.params['sigma'].stderr])\n",
    "hep.cms.text(loc=0, ax=axes[0], text=\"Preliminary\", fontsize=25)\n",
    "axes[0].set_title(f'Board 0 - Board 1', loc=\"right\", size=25)\n",
    "hep.histplot(dTOA_b01, ax=axes[0], density=False, lw=2)\n",
    "axes[0].plot(edges, out.best_fit, 'r--', lw=2, label=fr\"$\\mu:{out.params['center'].value:.3f}, \\sigma: {abs(out.params['sigma'].value):.3f}$\")\n",
    "axes[0].legend(fontsize=20, loc='upper right')\n",
    "\n",
    "\n",
    "edges = 0.5*(dTOA_b03.axes[0].edges[1:] + dTOA_b03.axes[0].edges[:-1])\n",
    "pars = mod.guess(dTOA_b03.values(), x=edges)\n",
    "out = mod.fit(dTOA_b03.values(), pars, x=edges)\n",
    "fit_params_lmfit.append([out.params['sigma'].value, out.params['sigma'].stderr])\n",
    "hep.cms.text(loc=0, ax=axes[1], text=\"Preliminary\", fontsize=25)\n",
    "axes[1].set_title(f'Board 0 - Board 3', loc=\"right\", size=25)\n",
    "hep.histplot(dTOA_b03, ax=axes[1], density=False, lw=2)\n",
    "axes[1].plot(edges, out.best_fit, 'r--', lw=2, label=fr\"$\\mu:{out.params['center'].value:.3f}, \\sigma: {abs(out.params['sigma'].value):.3f}$\")\n",
    "axes[1].legend(fontsize=20, loc='upper right')\n",
    "\n",
    "\n",
    "edges = 0.5*(dTOA_b13.axes[0].edges[1:] + dTOA_b13.axes[0].edges[:-1])\n",
    "pars = mod.guess(dTOA_b13.values(), x=edges)\n",
    "out = mod.fit(dTOA_b13.values(), pars, x=edges)\n",
    "fit_params_lmfit.append([out.params['sigma'].value, out.params['sigma'].stderr])\n",
    "hep.cms.text(loc=0, ax=axes[2], text=\"Preliminary\", fontsize=25)\n",
    "axes[2].set_title(f'Board 1 - Board 3', loc=\"right\", size=25)\n",
    "hep.histplot(dTOA_b13, ax=axes[2], density=False, lw=2)\n",
    "axes[2].plot(edges, out.best_fit, 'r--', lw=2, label=fr\"$\\mu:{out.params['center'].value:.3f}, \\sigma: {abs(out.params['sigma'].value):.3f}$\")\n",
    "axes[2].legend(fontsize=20, loc='upper right')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_b0,err_b0 = helper.return_resolution_ps(fit_params_lmfit[0][0], fit_params_lmfit[0][1],\n",
    "                                            fit_params_lmfit[1][0], fit_params_lmfit[1][1],\n",
    "                                            fit_params_lmfit[2][0], fit_params_lmfit[2][1])\n",
    "res_b1,err_b1 = helper.return_resolution_ps(fit_params_lmfit[0][0], fit_params_lmfit[0][1],\n",
    "                                            fit_params_lmfit[2][0], fit_params_lmfit[2][1],\n",
    "                                            fit_params_lmfit[1][0], fit_params_lmfit[1][1])\n",
    "res_b3,err_b3 = helper.return_resolution_ps(fit_params_lmfit[1][0], fit_params_lmfit[1][1],\n",
    "                                            fit_params_lmfit[2][0], fit_params_lmfit[2][1],\n",
    "                                            fit_params_lmfit[0][0], fit_params_lmfit[0][1])\n",
    "\n",
    "print(f'Board 0: {res_b0:.2f} ps, error: {err_b0:.2f} ps')\n",
    "print(f'Board 1: {res_b1:.2f} ps, error: {err_b1:.2f} ps')\n",
    "print(f'Board 3: {res_b3:.2f} ps, error: {err_b3:.2f} ps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Time Walk Correction -  Pairwise Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dense_model(numpars=2, print_summary=False):\n",
    "    input  = Input(shape=(numpars,), name='input')\n",
    "    dense1 = Dense(8, activation='relu', name='dense1',kernel_initializer=initializers.RandomNormal(),bias_initializer=initializers.Zeros())(input)\n",
    "    output = Dense(1, activation='linear', name='output',kernel_initializer=initializers.RandomNormal(),bias_initializer=initializers.Zeros())(dense1)\n",
    "    model  = Model(inputs=[input], outputs=output, name=\"simple_dense_NN\")\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    if(print_summary): print(model.summary())\n",
    "    return model\n",
    "\n",
    "model = return_dense_model(print_summary=True)\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_count = 10\n",
    "data_tag = 'tb_sep28_offset24_triggeroffset6'\n",
    "extra_tag = \"CALNarrow_TOA275to350forWB_NoTOTcut\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etroc_regression_using_NN(\n",
    "        input_df: pd.DataFrame,\n",
    "        variables: list,\n",
    "        data_tag: str,\n",
    "        extra_tag: str,\n",
    "        board_tag: str,\n",
    "        ensemble_count: int,\n",
    "        figure_title: str,\n",
    "        do_plotting: bool,\n",
    "    ):\n",
    "    filename = f'{data_tag}_weights_{extra_tag}_{board_tag}'\n",
    "\n",
    "    for en_idx in range(ensemble_count):\n",
    "        model = return_dense_model(numpars=2)\n",
    "        checkpointer = ModelCheckpoint(f'models/NNRun{en_idx}_{filename}.hdf5', verbose=0, save_best_only=True, monitor=\"val_loss\")\n",
    "        term = tf.keras.callbacks.TerminateOnNaN()\n",
    "        escb = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, verbose=0)\n",
    "        \n",
    "        history = model.fit(\n",
    "            input_df[[variables[0], variables[1]]].values, \n",
    "            (input_df[variables[2]]-input_df[variables[2]]).values, \n",
    "            validation_split=0.4, \n",
    "            epochs=150,\n",
    "            callbacks=[checkpointer,term,escb],\n",
    "            verbose=0)\n",
    "        \n",
    "        del model\n",
    "\n",
    "        if (do_plotting):\n",
    "            #plot the loss and validation loss of the dataset\n",
    "            fig, ax = plt.subplots(figsize=(15, 10), dpi=50)\n",
    "            hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "            ax.set_title(f'Model {en_idx}, {figure_title}', loc=\"right\", size=25)\n",
    "            plt.plot(history.history['loss'], label='mse')\n",
    "            plt.plot(history.history['val_loss'], label='val_mse')\n",
    "            plt.yscale(\"log\")\n",
    "            plt.legend()\n",
    "            plt.savefig(f\"models/NNRun{en_idx}_{filename}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run NN Training (skip if you don't want to do training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['tot_b0', 'tot_b1', 'toa_b0', 'toa_b1']\n",
    "etroc_regression_using_NN(df_in_time, vars, data_tag, extra_tag, \"b01\", ensemble_count, figure_title='Board 0 - Board 1', do_plotting=True)\n",
    "\n",
    "vars = ['tot_b0', 'tot_b3', 'toa_b0', 'toa_b3']\n",
    "etroc_regression_using_NN(df_in_time, vars, data_tag, extra_tag, \"b03\", ensemble_count, figure_title='Board 0 - Board 3', do_plotting=True)\n",
    "\n",
    "vars = ['tot_b1', 'tot_b3', 'toa_b1', 'toa_b3']\n",
    "etroc_regression_using_NN(df_in_time, vars, data_tag, extra_tag, \"b13\", ensemble_count, figure_title='Board 1 - Board 3', do_plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b01 = return_dense_model(numpars=2)\n",
    "filename = f'{data_tag}_weights_{extra_tag}_b01'\n",
    "for en_idx in range(ensemble_count):\n",
    "    model_b01.load_weights(f'models/NNRun{en_idx}_{filename}.hdf5')\n",
    "    if(en_idx==0): Y_pred = model_b01.predict(df_in_time[['tot_b0', 'tot_b1']].values, verbose=0).flatten()\n",
    "    else: Y_pred += model_b01.predict(df_in_time[['tot_b0', 'tot_b1']].values, verbose=0).flatten()\n",
    "del model_b01\n",
    "Y_pred_b01 = Y_pred/ensemble_count\n",
    "\n",
    "model_b03 = return_dense_model(numpars=2)\n",
    "for en_idx in range(ensemble_count):\n",
    "    model_b03.load_weights(f'models/NNRun{en_idx}_{filename}.hdf5')\n",
    "    if(en_idx==0): Y_pred = model_b03.predict(df_in_time[['tot_b0', 'tot_b3']].values, verbose=0).flatten()\n",
    "    else: Y_pred += model_b03.predict(df_in_time[['tot_b0', 'tot_b3']].values, verbose=0).flatten()\n",
    "del model_b03\n",
    "Y_pred_b03 = Y_pred/ensemble_count\n",
    "\n",
    "model_b13 = return_dense_model(numpars=2)\n",
    "for en_idx in range(ensemble_count):\n",
    "    model_b13.load_weights(f'models/NNRun{en_idx}_{filename}.hdf5')\n",
    "    if(en_idx==0): Y_pred = model_b13.predict(df_in_time[['tot_b1', 'tot_b3']].values, verbose=0).flatten()\n",
    "    else: Y_pred += model_b13.predict(df_in_time[['tot_b1',  'tot_b3']].values, verbose=0).flatten()\n",
    "del model_b13\n",
    "Y_pred_b13 = Y_pred/ensemble_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_b01 = (df_in_time['toa_b0']-df_in_time['toa_b1']).values-Y_pred_b01\n",
    "data_b03 = (df_in_time['toa_b0']-df_in_time['toa_b3']).values-Y_pred_b03\n",
    "data_b13 = (df_in_time['toa_b1']-df_in_time['toa_b3']).values-Y_pred_b13\n",
    "\n",
    "## These cuts only for a good fitting\n",
    "data_b01 = data_b01[(data_b01 > data_b01.mean().round(2)-0.5) & (data_b01 < data_b01.mean().round(2)+0.5)]\n",
    "data_b03 = data_b03[(data_b03 > data_b03.mean().round(2)-0.5) & (data_b03 < data_b03.mean().round(2)+0.5)]\n",
    "data_b13 = data_b13[(data_b13 > data_b13.mean().round(2)-0.5) & (data_b13 < data_b13.mean().round(2)+0.5)]\n",
    "\n",
    "dTOA_NN_b01 = hist.Hist(hist.axis.Regular(50, data_b01.mean().round(2)-0.5, data_b01.mean().round(2)+0.5, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "dTOA_NN_b03 = hist.Hist(hist.axis.Regular(50, data_b03.mean().round(2)-0.5, data_b03.mean().round(2)+0.5, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "dTOA_NN_b13 = hist.Hist(hist.axis.Regular(50, data_b13.mean().round(2)-0.5, data_b13.mean().round(2)+0.5, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "\n",
    "dTOA_NN_b01.fill(data_b01)\n",
    "dTOA_NN_b03.fill(data_b03)\n",
    "dTOA_NN_b13.fill(data_b13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### scipy exponnorm fit with NN outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import exponnorm, norm\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "fit_params_exponnorm_NN = []\n",
    "\n",
    "range1 = (data_b01.mean().round(2)-0.5, data_b01.mean().round(2)+0.5)\n",
    "range2 = (data_b03.mean().round(2)-0.5, data_b03.mean().round(2)+0.5)\n",
    "range3 = (data_b13.mean().round(2)-0.5, data_b13.mean().round(2)+0.5)\n",
    "## ----------------------------------------------------\n",
    "\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[0], text=\"Preliminary\", fontsize=25)\n",
    "axes[0].set_title(f'Board 0 - Board 1', loc=\"right\", size=25)\n",
    "hep.histplot(dTOA_NN_b01, ax=axes[0], density=True, lw=2)\n",
    "params = exponnorm.fit(data_b01)\n",
    "fit_params_exponnorm_NN.append(params)\n",
    "x_range = np.linspace(range1[0], range1[1], 500)\n",
    "axes[0].plot(x_range, exponnorm.pdf(x_range, *params), 'r--', lw=2, label=fr'$\\mu:{params[1]:.3f}, \\sigma: {abs(params[2]):.3f}$')\n",
    "axes[0].set_xlabel(r'Time Walk Corrected $\\Delta$TOA [ns]')\n",
    "axes[0].set_ylabel('Arbitrary Units')\n",
    "axes[0].legend(fontsize=20, loc='upper right')\n",
    "## ----------------------------------------------------\n",
    "\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[1], text=\"Preliminary\", fontsize=25)\n",
    "axes[1].set_title(f'Board 0 - Board 3', loc=\"right\", size=25)\n",
    "hep.histplot(dTOA_NN_b03, ax=axes[1], density=True, lw=2)\n",
    "params = exponnorm.fit(data_b03)\n",
    "fit_params_exponnorm_NN.append(params)\n",
    "x_range = np.linspace(range2[0], range2[1], 500)\n",
    "axes[1].plot(x_range, exponnorm.pdf(x_range, *params), 'r--', lw=2, label=fr'$\\mu:{params[1]:.3f}, \\sigma: {abs(params[2]):.3f}$')\n",
    "axes[1].set_xlabel(r'Time Walk Corrected $\\Delta$TOA [ns]')\n",
    "axes[1].set_ylabel('Arbitrary Units')\n",
    "axes[1].legend(fontsize=20, loc='upper right')\n",
    "## ----------------------------------------------------\n",
    "\n",
    "  \n",
    "hep.cms.text(loc=0, ax=axes[2], text=\"Preliminary\", fontsize=25)\n",
    "axes[1].set_title(f'Board 1 - Board 3', loc=\"right\", size=25)\n",
    "hep.histplot(dTOA_NN_b13, ax=axes[2], density=True, lw=2)\n",
    "params = exponnorm.fit(data_b13)\n",
    "fit_params_exponnorm_NN.append(params)\n",
    "x_range = np.linspace(range3[0], range3[1], 500)\n",
    "axes[2].plot(x_range, exponnorm.pdf(x_range, *params), 'r--', lw=2, label=fr'$\\mu:{params[1]:.3f}, \\sigma: {abs(params[2]):.3f}$')\n",
    "axes[2].set_xlabel(r'Time Walk Corrected $\\Delta$TOA [ns]')\n",
    "axes[2].set_ylabel('Arbitrary Units')\n",
    "axes[2].legend(fontsize=20, loc='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_b3,err_b3 = helper.return_resolution_ps(fit_params_exponnorm_NN[1][2], 0,\n",
    "                                            fit_params_exponnorm_NN[2][2], 0,\n",
    "                                            fit_params_exponnorm_NN[0][2], 0)\n",
    "res_b1,err_b1 = helper.return_resolution_ps(fit_params_exponnorm_NN[0][2], 0,\n",
    "                                            fit_params_exponnorm_NN[2][2], 0,\n",
    "                                            fit_params_exponnorm_NN[1][2], 0)\n",
    "res_b0,err_b0 = helper.return_resolution_ps(fit_params_exponnorm_NN[0][2], 0,\n",
    "                                            fit_params_exponnorm_NN[1][2], 0,\n",
    "                                            fit_params_exponnorm_NN[2][2], 0)\n",
    "\n",
    "print(f'Board 0: {res_b0:.2f} ps, error: {err_b0:.2f} ps')\n",
    "print(f'Board 1: {res_b1:.2f} ps, error: {err_b1:.2f} ps')\n",
    "print(f'Board 3: {res_b3:.2f} ps, error: {err_b3:.2f} ps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit using lmfit ExponentialGaussianModel with NN outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lmfit.models import ExponentialGaussianModel\n",
    "\n",
    "fit_params_lmfit_NN = []\n",
    "\n",
    "# Create a CrystalBallModel object\n",
    "mod = ExponentialGaussianModel()\n",
    "fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "\n",
    "\n",
    "edges = 0.5*(dTOA_NN_b01.axes[0].edges[1:] + dTOA_NN_b01.axes[0].edges[:-1])\n",
    "pars = mod.guess(dTOA_NN_b01.values(), x=edges)\n",
    "out = mod.fit(dTOA_NN_b01.values(), pars, x=edges)\n",
    "fit_params_lmfit_NN.append([out.params['sigma'].value, out.params['sigma'].stderr])\n",
    "hep.cms.text(loc=0, ax=axes[0], text=\"Preliminary\", fontsize=25)\n",
    "axes[0].set_title(f'Board 0 - Board 1', loc=\"right\", size=25)\n",
    "hep.histplot(dTOA_NN_b01, ax=axes[0], density=False, lw=2)\n",
    "axes[0].plot(edges, out.best_fit, 'r--', lw=2, label=fr\"$\\mu:{out.params['center'].value:.3f}, \\sigma: {abs(out.params['sigma'].value):.3f}$\")\n",
    "axes[0].legend(fontsize=20, loc='upper right')\n",
    "\n",
    "\n",
    "edges = 0.5*(dTOA_NN_b03.axes[0].edges[1:] + dTOA_NN_b03.axes[0].edges[:-1])\n",
    "pars = mod.guess(dTOA_NN_b03.values(), x=edges)\n",
    "out = mod.fit(dTOA_NN_b03.values(), pars, x=edges)\n",
    "fit_params_lmfit_NN.append([out.params['sigma'].value, out.params['sigma'].stderr])\n",
    "hep.cms.text(loc=0, ax=axes[1], text=\"Preliminary\", fontsize=25)\n",
    "axes[1].set_title(f'Board 0 - Board 3', loc=\"right\", size=25)\n",
    "hep.histplot(dTOA_NN_b03, ax=axes[1], density=False, lw=2)\n",
    "axes[1].plot(edges, out.best_fit, 'r--', lw=2, label=fr\"$\\mu:{out.params['center'].value:.3f}, \\sigma: {abs(out.params['sigma'].value):.3f}$\")\n",
    "axes[1].legend(fontsize=20, loc='upper right')\n",
    "\n",
    "\n",
    "edges = 0.5*(dTOA_NN_b13.axes[0].edges[1:] + dTOA_NN_b13.axes[0].edges[:-1])\n",
    "pars = mod.guess(dTOA_NN_b13.values(), x=edges)\n",
    "out = mod.fit(dTOA_NN_b13.values(), pars, x=edges)\n",
    "fit_params_lmfit_NN.append([out.params['sigma'].value, out.params['sigma'].stderr])\n",
    "hep.cms.text(loc=0, ax=axes[2], text=\"Preliminary\", fontsize=25)\n",
    "axes[2].set_title(f'Board 1 - Board 3', loc=\"right\", size=25)\n",
    "hep.histplot(dTOA_NN_b13, ax=axes[2], density=False, lw=2)\n",
    "axes[2].plot(edges, out.best_fit, 'r--', lw=2, label=fr\"$\\mu:{out.params['center'].value:.3f}, \\sigma: {abs(out.params['sigma'].value):.3f}$\")\n",
    "axes[2].legend(fontsize=20, loc='upper right')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_b0,err_b0 = helper.return_resolution_ps(fit_params_lmfit_NN[0][0], fit_params_lmfit_NN[0][1],\n",
    "                                            fit_params_lmfit_NN[1][0], fit_params_lmfit_NN[1][1],\n",
    "                                            fit_params_lmfit_NN[2][0], fit_params_lmfit_NN[2][1])\n",
    "res_b1,err_b1 = helper.return_resolution_ps(fit_params_lmfit_NN[0][0], fit_params_lmfit_NN[0][1],\n",
    "                                            fit_params_lmfit_NN[2][0], fit_params_lmfit_NN[2][1],\n",
    "                                            fit_params_lmfit_NN[1][0], fit_params_lmfit_NN[1][1])\n",
    "res_b3,err_b3 = helper.return_resolution_ps(fit_params_lmfit_NN[1][0], fit_params_lmfit_NN[1][1],\n",
    "                                            fit_params_lmfit_NN[2][0], fit_params_lmfit_NN[2][1],\n",
    "                                            fit_params_lmfit_NN[0][0], fit_params_lmfit_NN[0][1])\n",
    "\n",
    "print(f'Board 0: {res_b0:.2f} ps, error: {err_b0:.2f} ps')\n",
    "print(f'Board 1: {res_b1:.2f} ps, error: {err_b1:.2f} ps')\n",
    "print(f'Board 3: {res_b3:.2f} ps, error: {err_b3:.2f} ps')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTWC Performance Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_b01 = return_dense_model(numpars=2)\n",
    "model_b03 = return_dense_model(numpars=2)\n",
    "model_b13 = return_dense_model(numpars=2)\n",
    "model_b01.load_weights(f'models/sep27_weights_{0}_b01.hdf5')\n",
    "nn_del_b01 = model_b01.predict(df_in_time[['tot_b0', 'tot_b1']].values, verbose=0).flatten()\n",
    "model_b03.load_weights(f'models/sep27_weights_{0}_b03.hdf5')\n",
    "nn_del_b03 = model_b03.predict(df_in_time[['tot_b0', 'tot_b3']].values, verbose=0).flatten()\n",
    "model_b13.load_weights(f'models/sep27_weights_{0}_b13.hdf5')\n",
    "nn_del_b13 = model_b13.predict(df_in_time[['tot_b1', 'tot_b3']].values, verbose=0).flatten()\n",
    "for en_idx in range(1, ensemble_count):\n",
    "    model_b01.load_weights(f'models/sep27_weights_{en_idx}_b01.hdf5')\n",
    "    nn_del_b01 += model_b01.predict(df_in_time[['tot_b0', 'tot_b1']].values, verbose=0).flatten()\n",
    "    model_b03.load_weights(f'models/sep27_weights_{en_idx}_b03.hdf5')\n",
    "    nn_del_b03 += model_b03.predict(df_in_time[['tot_b0', 'tot_b3']].values, verbose=0).flatten()\n",
    "    model_b13.load_weights(f'models/sep27_weights_{en_idx}_b13.hdf5')\n",
    "    nn_del_b13 += model_b13.predict(df_in_time[['tot_b1', 'tot_b3']].values, verbose=0).flatten()\n",
    "nn_del_b01 = nn_del_b01/ensemble_count\n",
    "nn_del_b03 = nn_del_b03/ensemble_count\n",
    "nn_del_b13 = nn_del_b13/ensemble_count\n",
    "del model_b13,model_b01,model_b03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_b01 = stats.binned_statistic_2d(df_in_time['tot_b0'].values, df_in_time['tot_b1'].values, \n",
    "                                    range=[[2,8],[4,8]], bins=(4,4),\n",
    "                                    values=(nn_del_b01-(df_in_time['toa_b0']-df_in_time['toa_b1']).values), \n",
    "                                    statistic='mean')\n",
    "res_b01 = stats.binned_statistic_2d(df_in_time['tot_b0'].values, df_in_time['tot_b1'].values, \n",
    "                                    range=[[2,8],[4,8]], bins=(4,4),\n",
    "                                    values=(nn_del_b01-(df_in_time['toa_b0']-df_in_time['toa_b1']).values), \n",
    "                                    statistic='std')\n",
    "plt.figure(dpi=50)\n",
    "plt.imshow(cls_b01.statistic.T, extent=[cls_b01.x_edge[0], cls_b01.x_edge[-1], cls_b01.y_edge[0], cls_b01.y_edge[-1]],\n",
    "           interpolation='nearest',aspect='auto',origin='lower')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.figure(dpi=50)\n",
    "plt.imshow(res_b01.statistic.T, extent=[res_b01.x_edge[0], res_b01.x_edge[-1], res_b01.y_edge[0], res_b01.y_edge[-1]],\n",
    "           interpolation='nearest',aspect='auto',origin='lower')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del nn_del_b01,nn_del_b03,nn_del_b13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the traditional plots with the NN outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_b01 = return_dense_model(numpars=2)\n",
    "model_b03 = return_dense_model(numpars=2)\n",
    "model_b13 = return_dense_model(numpars=2)\n",
    "model_b01.load_weights(f'models/sep27_weights_{0}_b01.hdf5')\n",
    "nn_del_b01 = model_b01.predict(df_in_time[['tot_b0', 'tot_b1']].values, verbose=0).flatten()\n",
    "model_b03.load_weights(f'models/sep27_weights_{0}_b03.hdf5')\n",
    "nn_del_b03 = model_b03.predict(df_in_time[['tot_b0', 'tot_b3']].values, verbose=0).flatten()\n",
    "model_b13.load_weights(f'models/sep27_weights_{0}_b13.hdf5')\n",
    "nn_del_b13 = model_b13.predict(df_in_time[['tot_b1', 'tot_b3']].values, verbose=0).flatten()\n",
    "for en_idx in range(1, ensemble_count):\n",
    "    model_b01.load_weights(f'models/sep27_weights_{en_idx}_b01.hdf5')\n",
    "    nn_del_b01 += model_b01.predict(df_in_time[['tot_b0', 'tot_b1']].values, verbose=0).flatten()\n",
    "    model_b03.load_weights(f'models/sep27_weights_{en_idx}_b03.hdf5')\n",
    "    nn_del_b03 += model_b03.predict(df_in_time[['tot_b0', 'tot_b3']].values, verbose=0).flatten()\n",
    "    model_b13.load_weights(f'models/sep27_weights_{en_idx}_b13.hdf5')\n",
    "    nn_del_b13 += model_b13.predict(df_in_time[['tot_b1', 'tot_b3']].values, verbose=0).flatten()\n",
    "nn_del_b01 = nn_del_b01/ensemble_count\n",
    "nn_del_b03 = nn_del_b03/ensemble_count\n",
    "nn_del_b13 = nn_del_b13/ensemble_count\n",
    "del model_b13,model_b01,model_b03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "hep.cms.text(loc=0, ax=axes[0], text=\"Preliminary\", fontsize=25)\n",
    "axes[0].set_title(f'Board 0 Time Walk Correction NN', loc=\"right\", size=25)\n",
    "axes[0].scatter(df_in_time['tot_b0'].values,  del_toa_b0, label='data')\n",
    "axes[0].plot(df_in_time['tot_b0'].values, -0.5*(nn_del_b01+nn_del_b03), 'r.', label='Neural Network')\n",
    "axes[0].set_xlabel('TOT time [ns]')\n",
    "axes[0].set_ylabel(r'$(TOA_{i} + TOA_{j})/2 - TOA$ [ns]' )\n",
    "axes[0].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[1], text=\"Preliminary\", fontsize=25)\n",
    "axes[1].set_title(f'Board 1 Time Walk Correction NN', loc=\"right\", size=25)\n",
    "axes[1].scatter(df_in_time['tot_b1'].values,  del_toa_b1, label='data')\n",
    "axes[1].plot(df_in_time['tot_b1'].values, 0.5*(nn_del_b01-nn_del_b13), 'r.', label='Neural Network')\n",
    "axes[1].set_xlabel('TOT time [ns]')\n",
    "axes[1].set_ylabel(r'$(TOA_{i} + TOA_{j})/2 - TOA$ [ns]')\n",
    "axes[1].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[2], text=\"Preliminary\", fontsize=25)\n",
    "axes[2].set_title(f'Board 3 Time Walk Correction NN', loc=\"right\", size=25)\n",
    "axes[2].scatter(df_in_time['tot_b3'].values,  del_toa_b3, label='data')\n",
    "axes[2].plot(df_in_time['tot_b3'].values, 0.5*(nn_del_b03+nn_del_b13), 'r.', label='Neural Network')\n",
    "axes[2].set_xlabel('TOT time [ns]')\n",
    "axes[2].set_ylabel(r'$(TOA_{i} + TOA_{j})/2 - TOA$ [ns]')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_b0_nn = df_in_time['toa_b0'].values - 0.5*(nn_del_b01+nn_del_b03)\n",
    "diff_b1_nn = df_in_time['toa_b1'].values + 0.5*(nn_del_b01-nn_del_b13)\n",
    "diff_b3_nn = df_in_time['toa_b3'].values + 0.5*(nn_del_b03+nn_del_b13)\n",
    "\n",
    "diff_b01_nn = diff_b0_nn - diff_b1_nn\n",
    "diff_b03_nn = diff_b0_nn - diff_b3_nn\n",
    "diff_b13_nn = diff_b1_nn - diff_b3_nn\n",
    "\n",
    "fit_params = []\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "hep.cms.text(loc=0, ax=axes[0], text=\"Preliminary\", fontsize=25)\n",
    "axes[0].set_title(f'Board 0 Time Walk Correction', loc=\"right\", size=25)\n",
    "\n",
    "bins, edges = np.histogram(diff_b01_nn, range=(-1,1), bins=50, density=True)\n",
    "centers = 0.5*(edges[1:]+edges[:-1])\n",
    "popt, _ = curve_fit(Gauss, centers, bins)\n",
    "fit_params.append(popt)\n",
    "\n",
    "axes[0].hist(diff_b01_nn, range=(-1,1), bins=50, density=True, label='')\n",
    "axes[0].plot(np.linspace(-1,1,500), Gauss(np.linspace(-1,1,500), *popt), 'r-', label=fr'$\\mu:{popt[1]:.3f}, \\sigma: {abs(popt[2]):.3f}$')\n",
    "axes[0].set_xlabel(r'Time Walk Corrected $\\Delta$TOA [ns]')\n",
    "axes[0].set_ylabel('Arbitrary Units')\n",
    "axes[0].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[1], text=\"Preliminary\", fontsize=25)\n",
    "axes[1].set_title(f'Board 1 Time Walk Correction', loc=\"right\", size=25)\n",
    "\n",
    "bins, edges = np.histogram(diff_b03_nn, range=(-1,1), bins=50, density=True)\n",
    "centers = 0.5*(edges[1:]+edges[:-1])\n",
    "popt, _ = curve_fit(Gauss, centers, bins)\n",
    "fit_params.append(popt)\n",
    "\n",
    "axes[1].hist(diff_b03_nn, range=(-1,1), bins=50, density=True, label='')\n",
    "axes[1].plot(np.linspace(-1,1,500), Gauss(np.linspace(-1,1,500), *popt), 'r-', label=fr'$\\mu:{popt[1]:.3f}, \\sigma: {abs(popt[2]):.3f}$')\n",
    "axes[1].set_xlabel(r'Time Walk Corrected $\\Delta$TOA [ns]')\n",
    "axes[1].set_ylabel('Arbitrary Units')\n",
    "axes[1].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[2], text=\"Preliminary\", fontsize=25)\n",
    "axes[2].set_title(f'Board 3 Time Walk Correction', loc=\"right\", size=25)\n",
    "\n",
    "bins, edges = np.histogram(diff_b13_nn, range=(-1,1), bins=50, density=True)\n",
    "centers = 0.5*(edges[1:]+edges[:-1])\n",
    "popt, _ = curve_fit(Gauss, centers, bins)\n",
    "fit_params.append(popt)\n",
    "\n",
    "axes[2].hist(diff_b13_nn, range=(-1,1), bins=50, density=True, label='')\n",
    "axes[2].plot(np.linspace(-1,1,500), Gauss(np.linspace(-1,1,500), *popt), 'r-', label=fr'$\\mu:{popt[1]:.3f}, \\sigma: {abs(popt[2]):.3f}$')\n",
    "axes[2].set_xlabel(r'Time Walk Corrected $\\Delta$TOA [ns]')\n",
    "axes[2].set_ylabel('Arbitrary Units')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_resol_b3 = np.sqrt(0.5)*(np.sqrt(fit_params[2][2]**2 + fit_params[1][2]**2 - fit_params[0][2]**2))\n",
    "time_resol_b3*1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_resol_b1 = np.sqrt(0.5)*(np.sqrt(fit_params[2][2]**2 + fit_params[0][2]**2 - fit_params[1][2]**2))\n",
    "time_resol_b1*1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_resol_b0 = np.sqrt(0.5)*(np.sqrt(fit_params[0][2]**2 + fit_params[1][2]**2 - fit_params[2][2]**2))\n",
    "time_resol_b0*1e3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Time Walk Correction -  Triple Input Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_big_dense_model(numpars=3, print_summary=False):\n",
    "    input  = Input(shape=(numpars,), name='input')\n",
    "    dense1 = Dense(8, activation='relu', name='dense1',kernel_initializer=initializers.RandomNormal(),bias_initializer=initializers.Zeros())(input)\n",
    "    dense2 = Dense(8, activation='relu', name='dense2',kernel_initializer=initializers.RandomNormal(),bias_initializer=initializers.Zeros())(dense1)\n",
    "    output = Dense(1, activation='linear', name='output',kernel_initializer=initializers.RandomNormal(),bias_initializer=initializers.Zeros())(dense2)\n",
    "    model  = Model(inputs=[input], outputs=output, name=\"big_dense_NN\")\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    if(print_summary): print(model.summary())\n",
    "    return model\n",
    "model = return_big_dense_model(print_summary=True)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_training = False\n",
    "if(do_training):\n",
    "    for en_idx in range(ensemble_count):\n",
    "        model_b130 = return_big_dense_model(numpars=1)\n",
    "        checkpointer = ModelCheckpoint(f'models/sep28_weights_{en_idx}_b130.hdf5', verbose=0, save_best_only=True,monitor=\"val_loss\")\n",
    "        term = tf.keras.callbacks.TerminateOnNaN()\n",
    "        escb = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, verbose=0)\n",
    "        history_b130 = model_b130.fit(\n",
    "            df_in_time[['tot_b0']].values, \n",
    "            ((df_in_time['toa_b1']+df_in_time['toa_b3']).values/2.) - df_in_time['toa_b0'].values, \n",
    "            validation_split=0.4, \n",
    "            epochs=150,\n",
    "            callbacks=[checkpointer,term,escb],\n",
    "            verbose=0)\n",
    "        del model_b130\n",
    "        \n",
    "        #plot the loss and validation loss of the dataset\n",
    "        fig, ax = plt.subplots(figsize=(15, 10), dpi=50)\n",
    "        hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "        ax.set_title(f'Model {en_idx}, TWC: Board 0', loc=\"right\", size=25)\n",
    "        plt.plot(history_b130.history['loss'], label='mse')\n",
    "        plt.plot(history_b130.history['val_loss'], label='val_mse')\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"models/\"+f\"sep28_weights_{en_idx}_b130_loss\"+\".png\")\n",
    "        plt.show()\n",
    "\n",
    "model_b130 = return_big_dense_model(numpars=1)\n",
    "for en_idx in range(ensemble_count):\n",
    "    model_b130.load_weights(f'models/sep28_weights_{en_idx}_b130.hdf5')\n",
    "    if(en_idx==0): Y_pred = model_b130.predict(df_in_time[['tot_b0']].values, verbose=0).flatten()\n",
    "    else: Y_pred += model_b130.predict(df_in_time[['tot_b0']].values, verbose=0).flatten()\n",
    "del model_b130\n",
    "Y_pred = Y_pred/ensemble_count\n",
    "  \n",
    "data_b0 = df_in_time['toa_b0'].values + Y_pred\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "ax.set_title(f'Board 0 Time Walk Correction NN', loc=\"right\", size=25)\n",
    "ax.scatter(df_in_time['tot_b0'].values,  ((df_in_time['toa_b1']+df_in_time['toa_b3']).values/2.) - df_in_time['toa_b0'].values, label='data')\n",
    "ax.plot(df_in_time['tot_b0'].values, Y_pred, 'r.', label='Neural Network')\n",
    "ax.set_xlabel('TOT time [ns]')\n",
    "ax.set_ylabel(r'$(TOA_{1} + TOA_{3})/2 - TOA_0$ [ns]' )\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_training = True\n",
    "if(do_training):\n",
    "    for en_idx in range(ensemble_count):\n",
    "        model_b031 = return_big_dense_model(numpars=1)\n",
    "        checkpointer = ModelCheckpoint(f'models/sep28_weights_{en_idx}_b031.hdf5', verbose=0, save_best_only=True,monitor=\"val_loss\")\n",
    "        term = tf.keras.callbacks.TerminateOnNaN()\n",
    "        escb = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, verbose=0)\n",
    "        history_b031 = model_b031.fit(\n",
    "            df_in_time[['tot_b1']].values, \n",
    "            ((df_in_time['toa_b0']+df_in_time['toa_b3']).values/2.) - df_in_time['toa_b1'].values, \n",
    "            validation_split=0.4, \n",
    "            epochs=150,\n",
    "            callbacks=[checkpointer,term,escb],\n",
    "            verbose=0)\n",
    "        del model_b031\n",
    "        \n",
    "        #plot the loss and validation loss of the dataset\n",
    "        fig, ax = plt.subplots(figsize=(15, 10), dpi=50)\n",
    "        hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "        ax.set_title(f'Model {en_idx}, TWC: Board 1', loc=\"right\", size=25)\n",
    "        plt.plot(history_b031.history['loss'], label='mse')\n",
    "        plt.plot(history_b031.history['val_loss'], label='val_mse')\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"models/\"+f\"sep28_weights_{en_idx}_b031_loss\"+\".png\")\n",
    "        plt.show()\n",
    "\n",
    "model_b031 = return_big_dense_model(numpars=1)\n",
    "for en_idx in range(ensemble_count):\n",
    "    model_b031.load_weights(f'models/sep28_weights_{en_idx}_b031.hdf5')\n",
    "    if(en_idx==0): Y_pred = model_b031.predict(df_in_time[['tot_b1']].values, verbose=0).flatten()\n",
    "    else: Y_pred += model_b031.predict(df_in_time[['tot_b1']].values, verbose=0).flatten()\n",
    "del model_b031\n",
    "Y_pred = Y_pred/ensemble_count\n",
    "  \n",
    "data_b1 = df_in_time['toa_b1'].values + Y_pred\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "ax.set_title(f'Board 1 Time Walk Correction NN', loc=\"right\", size=25)\n",
    "ax.scatter(df_in_time['tot_b1'].values,  ((df_in_time['toa_b0']+df_in_time['toa_b3']).values/2.) - df_in_time['toa_b1'].values, label='data')\n",
    "ax.plot(df_in_time['tot_b1'].values, Y_pred, 'r.', label='Neural Network')\n",
    "ax.set_xlabel('TOT time [ns]')\n",
    "ax.set_ylabel(r'$(TOA_{0} + TOA_{3})/2 - TOA_1$ [ns]' )\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_training = True\n",
    "if(do_training):\n",
    "    for en_idx in range(ensemble_count):\n",
    "        model_b013 = return_big_dense_model(numpars=1)\n",
    "        checkpointer = ModelCheckpoint(f'models/sep28_weights_{en_idx}_b013.hdf5', verbose=0, save_best_only=True,monitor=\"val_loss\")\n",
    "        term = tf.keras.callbacks.TerminateOnNaN()\n",
    "        escb = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, verbose=0)\n",
    "        history_b013 = model_b013.fit(\n",
    "            df_in_time[['tot_b3']].values, \n",
    "            ((df_in_time['toa_b0']+df_in_time['toa_b1']).values/2.) - df_in_time['toa_b3'].values, \n",
    "            validation_split=0.4, \n",
    "            epochs=150,\n",
    "            callbacks=[checkpointer,term,escb],\n",
    "            verbose=0)\n",
    "        del model_b013\n",
    "        \n",
    "        #plot the loss and validation loss of the dataset\n",
    "        fig, ax = plt.subplots(figsize=(15, 10), dpi=50)\n",
    "        hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "        ax.set_title(f'Model {en_idx}, TWC: Board 3', loc=\"right\", size=25)\n",
    "        plt.plot(history_b013.history['loss'], label='mse')\n",
    "        plt.plot(history_b013.history['val_loss'], label='val_mse')\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"models/\"+f\"sep28_weights_{en_idx}_b013_loss\"+\".png\")\n",
    "        plt.show()\n",
    "\n",
    "model_b013 = return_big_dense_model(numpars=1)\n",
    "for en_idx in range(ensemble_count):\n",
    "    model_b013.load_weights(f'models/sep28_weights_{en_idx}_b013.hdf5')\n",
    "    if(en_idx==0): Y_pred = model_b013.predict(df_in_time[['tot_b3']].values, verbose=0).flatten()\n",
    "    else: Y_pred += model_b013.predict(df_in_time[['tot_b3']].values, verbose=0).flatten()\n",
    "del model_b013\n",
    "Y_pred = Y_pred/ensemble_count\n",
    "  \n",
    "data_b3 = df_in_time['toa_b3'].values + Y_pred\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "ax.set_title(f'Board 1 Time Walk Correction NN', loc=\"right\", size=25)\n",
    "ax.scatter(df_in_time['tot_b3'].values,  ((df_in_time['toa_b0']+df_in_time['toa_b1']).values/2.) - df_in_time['toa_b3'].values, label='data')\n",
    "ax.plot(df_in_time['tot_b3'].values, Y_pred, 'r.', label='Neural Network')\n",
    "ax.set_xlabel('TOT time [ns]')\n",
    "ax.set_ylabel(r'$(TOA_{0} + TOA_{1})/2 - TOA_3$ [ns]' )\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_b01_nn = data_b0 - data_b1\n",
    "diff_b03_nn = data_b0 - data_b3\n",
    "diff_b13_nn = data_b1 - data_b3\n",
    "\n",
    "fit_params_NN = []\n",
    "fit_errors_NN = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_hist = hist.Hist(hist.axis.Regular(50, -1, 1, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "time_hist.fill(diff_b01_nn)\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "grid = fig.add_gridspec(2, 1, hspace=0, height_ratios=[3, 1])\n",
    "main_ax = fig.add_subplot(grid[0])\n",
    "subplot_ax = fig.add_subplot(grid[1], sharex=main_ax)\n",
    "plt.setp(main_ax.get_xticklabels(), visible=False)\n",
    "main_ax_artists, sublot_ax_arists = time_hist.plot_pull(\n",
    "    \"normal\",\n",
    "    eb_ecolor=\"steelblue\",\n",
    "    eb_mfc=\"steelblue\",\n",
    "    eb_mec=\"steelblue\",\n",
    "    eb_fmt=\"o\",\n",
    "    eb_ms=6,\n",
    "    eb_capsize=1,\n",
    "    eb_capthick=2,\n",
    "    eb_alpha=0.8,\n",
    "    fp_c=\"hotpink\",\n",
    "    fp_ls=\"-\",\n",
    "    fp_lw=2,\n",
    "    fp_alpha=0.8,\n",
    "    bar_fc=\"royalblue\",\n",
    "    pp_num=3,\n",
    "    pp_fc=\"royalblue\",\n",
    "    pp_alpha=0.618,\n",
    "    pp_ec=None,\n",
    "    ub_alpha=0.2,\n",
    "    fit_fmt= r\"{name} = {value:.4g} $\\pm$ {error:.4g}\",\n",
    "    ax_dict= {\"main_ax\":main_ax,\"pull_ax\":subplot_ax},\n",
    ")\n",
    "hep.cms.text(loc=0, ax=main_ax, text=\"Preliminary\", fontsize=25)\n",
    "main_ax.set_title(f'Board 0 - Board 1', loc=\"right\", size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params_NN.append([741.1, -0.325, 0.1123])\n",
    "fit_errors_NN.append([12.85, 0.00156, 0.001173])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_hist = hist.Hist(hist.axis.Regular(50, -1, 1, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "time_hist.fill(diff_b03_nn)\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "grid = fig.add_gridspec(2, 1, hspace=0, height_ratios=[3, 1])\n",
    "main_ax = fig.add_subplot(grid[0])\n",
    "subplot_ax = fig.add_subplot(grid[1], sharex=main_ax)\n",
    "plt.setp(main_ax.get_xticklabels(), visible=False)\n",
    "main_ax_artists, sublot_ax_arists = time_hist.plot_pull(\n",
    "    \"normal\",\n",
    "    eb_ecolor=\"steelblue\",\n",
    "    eb_mfc=\"steelblue\",\n",
    "    eb_mec=\"steelblue\",\n",
    "    eb_fmt=\"o\",\n",
    "    eb_ms=6,\n",
    "    eb_capsize=1,\n",
    "    eb_capthick=2,\n",
    "    eb_alpha=0.8,\n",
    "    fp_c=\"hotpink\",\n",
    "    fp_ls=\"-\",\n",
    "    fp_lw=2,\n",
    "    fp_alpha=0.8,\n",
    "    bar_fc=\"royalblue\",\n",
    "    pp_num=3,\n",
    "    pp_fc=\"royalblue\",\n",
    "    pp_alpha=0.618,\n",
    "    pp_ec=None,\n",
    "    ub_alpha=0.2,\n",
    "    fit_fmt= r\"{name} = {value:.4g} $\\pm$ {error:.4g}\",\n",
    "    ax_dict= {\"main_ax\":main_ax,\"pull_ax\":subplot_ax},\n",
    ")\n",
    "hep.cms.text(loc=0, ax=main_ax, text=\"Preliminary\", fontsize=25)\n",
    "main_ax.set_title(f'Board 0 - Board 3', loc=\"right\", size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params_NN.append([831.9, -0.3442, 0.09955])\n",
    "fit_errors_NN.append([14.53, 0.001384, 0.001056])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_hist = hist.Hist(hist.axis.Regular(50, -1, 1, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "time_hist.fill(diff_b13_nn)\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "grid = fig.add_gridspec(2, 1, hspace=0, height_ratios=[3, 1])\n",
    "main_ax = fig.add_subplot(grid[0])\n",
    "subplot_ax = fig.add_subplot(grid[1], sharex=main_ax)\n",
    "plt.setp(main_ax.get_xticklabels(), visible=False)\n",
    "main_ax_artists, sublot_ax_arists = time_hist.plot_pull(\n",
    "    \"normal\",\n",
    "    eb_ecolor=\"steelblue\",\n",
    "    eb_mfc=\"steelblue\",\n",
    "    eb_mec=\"steelblue\",\n",
    "    eb_fmt=\"o\",\n",
    "    eb_ms=6,\n",
    "    eb_capsize=1,\n",
    "    eb_capthick=2,\n",
    "    eb_alpha=0.8,\n",
    "    fp_c=\"hotpink\",\n",
    "    fp_ls=\"-\",\n",
    "    fp_lw=2,\n",
    "    fp_alpha=0.8,\n",
    "    bar_fc=\"royalblue\",\n",
    "    pp_num=3,\n",
    "    pp_fc=\"royalblue\",\n",
    "    pp_alpha=0.618,\n",
    "    pp_ec=None,\n",
    "    ub_alpha=0.2,\n",
    "    fit_fmt= r\"{name} = {value:.4g} $\\pm$ {error:.4g}\",\n",
    "    ax_dict= {\"main_ax\":main_ax,\"pull_ax\":subplot_ax},\n",
    ")\n",
    "hep.cms.text(loc=0, ax=main_ax, text=\"Preliminary\", fontsize=25)\n",
    "main_ax.set_title(f'Board 1 - Board 3', loc=\"right\", size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params_NN.append([899.9, -0.01758, 0.09358])\n",
    "fit_errors_NN.append([15.36, 0.001289, 0.0009443])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_b3,err_b3 = return_resolution_ps(fit_params_NN[1][2], fit_errors_NN[1][2], \n",
    "                                     fit_params_NN[2][2], fit_errors_NN[2][2], \n",
    "                                     fit_params_NN[0][2], fit_errors_NN[0][2])\n",
    "print(res_b3,err_b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_b1,err_b1 = return_resolution_ps(fit_params_NN[0][2], fit_errors_NN[0][2], \n",
    "                                     fit_params_NN[2][2], fit_errors_NN[2][2], \n",
    "                                     fit_params_NN[1][2], fit_errors_NN[1][2])\n",
    "print(res_b1,err_b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_b0,err_b0 = return_resolution_ps(fit_params_NN[0][2], fit_errors_NN[0][2], \n",
    "                                     fit_params_NN[1][2], fit_errors_NN[1][2], \n",
    "                                     fit_params_NN[2][2], fit_errors_NN[2][2])\n",
    "print(res_b0,err_b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del diff_b01_nn,diff_b03_nn,diff_b13_nn,data_b3,data_b1,data_b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
