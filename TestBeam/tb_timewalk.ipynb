{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# zlib License\n",
    "#\n",
    "# (C) 2023 Murtaza Safdari <musafdar@cern.ch>, Jongho Lee <jongho.lee@cern.ch>\n",
    "#\n",
    "# This software is provided 'as-is', without any express or implied\n",
    "# warranty.  In no event will the authors be held liable for any damages\n",
    "# arising from the use of this software.\n",
    "#\n",
    "# Permission is granted to anyone to use this software for any purpose,\n",
    "# including commercial applications, and to alter it and redistribute it\n",
    "# freely, subject to the following restrictions:\n",
    "#\n",
    "# 1. The origin of this software must not be misrepresented; you must not\n",
    "#    claim that you wrote the original software. If you use this software\n",
    "#    in a product, an acknowledgment in the product documentation would be\n",
    "#    appreciated but is not required.\n",
    "# 2. Altered source versions must be plainly marked as such, and must not be\n",
    "#    misrepresented as being the original software.\n",
    "# 3. This notice may not be removed or altered from any source distribution.\n",
    "#############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from beamtest_analysis_helper import etroc2_analysis_helper\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from natsort import natsorted\n",
    "from scipy.optimize import curve_fit\n",
    "import hist\n",
    "import mplhep as hep\n",
    "hep.style.use('CMS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !!!!!!!!!!!!\n",
    "# It is very important to correctly set the chip name, this value is stored with the data\n",
    "chip_names = [\"ET2_W36_IP7_13_HV210V_offset20\",\"ET2_EPIR_1_1_HV210V_offset20\", \"ET2_CNM_1_3_HV210V_offset20\"]\n",
    "chip_fignames = chip_names\n",
    "chip_figtitles = [\"ETROC2 WB W36 IP7-13 HV210V OS:20\",\"ETROC2 BB EPIR 1-1 HV210V OS:20\", \"(Trigger) ETROC2 BB CNM 1-3 HV210V OS:20\"]\n",
    "\n",
    "chip_labels= [\"1\",\"0\",\"3\"]\n",
    "\n",
    "today = datetime.date.today().isoformat()\n",
    "fig_outdir = Path('../../ETROC-figures')\n",
    "fig_outdir = fig_outdir / (today + '_Array_Test_Results')\n",
    "fig_outdir.mkdir(exist_ok=True)\n",
    "fig_path = str(fig_outdir)\n",
    "\n",
    "# path_pattern = f\"*2023-09-21_Array_Test_Results/SelfTrigger_bottom_Readout_topbottom_1\"\n",
    "path_pattern = f\"../../beamdata/SelfTrigger_ET2_CNM_BATCH_1_3_Readout_ET2_EPIR_BATCH1_1_ET2_W36_IP7_13_ET2_CNM_BATCH1_3_loop_*.pqt\"\n",
    "\n",
    "helper = etroc2_analysis_helper(chip_names=chip_names, chip_figtitles=chip_figtitles, chip_labels=chip_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(dpi=50, figsize=(5,5))\n",
    "gs = fig.add_gridspec(1,1)\n",
    "\n",
    "ax0 = fig.add_subplot(gs[0,0])\n",
    "ax0.plot([1, 0], [1, 0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(path_pattern)\n",
    "files = natsorted(files)\n",
    "\n",
    "dataframes = []\n",
    "\n",
    "cal_cut = [150, 250] # min, max\n",
    "toa_cut = [100, 500] # min, max\n",
    "tot_cut = [ 50, 300] # min, max\n",
    "\n",
    "for ifile in files:\n",
    "    tmp_df = pd.read_parquet(ifile)\n",
    "\n",
    "    ## Boundary values are included by default:\n",
    "    selected_df = tmp_df[tmp_df['cal'].between(cal_cut[0], cal_cut[1]) &\n",
    "                         tmp_df['toa'].between(toa_cut[0], toa_cut[1]) &\n",
    "                         tmp_df['tot'].between(tot_cut[0], tot_cut[1])]\n",
    "\n",
    "    selected_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    dataframes.append(selected_df)\n",
    "    del tmp_df, selected_df\n",
    "\n",
    "df = pd.concat(dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the DataFrame by 'evt' and count unique 'board' values in each group\n",
    "unique_board_counts = df.groupby('evt')['board'].nunique()\n",
    "\n",
    "## event has three unique board ID\n",
    "event_numbers_with_three_unique_boards = unique_board_counts[unique_board_counts == 3].index\n",
    "subset_df = df[df['evt'].isin(event_numbers_with_three_unique_boards)]\n",
    "subset_df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## event has one hit from each board\n",
    "event_board_counts = subset_df.groupby(['evt', 'board']).size().unstack(fill_value=0)\n",
    "selected_event_numbers = event_board_counts[(event_board_counts[0] == 1) & (event_board_counts[1] == 1) & (event_board_counts[3] == 1)].index\n",
    "selected_subset_df = subset_df[subset_df['evt'].isin(selected_event_numbers)]\n",
    "selected_subset_df.reset_index(inplace=True, drop=True)\n",
    "selected_subset_df\n",
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_subset_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_selection = helper.return_hist(selected_subset_df, chip_names, chip_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.make_pix_inclusive_plots(h_selection, chip_names[0], chip_fignames[0], chip_figtitles[0], fig_path, save=False, show=True, tag=\"inclusive\", title_tag=\", inclusive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_filter(group, board, row, col):\n",
    "    return any((group['board'] == board) & (group['row'] == row) & (group['col'] == col))\n",
    "\n",
    "def custom_filter(group):\n",
    "    return any((group['board'] == 1) & (group['row'] == 15) & (group['col'] == 6)) & \\\n",
    "            any((group['board'] == 0) & (group['row'] == 2) & (group['col'] == 6)) & \\\n",
    "            any((group['board'] == 3) & (group['row'] == 2) & (group['col'] == 5))\n",
    "\n",
    "def sort_filter(group):\n",
    "    return group.sort_values(by=['board'], ascending=True)\n",
    "\n",
    "def distance_filter(group, distance):\n",
    "    board0_row = group[(group[\"board\"] == 0)]\n",
    "    board3_row = group[(group[\"board\"] == 3)]\n",
    "    board0_col = group[(group[\"board\"] == 0)]\n",
    "    board3_col = group[(group[\"board\"] == 3)]\n",
    "\n",
    "    if not board0_row.empty and not board3_row.empty and not board0_col.empty and not board3_col.empty:\n",
    "        row_index_diff = abs(board0_row[\"row\"].values[0] - board3_row[\"row\"].values[0])\n",
    "        col_index_diff = abs(board0_col[\"col\"].values[0] - board3_col[\"col\"].values[0])\n",
    "        return row_index_diff < distance and col_index_diff < distance\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_group = selected_subset_df.groupby('evt')\n",
    "filtered_simple_group = tmp_group.filter(simple_filter, board=1, row=15, col=6)\n",
    "filtered_simple_group.reset_index(inplace=True, drop=True)\n",
    "del tmp_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = filtered_simple_group.groupby('evt')\n",
    "sorted_filtered_simple_group = grouped.apply(sort_filter)\n",
    "sorted_filtered_simple_group.reset_index(inplace=True, drop=True)\n",
    "sorted_filtered_simple_group\n",
    "del grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = sorted_filtered_simple_group.groupby('evt')\n",
    "dis_simple_group = grouped.filter(distance_filter, distance=2)\n",
    "dis_simple_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_group = dis_simple_group.groupby(['board', 'row', 'col'])\n",
    "test = test_group.size().reset_index(name='count')\n",
    "test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del filtered_simple_group,sorted_filtered_simple_group,grouped,dis_simple_group,test_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_group = selected_subset_df.groupby('evt')\n",
    "filtered_group = tmp_group.filter(custom_filter)\n",
    "filtered_group.reset_index(inplace=True, drop=True)\n",
    "filtered_group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert TDC code to TDC time in [ns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_df = filtered_group\n",
    "\n",
    "pix_rows = []\n",
    "pix_cols = []\n",
    "fit_params = []\n",
    "cal_means = {boardID:{} for boardID in chip_labels}\n",
    "\n",
    "for boardID in chip_labels:\n",
    "    groups = selected_df[selected_df['board'] == int(boardID)].groupby(['row', 'col'])\n",
    "    for (row, col), group in groups:\n",
    "        \n",
    "        cal_mean = group['cal'].mean()\n",
    "        cal_means[boardID][(row, col)] = cal_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_based_group = selected_df.groupby('evt')\n",
    "\n",
    "d = []\n",
    "\n",
    "for key, data in event_based_group:\n",
    "\n",
    "    sorted_group = sort_filter(data)\n",
    "    toa_in_time_b0 = 12.5 - (sorted_group[sorted_group['board'] == 0]['toa'] * (3.125/cal_means[\"0\"][(2, 6)]))\n",
    "    toa_in_time_b1 = 12.5 - (sorted_group[sorted_group['board'] == 1]['toa'] * (3.125/cal_means[\"1\"][(15, 6)]))\n",
    "    toa_in_time_b3 = 12.5 - (sorted_group[sorted_group['board'] == 3]['toa'] * (3.125/cal_means[\"3\"][(2, 5)]))\n",
    "\n",
    "    tot_in_time_b0 = (2*sorted_group[sorted_group['board'] == 0]['tot'] - np.floor(sorted_group[sorted_group['board'] == 0]['tot']/32)) * (3.125/cal_means[\"0\"][(2, 6)])\n",
    "    tot_in_time_b1 = (2*sorted_group[sorted_group['board'] == 1]['tot'] - np.floor(sorted_group[sorted_group['board'] == 1]['tot']/32)) * (3.125/cal_means[\"1\"][(15, 6)])\n",
    "    tot_in_time_b3 = (2*sorted_group[sorted_group['board'] == 3]['tot'] - np.floor(sorted_group[sorted_group['board'] == 3]['tot']/32)) * (3.125/cal_means[\"3\"][(2, 5)])\n",
    "\n",
    "    d.append(\n",
    "        {\n",
    "        'evt': key,\n",
    "        'toa_b0': toa_in_time_b0.values.squeeze(),\n",
    "        'tot_b0': tot_in_time_b0.values.squeeze(),\n",
    "        'toa_b1': toa_in_time_b1.values.squeeze(),\n",
    "        'tot_b1': tot_in_time_b1.values.squeeze(),\n",
    "        'toa_b3': toa_in_time_b3.values.squeeze(),\n",
    "        'tot_b3': tot_in_time_b3.values.squeeze(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "df_in_time = pd.DataFrame(d)\n",
    "\n",
    "# Change the data type of the 'evt' column to integer\n",
    "df_in_time['evt'] = df_in_time['evt'].astype(int)\n",
    "\n",
    "# Change the data type of the other columns to float\n",
    "float_columns = ['toa_b0', 'tot_b0', 'toa_b1', 'tot_b1', 'toa_b3', 'tot_b3']\n",
    "df_in_time[float_columns] = df_in_time[float_columns].astype(float)\n",
    "\n",
    "del d, selected_df\n",
    "df_in_time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traditional Time Walk Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_toa_b0 = (0.5*(df_in_time['toa_b1'] + df_in_time['toa_b3']) - df_in_time['toa_b0']).values\n",
    "del_toa_b1 = (0.5*(df_in_time['toa_b0'] + df_in_time['toa_b3']) - df_in_time['toa_b1']).values\n",
    "del_toa_b3 = (0.5*(df_in_time['toa_b0'] + df_in_time['toa_b1']) - df_in_time['toa_b3']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff_b0 = np.polyfit(df_in_time['tot_b0'].values, del_toa_b0, 3)\n",
    "poly_func_b0 = np.poly1d(coeff_b0)\n",
    "\n",
    "coeff_b1 = np.polyfit(df_in_time['tot_b1'].values, del_toa_b1, 3)\n",
    "poly_func_b1 = np.poly1d(coeff_b1)\n",
    "\n",
    "coeff_b3 = np.polyfit(df_in_time['tot_b3'].values, del_toa_b3, 3)\n",
    "poly_func_b3 = np.poly1d(coeff_b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplhep as hep\n",
    "plt.style.use(hep.style.CMS)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "hep.cms.text(loc=0, ax=axes[0], text=\"Preliminary\", fontsize=25)\n",
    "axes[0].set_title(f'Board 0 Time Walk Correction', loc=\"right\", size=25)\n",
    "axes[0].scatter(df_in_time['tot_b0'].values,  del_toa_b0, label='data')\n",
    "axes[0].plot(df_in_time['tot_b0'].values, poly_func_b0(df_in_time['tot_b0'].values), 'r.', label='fit')\n",
    "axes[0].set_xlabel('TOT time [ns]')\n",
    "axes[0].set_ylabel(r'$(TOA_{i} + TOA_{j})/2 - TOA$ [ns]' )\n",
    "axes[0].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[1], text=\"Preliminary\", fontsize=25)\n",
    "axes[1].set_title(f'Board 1 Time Walk Correction', loc=\"right\", size=25)\n",
    "axes[1].scatter(df_in_time['tot_b1'].values,  del_toa_b1, label='data')\n",
    "axes[1].plot(df_in_time['tot_b1'].values, poly_func_b1(df_in_time['tot_b1'].values), 'r.', label='fit')\n",
    "axes[1].set_xlabel('TOT time [ns]')\n",
    "axes[1].set_ylabel(r'$(TOA_{i} + TOA_{j})/2 - TOA$ [ns]')\n",
    "axes[1].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[2], text=\"Preliminary\", fontsize=25)\n",
    "axes[2].set_title(f'Board 3 Time Walk Correction', loc=\"right\", size=25)\n",
    "axes[2].scatter(df_in_time['tot_b3'].values,  del_toa_b3, label='data')\n",
    "axes[2].plot(df_in_time['tot_b3'].values, poly_func_b3(df_in_time['tot_b3'].values), 'r.', label='fit')\n",
    "axes[2].set_xlabel('TOT time [ns]')\n",
    "axes[2].set_ylabel(r'$(TOA_{i} + TOA_{j})/2 - TOA$ [ns]')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_b0 = df_in_time['toa_b0'].values + poly_func_b0(df_in_time['tot_b0'].values)\n",
    "diff_b1 = df_in_time['toa_b1'].values + poly_func_b1(df_in_time['tot_b1'].values)\n",
    "diff_b3 = df_in_time['toa_b3'].values + poly_func_b3(df_in_time['tot_b3'].values)\n",
    "\n",
    "# Define the Gaussian function\n",
    "def Gauss(x, a, mu, sig):\n",
    "    y = a*np.exp(-1*(1/(2*sig**2))*(x-mu)**2)\n",
    "    return y\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "hep.cms.text(loc=0, ax=axes[0], text=\"Preliminary\", fontsize=25)\n",
    "axes[0].set_title(f'Board 0 Time Walk Correction', loc=\"right\", size=25)\n",
    "\n",
    "# bins, edges = np.histogram(diff_b0, range=(-1,1), bins=50, density=True)\n",
    "# centers = 0.5*(edges[1:]+edges[:-1])\n",
    "# popt, _ = curve_fit(Gauss, centers, bins)\n",
    "\n",
    "axes[0].hist(diff_b0, bins=25, density=True, label='')\n",
    "# axes[0].plot(np.linspace(-1,1,500), Gauss(np.linspace(-1,1,500), *popt), 'r-', label=fr'$\\mu:{popt[1]:.3f}, \\sigma: {abs(popt[2]):.3f}$')\n",
    "axes[0].set_xlabel('Time Walk Corrected TOA [ns]')\n",
    "axes[0].set_ylabel('Arbitrary Units')\n",
    "# axes[0].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[1], text=\"Preliminary\", fontsize=25)\n",
    "axes[1].set_title(f'Board 1 Time Walk Correction', loc=\"right\", size=25)\n",
    "\n",
    "# bins, edges = np.histogram(diff_b1, range=(-1,1), bins=50, density=True)\n",
    "# centers = 0.5*(edges[1:]+edges[:-1])\n",
    "# popt, _ = curve_fit(Gauss, centers, bins)\n",
    "\n",
    "axes[1].hist(diff_b1, bins=25, density=True, label='')\n",
    "# axes[1].plot(np.linspace(-1,1,500), Gauss(np.linspace(-1,1,500), *popt), 'r-', label=fr'$\\mu:{popt[1]:.3f}, \\sigma: {abs(popt[2]):.3f}$')\n",
    "axes[1].set_xlabel('Time Walk Corrected TOA [ns]')\n",
    "axes[1].set_ylabel('Arbitrary Units')\n",
    "# axes[1].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[2], text=\"Preliminary\", fontsize=25)\n",
    "axes[2].set_title(f'Board 3 Time Walk Correction', loc=\"right\", size=25)\n",
    "\n",
    "# bins, edges = np.histogram(diff_b3, range=(-1,1), bins=50, density=True)\n",
    "# centers = 0.5*(edges[1:]+edges[:-1])\n",
    "# popt, _ = curve_fit(Gauss, centers, bins)\n",
    "\n",
    "axes[2].hist(diff_b3, bins=25, density=True, label='')\n",
    "# axes[2].plot(np.linspace(-1,1,500), Gauss(np.linspace(-1,1,500), *popt), 'r-', label=fr'$\\mu:{popt[1]:.3f}, \\sigma: {abs(popt[2]):.3f}$')\n",
    "axes[2].set_xlabel('Time Walk Corrected TOA [ns]')\n",
    "axes[2].set_ylabel('Arbitrary Units')\n",
    "# axes[2].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_b01 = diff_b0 - diff_b1\n",
    "diff_b03 = diff_b0 - diff_b3\n",
    "diff_b13 = diff_b1 - diff_b3\n",
    "\n",
    "fit_params = []\n",
    "\n",
    "# Define the Gaussian function\n",
    "def Gauss(x, a, mu, sig):\n",
    "    y = a*np.exp(-1*(1/(2*sig**2))*(x-mu)**2)\n",
    "    return y\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "hep.cms.text(loc=0, ax=axes[0], text=\"Preliminary\", fontsize=25)\n",
    "axes[0].set_title(f'Board 0 - Board 1', loc=\"right\", size=25)\n",
    "\n",
    "bins, edges = np.histogram(diff_b01, range=(-1,1), bins=50, density=True)\n",
    "centers = 0.5*(edges[1:]+edges[:-1])\n",
    "popt, _ = curve_fit(Gauss, centers, bins)\n",
    "fit_params.append(popt)\n",
    "\n",
    "axes[0].hist(diff_b01, range=(-1,1), bins=50, density=True, label='')\n",
    "axes[0].plot(np.linspace(-1,1,500), Gauss(np.linspace(-1,1,500), *popt), 'r-', label=fr'$\\mu:{popt[1]:.3f}, \\sigma: {abs(popt[2]):.3f}$')\n",
    "axes[0].set_xlabel(r'Time Walk Corrected $\\Delta$TOA [ns]')\n",
    "axes[0].set_ylabel('Arbitrary Units')\n",
    "axes[0].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[1], text=\"Preliminary\", fontsize=25)\n",
    "axes[1].set_title(f'Board 0 - Board 3', loc=\"right\", size=25)\n",
    "\n",
    "bins, edges = np.histogram(diff_b03, range=(-1,1), bins=50, density=True)\n",
    "centers = 0.5*(edges[1:]+edges[:-1])\n",
    "popt, _ = curve_fit(Gauss, centers, bins)\n",
    "fit_params.append(popt)\n",
    "\n",
    "axes[1].hist(diff_b03, range=(-1,1), bins=50, density=True, label='')\n",
    "axes[1].plot(np.linspace(-1,1,500), Gauss(np.linspace(-1,1,500), *popt), 'r-', label=fr'$\\mu:{popt[1]:.3f}, \\sigma: {abs(popt[2]):.3f}$')\n",
    "axes[1].set_xlabel(r'Time Walk Corrected $\\Delta$TOA [ns]')\n",
    "axes[1].set_ylabel('Arbitrary Units')\n",
    "axes[1].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[2], text=\"Preliminary\", fontsize=25)\n",
    "axes[2].set_title(f'Board 1 - Board 3', loc=\"right\", size=25)\n",
    "\n",
    "bins, edges = np.histogram(diff_b13, range=(-1,1), bins=50, density=True)\n",
    "centers = 0.5*(edges[1:]+edges[:-1])\n",
    "popt, _ = curve_fit(Gauss, centers, bins)\n",
    "fit_params.append(popt)\n",
    "\n",
    "axes[2].hist(diff_b13, range=(-1,1), bins=50, density=True, label='')\n",
    "axes[2].plot(np.linspace(-1,1,500), Gauss(np.linspace(-1,1,500), *popt), 'r-', label=fr'$\\mu:{popt[1]:.3f}, \\sigma: {abs(popt[2]):.3f}$')\n",
    "axes[2].set_xlabel(r'Time Walk Corrected $\\Delta$TOA [ns]')\n",
    "axes[2].set_ylabel('Arbitrary Units')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_resol_b0 = np.sqrt(0.5)*(np.sqrt(fit_params[0][2]**2 + fit_params[1][2]**2 - fit_params[2][2]**2))\n",
    "time_resol_b0*1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_resol_b1 = np.sqrt(0.5)*(np.sqrt(fit_params[2][2]**2 + fit_params[0][2]**2 - fit_params[1][2]**2))\n",
    "time_resol_b1*1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_resol_b3 = np.sqrt(0.5)*(np.sqrt(fit_params[2][2]**2 + fit_params[1][2]**2 - fit_params[0][2]**2))\n",
    "time_resol_b3*1e3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Time Walk Correction -  Pairwise Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dense_model(numpars=2, print_summary=False):\n",
    "    input  = Input(shape=(numpars,), name='input')\n",
    "    dense1 = Dense(8, activation='relu', name='dense1',kernel_initializer=initializers.RandomNormal(),bias_initializer=initializers.Zeros())(input)\n",
    "    output = Dense(1, activation='linear', name='output',kernel_initializer=initializers.RandomNormal(),bias_initializer=initializers.Zeros())(dense1)\n",
    "    model  = Model(inputs=[input], outputs=output, name=\"simple_dense_NN\")\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    if(print_summary): print(model.summary())\n",
    "    return model\n",
    "model = return_dense_model(print_summary=True)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params_NN = []\n",
    "fit_errors_NN = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_training = False\n",
    "if(do_training):\n",
    "    for en_idx in range(ensemble_count):\n",
    "        model_b01 = return_dense_model(numpars=2)\n",
    "        checkpointer = ModelCheckpoint(f'models/sep27_weights_{en_idx}_b01.hdf5', verbose=0, save_best_only=True,monitor=\"val_loss\")\n",
    "        term = tf.keras.callbacks.TerminateOnNaN()\n",
    "        escb = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, verbose=0)\n",
    "        history_b01 = model_b01.fit(\n",
    "            df_in_time[['tot_b0', 'tot_b1']].values, \n",
    "            (df_in_time['toa_b0']-df_in_time['toa_b1']).values, \n",
    "            validation_split=0.4, \n",
    "            epochs=150,\n",
    "            callbacks=[checkpointer,term,escb],\n",
    "            verbose=0)\n",
    "        del model_b01\n",
    "        \n",
    "        #plot the loss and validation loss of the dataset\n",
    "        fig, ax = plt.subplots(figsize=(15, 10), dpi=50)\n",
    "        hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "        ax.set_title(f'Model {en_idx}, TWC: Board 0 - Board 1', loc=\"right\", size=25)\n",
    "        plt.plot(history_b01.history['loss'], label='mse')\n",
    "        plt.plot(history_b01.history['val_loss'], label='val_mse')\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"models/\"+f\"sep27_weights_{en_idx}_b01_loss\"+\".png\")\n",
    "        plt.show()\n",
    "\n",
    "model_b01 = return_dense_model(numpars=2)\n",
    "for en_idx in range(ensemble_count):\n",
    "    model_b01.load_weights(f'models/sep27_weights_{en_idx}_b01.hdf5')\n",
    "    if(en_idx==0): Y_pred = model_b01.predict(df_in_time[['tot_b0', 'tot_b1']].values, verbose=0).flatten()\n",
    "    else: Y_pred += model_b01.predict(df_in_time[['tot_b0', 'tot_b1']].values, verbose=0).flatten()\n",
    "del model_b01\n",
    "Y_pred = Y_pred/ensemble_count\n",
    "  \n",
    "data_b01 = (df_in_time['toa_b0']-df_in_time['toa_b1']).values-Y_pred\n",
    "\n",
    "time_hist = hist.Hist(hist.axis.Regular(50, -.5, .5, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "time_hist.fill(data_b01)\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "grid = fig.add_gridspec(2, 1, hspace=0, height_ratios=[3, 1])\n",
    "main_ax = fig.add_subplot(grid[0])\n",
    "subplot_ax = fig.add_subplot(grid[1], sharex=main_ax)\n",
    "plt.setp(main_ax.get_xticklabels(), visible=False)\n",
    "main_ax_artists, sublot_ax_arists = time_hist.plot_pull(\n",
    "    \"normal\",\n",
    "    eb_ecolor=\"steelblue\",\n",
    "    eb_mfc=\"steelblue\",\n",
    "    eb_mec=\"steelblue\",\n",
    "    eb_fmt=\"o\",\n",
    "    eb_ms=6,\n",
    "    eb_capsize=1,\n",
    "    eb_capthick=2,\n",
    "    eb_alpha=0.8,\n",
    "    fp_c=\"hotpink\",\n",
    "    fp_ls=\"-\",\n",
    "    fp_lw=2,\n",
    "    fp_alpha=0.8,\n",
    "    bar_fc=\"royalblue\",\n",
    "    pp_num=3,\n",
    "    pp_fc=\"royalblue\",\n",
    "    pp_alpha=0.618,\n",
    "    pp_ec=None,\n",
    "    ub_alpha=0.2,\n",
    "    fit_fmt= r\"{name} = {value:.4g} $\\pm$ {error:.4g}\",\n",
    "    ax_dict= {\"main_ax\":main_ax,\"pull_ax\":subplot_ax},\n",
    ")\n",
    "hep.cms.text(loc=0, ax=main_ax, text=\"Preliminary\", fontsize=25)\n",
    "main_ax.set_title(f'Board 0 - Board 1', loc=\"right\", size=25)\n",
    "plt.show()\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(10, 10))\n",
    "# hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "# ax.set_title(f'Board 0 - Board 1', loc=\"right\", size=25)\n",
    "\n",
    "# bins, edges = np.histogram(data_b01, range=(-1,1), bins=50, density=False)\n",
    "# centers = 0.5*(edges[1:]+edges[:-1])\n",
    "# popt, pcov = curve_fit(Gauss, centers, bins)\n",
    "# fit_params_NN.append(popt)\n",
    "# fit_errors_NN.append(np.sqrt(np.diagonal(pcov)))\n",
    "# print(popt)\n",
    "# print(pcov)\n",
    "\n",
    "# ax.hist(data_b01, range=(-1,1), bins=50, density=False, label='')\n",
    "# ax.plot(np.linspace(-1,1,500), Gauss(np.linspace(-1,1,500), *popt), 'r-', label=fr'$\\mu:{popt[1]:.3f}\\pm{np.sqrt(pcov[1,1]):.3f}$')\n",
    "# ax.plot(np.NaN, np.NaN, '-', color='none', label=fr'$\\sigma:{abs(popt[2]):.3f}\\pm{np.sqrt(pcov[2,2]):.3f}$')\n",
    "# ax.set_xlabel(r'Time Walk Corrected $\\Delta$TOA [ns]')\n",
    "# ax.set_ylabel('Arbitrary Units')\n",
    "# ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params_NN.append([375.5, 0.003298, 0.1107])\n",
    "fit_errors_NN.append([6.529, 0.001536, 0.001164])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_training = False\n",
    "if(do_training):\n",
    "    for en_idx in range(ensemble_count):\n",
    "        model_b03 = return_dense_model(numpars=2)\n",
    "        checkpointer = ModelCheckpoint(f'models/sep27_weights_{en_idx}_b03.hdf5', verbose=0, save_best_only=True,monitor=\"val_loss\")\n",
    "        term = tf.keras.callbacks.TerminateOnNaN()\n",
    "        escb = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, verbose=0)\n",
    "        history_b03 = model_b03.fit(\n",
    "            df_in_time[['tot_b0', 'tot_b3']].values, \n",
    "            (df_in_time['toa_b0']-df_in_time['toa_b3']).values, \n",
    "            validation_split=0.3, \n",
    "            epochs=150,\n",
    "            callbacks=[checkpointer,term,escb],\n",
    "            verbose=0)\n",
    "        del model_b03\n",
    "        \n",
    "        #plot the loss and validation loss of the dataset\n",
    "        fig, ax = plt.subplots(figsize=(15, 10), dpi=50)\n",
    "        hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "        ax.set_title(f'Model {en_idx}, TWC: Board 0 - Board 3', loc=\"right\", size=25)\n",
    "        plt.plot(history_b03.history['loss'], label='mse')\n",
    "        plt.plot(history_b03.history['val_loss'], label='val_mse')\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"models/\"+f\"sep27_weights_{en_idx}_b03_loss\"+\".png\")\n",
    "        plt.show()\n",
    "\n",
    "model_b03 = return_dense_model(numpars=2)\n",
    "for en_idx in range(ensemble_count):\n",
    "    model_b03.load_weights(f'models/sep27_weights_{en_idx}_b03.hdf5')\n",
    "    if(en_idx==0): Y_pred = model_b03.predict(df_in_time[['tot_b0', 'tot_b3']].values, verbose=0).flatten()\n",
    "    else: Y_pred += model_b03.predict(df_in_time[['tot_b0', 'tot_b3']].values, verbose=0).flatten()\n",
    "del model_b03\n",
    "Y_pred = Y_pred/ensemble_count\n",
    "  \n",
    "data_b03 = (df_in_time['toa_b0']-df_in_time['toa_b3']).values-Y_pred\n",
    "\n",
    "time_hist = hist.Hist(hist.axis.Regular(50, -.5, .5, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "time_hist.fill(data_b03)\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "grid = fig.add_gridspec(2, 1, hspace=0, height_ratios=[3, 1])\n",
    "main_ax = fig.add_subplot(grid[0])\n",
    "subplot_ax = fig.add_subplot(grid[1], sharex=main_ax)\n",
    "plt.setp(main_ax.get_xticklabels(), visible=False)\n",
    "main_ax_artists, sublot_ax_arists = time_hist.plot_pull(\n",
    "    \"normal\",\n",
    "    eb_ecolor=\"steelblue\",\n",
    "    eb_mfc=\"steelblue\",\n",
    "    eb_mec=\"steelblue\",\n",
    "    eb_fmt=\"o\",\n",
    "    eb_ms=6,\n",
    "    eb_capsize=1,\n",
    "    eb_capthick=2,\n",
    "    eb_alpha=0.8,\n",
    "    fp_c=\"hotpink\",\n",
    "    fp_ls=\"-\",\n",
    "    fp_lw=2,\n",
    "    fp_alpha=0.8,\n",
    "    bar_fc=\"royalblue\",\n",
    "    pp_num=3,\n",
    "    pp_fc=\"royalblue\",\n",
    "    pp_alpha=0.618,\n",
    "    pp_ec=None,\n",
    "    ub_alpha=0.2,\n",
    "    fit_fmt= r\"{name} = {value:.4g} $\\pm$ {error:.4g}\",\n",
    "    ax_dict= {\"main_ax\":main_ax,\"pull_ax\":subplot_ax},\n",
    ")\n",
    "hep.cms.text(loc=0, ax=main_ax, text=\"Preliminary\", fontsize=25)\n",
    "main_ax.set_title(f'Board 0 - Board 3', loc=\"right\", size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params_NN.append([412.9, -0.001502, 0.1])\n",
    "fit_errors_NN.append([7.247, 0.00139, 0.001072])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_training = False\n",
    "if(do_training):\n",
    "    for en_idx in range(ensemble_count):\n",
    "        model_b13 = return_dense_model(numpars=2)\n",
    "        checkpointer = ModelCheckpoint(f'models/sep27_weights_{en_idx}_b13.hdf5', verbose=0, save_best_only=True,monitor=\"val_loss\")\n",
    "        term = tf.keras.callbacks.TerminateOnNaN()\n",
    "        escb = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, verbose=0)\n",
    "        history_b13 = model_b13.fit(\n",
    "            df_in_time[['tot_b1', 'tot_b3']].values, \n",
    "            (df_in_time['toa_b1']-df_in_time['toa_b3']).values, \n",
    "            validation_split=0.3, \n",
    "            epochs=150,\n",
    "            callbacks=[checkpointer,term,escb],\n",
    "            verbose=0)\n",
    "        del model_b13\n",
    "        \n",
    "        #plot the loss and validation loss of the dataset\n",
    "        fig, ax = plt.subplots(figsize=(15, 10), dpi=50)\n",
    "        hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "        ax.set_title(f'Model {en_idx}, TWC: Board 1 - Board 3', loc=\"right\", size=25)\n",
    "        plt.plot(history_b03.history['loss'], label='mse')\n",
    "        plt.plot(history_b03.history['val_loss'], label='val_mse')\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"models/\"+f\"sep27_weights_{en_idx}_b13_loss\"+\".png\")\n",
    "        plt.show()\n",
    "\n",
    "model_b13 = return_dense_model(numpars=2)\n",
    "for en_idx in range(ensemble_count):\n",
    "    model_b13.load_weights(f'models/sep27_weights_{en_idx}_b13.hdf5')\n",
    "    if(en_idx==0): Y_pred = model_b13.predict(df_in_time[['tot_b1', 'tot_b3']].values, verbose=0).flatten()\n",
    "    else: Y_pred += model_b13.predict(df_in_time[['tot_b1', 'tot_b3']].values, verbose=0).flatten()\n",
    "del model_b13\n",
    "Y_pred = Y_pred/ensemble_count\n",
    "  \n",
    "data_b13 = (df_in_time['toa_b1']-df_in_time['toa_b3']).values-Y_pred\n",
    "\n",
    "time_hist = hist.Hist(hist.axis.Regular(50, -.5, .5, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "time_hist.fill(data_b13)\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "grid = fig.add_gridspec(2, 1, hspace=0, height_ratios=[3, 1])\n",
    "main_ax = fig.add_subplot(grid[0])\n",
    "subplot_ax = fig.add_subplot(grid[1], sharex=main_ax)\n",
    "plt.setp(main_ax.get_xticklabels(), visible=False)\n",
    "main_ax_artists, sublot_ax_arists = time_hist.plot_pull(\n",
    "    \"normal\",\n",
    "    eb_ecolor=\"steelblue\",\n",
    "    eb_mfc=\"steelblue\",\n",
    "    eb_mec=\"steelblue\",\n",
    "    eb_fmt=\"o\",\n",
    "    eb_ms=6,\n",
    "    eb_capsize=1,\n",
    "    eb_capthick=2,\n",
    "    eb_alpha=0.8,\n",
    "    fp_c=\"hotpink\",\n",
    "    fp_ls=\"-\",\n",
    "    fp_lw=2,\n",
    "    fp_alpha=0.8,\n",
    "    bar_fc=\"royalblue\",\n",
    "    pp_num=3,\n",
    "    pp_fc=\"royalblue\",\n",
    "    pp_alpha=0.618,\n",
    "    pp_ec=None,\n",
    "    ub_alpha=0.2,\n",
    "    fit_fmt= r\"{name} = {value:.4g} $\\pm$ {error:.4g}\",\n",
    "    ax_dict= {\"main_ax\":main_ax,\"pull_ax\":subplot_ax},\n",
    ")\n",
    "hep.cms.text(loc=0, ax=main_ax, text=\"Preliminary\", fontsize=25)\n",
    "main_ax.set_title(f'Board 1 - Board 3', loc=\"right\", size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params_NN.append([461.2, -0.00941, 0.09088])\n",
    "fit_errors_NN.append([7.834, 0.001256, 0.0009008])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_resolution_ps(sig_a, err_a, sig_b, err_b, sig_c, err_c):\n",
    "    res = np.sqrt(0.5)*(np.sqrt(sig_a**2 + sig_b**2 - sig_c**2))\n",
    "    var_res = (1/4)*(1/res**2)*(((sig_a**2)*(err_a**2))+((sig_b**2)*(err_b**2))+((sig_c**2)*(err_c**2)))\n",
    "    return res*1e3, np.sqrt(var_res)*1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_b3,err_b3 = return_resolution_ps(fit_params_NN[1][2], fit_errors_NN[1][2], \n",
    "                                     fit_params_NN[2][2], fit_errors_NN[2][2], \n",
    "                                     fit_params_NN[0][2], fit_errors_NN[0][2])\n",
    "print(res_b3,err_b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_b1,err_b1 = return_resolution_ps(fit_params_NN[0][2], fit_errors_NN[0][2], \n",
    "                                     fit_params_NN[2][2], fit_errors_NN[2][2], \n",
    "                                     fit_params_NN[1][2], fit_errors_NN[1][2])\n",
    "print(res_b1,err_b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_b0,err_b0 = return_resolution_ps(fit_params_NN[0][2], fit_errors_NN[0][2], \n",
    "                                     fit_params_NN[1][2], fit_errors_NN[1][2], \n",
    "                                     fit_params_NN[2][2], fit_errors_NN[2][2])\n",
    "print(res_b0,err_b0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTWC Performance Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_b01 = return_dense_model(numpars=2)\n",
    "model_b03 = return_dense_model(numpars=2)\n",
    "model_b13 = return_dense_model(numpars=2)\n",
    "model_b01.load_weights(f'models/sep27_weights_{0}_b01.hdf5')\n",
    "nn_del_b01 = model_b01.predict(df_in_time[['tot_b0', 'tot_b1']].values, verbose=0).flatten()\n",
    "model_b03.load_weights(f'models/sep27_weights_{0}_b03.hdf5')\n",
    "nn_del_b03 = model_b03.predict(df_in_time[['tot_b0', 'tot_b3']].values, verbose=0).flatten()\n",
    "model_b13.load_weights(f'models/sep27_weights_{0}_b13.hdf5')\n",
    "nn_del_b13 = model_b13.predict(df_in_time[['tot_b1', 'tot_b3']].values, verbose=0).flatten()\n",
    "for en_idx in range(1, ensemble_count):\n",
    "    model_b01.load_weights(f'models/sep27_weights_{en_idx}_b01.hdf5')\n",
    "    nn_del_b01 += model_b01.predict(df_in_time[['tot_b0', 'tot_b1']].values, verbose=0).flatten()\n",
    "    model_b03.load_weights(f'models/sep27_weights_{en_idx}_b03.hdf5')\n",
    "    nn_del_b03 += model_b03.predict(df_in_time[['tot_b0', 'tot_b3']].values, verbose=0).flatten()\n",
    "    model_b13.load_weights(f'models/sep27_weights_{en_idx}_b13.hdf5')\n",
    "    nn_del_b13 += model_b13.predict(df_in_time[['tot_b1', 'tot_b3']].values, verbose=0).flatten()\n",
    "nn_del_b01 = nn_del_b01/ensemble_count\n",
    "nn_del_b03 = nn_del_b03/ensemble_count\n",
    "nn_del_b13 = nn_del_b13/ensemble_count\n",
    "del model_b13,model_b01,model_b03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_b01 = stats.binned_statistic_2d(df_in_time['tot_b0'].values, df_in_time['tot_b1'].values, \n",
    "                                    range=[[2,8],[4,8]], bins=(4,4),\n",
    "                                    values=(nn_del_b01-(df_in_time['toa_b0']-df_in_time['toa_b1']).values), \n",
    "                                    statistic='mean')\n",
    "res_b01 = stats.binned_statistic_2d(df_in_time['tot_b0'].values, df_in_time['tot_b1'].values, \n",
    "                                    range=[[2,8],[4,8]], bins=(4,4),\n",
    "                                    values=(nn_del_b01-(df_in_time['toa_b0']-df_in_time['toa_b1']).values), \n",
    "                                    statistic='std')\n",
    "plt.figure(dpi=50)\n",
    "plt.imshow(cls_b01.statistic.T, extent=[cls_b01.x_edge[0], cls_b01.x_edge[-1], cls_b01.y_edge[0], cls_b01.y_edge[-1]],\n",
    "           interpolation='nearest',aspect='auto',origin='lower')\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "plt.figure(dpi=50)\n",
    "plt.imshow(res_b01.statistic.T, extent=[res_b01.x_edge[0], res_b01.x_edge[-1], res_b01.y_edge[0], res_b01.y_edge[-1]],\n",
    "           interpolation='nearest',aspect='auto',origin='lower')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del nn_del_b01,nn_del_b03,nn_del_b13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make the traditional plots with the NN outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_b01 = return_dense_model(numpars=2)\n",
    "model_b03 = return_dense_model(numpars=2)\n",
    "model_b13 = return_dense_model(numpars=2)\n",
    "model_b01.load_weights(f'models/sep27_weights_{0}_b01.hdf5')\n",
    "nn_del_b01 = model_b01.predict(df_in_time[['tot_b0', 'tot_b1']].values, verbose=0).flatten()\n",
    "model_b03.load_weights(f'models/sep27_weights_{0}_b03.hdf5')\n",
    "nn_del_b03 = model_b03.predict(df_in_time[['tot_b0', 'tot_b3']].values, verbose=0).flatten()\n",
    "model_b13.load_weights(f'models/sep27_weights_{0}_b13.hdf5')\n",
    "nn_del_b13 = model_b13.predict(df_in_time[['tot_b1', 'tot_b3']].values, verbose=0).flatten()\n",
    "for en_idx in range(1, ensemble_count):\n",
    "    model_b01.load_weights(f'models/sep27_weights_{en_idx}_b01.hdf5')\n",
    "    nn_del_b01 += model_b01.predict(df_in_time[['tot_b0', 'tot_b1']].values, verbose=0).flatten()\n",
    "    model_b03.load_weights(f'models/sep27_weights_{en_idx}_b03.hdf5')\n",
    "    nn_del_b03 += model_b03.predict(df_in_time[['tot_b0', 'tot_b3']].values, verbose=0).flatten()\n",
    "    model_b13.load_weights(f'models/sep27_weights_{en_idx}_b13.hdf5')\n",
    "    nn_del_b13 += model_b13.predict(df_in_time[['tot_b1', 'tot_b3']].values, verbose=0).flatten()\n",
    "nn_del_b01 = nn_del_b01/ensemble_count\n",
    "nn_del_b03 = nn_del_b03/ensemble_count\n",
    "nn_del_b13 = nn_del_b13/ensemble_count\n",
    "del model_b13,model_b01,model_b03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "hep.cms.text(loc=0, ax=axes[0], text=\"Preliminary\", fontsize=25)\n",
    "axes[0].set_title(f'Board 0 Time Walk Correction NN', loc=\"right\", size=25)\n",
    "axes[0].scatter(df_in_time['tot_b0'].values,  del_toa_b0, label='data')\n",
    "axes[0].plot(df_in_time['tot_b0'].values, -0.5*(nn_del_b01+nn_del_b03), 'r.', label='Neural Network')\n",
    "axes[0].set_xlabel('TOT time [ns]')\n",
    "axes[0].set_ylabel(r'$(TOA_{i} + TOA_{j})/2 - TOA$ [ns]' )\n",
    "axes[0].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[1], text=\"Preliminary\", fontsize=25)\n",
    "axes[1].set_title(f'Board 1 Time Walk Correction NN', loc=\"right\", size=25)\n",
    "axes[1].scatter(df_in_time['tot_b1'].values,  del_toa_b1, label='data')\n",
    "axes[1].plot(df_in_time['tot_b1'].values, 0.5*(nn_del_b01-nn_del_b13), 'r.', label='Neural Network')\n",
    "axes[1].set_xlabel('TOT time [ns]')\n",
    "axes[1].set_ylabel(r'$(TOA_{i} + TOA_{j})/2 - TOA$ [ns]')\n",
    "axes[1].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[2], text=\"Preliminary\", fontsize=25)\n",
    "axes[2].set_title(f'Board 3 Time Walk Correction NN', loc=\"right\", size=25)\n",
    "axes[2].scatter(df_in_time['tot_b3'].values,  del_toa_b3, label='data')\n",
    "axes[2].plot(df_in_time['tot_b3'].values, 0.5*(nn_del_b03+nn_del_b13), 'r.', label='Neural Network')\n",
    "axes[2].set_xlabel('TOT time [ns]')\n",
    "axes[2].set_ylabel(r'$(TOA_{i} + TOA_{j})/2 - TOA$ [ns]')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_b0_nn = df_in_time['toa_b0'].values - 0.5*(nn_del_b01+nn_del_b03)\n",
    "diff_b1_nn = df_in_time['toa_b1'].values + 0.5*(nn_del_b01-nn_del_b13)\n",
    "diff_b3_nn = df_in_time['toa_b3'].values + 0.5*(nn_del_b03+nn_del_b13)\n",
    "\n",
    "diff_b01_nn = diff_b0_nn - diff_b1_nn\n",
    "diff_b03_nn = diff_b0_nn - diff_b3_nn\n",
    "diff_b13_nn = diff_b1_nn - diff_b3_nn\n",
    "\n",
    "fit_params = []\n",
    "\n",
    "# Define the Gaussian function\n",
    "def Gauss(x, a, mu, sig):\n",
    "    y = a*np.exp(-1*(1/(2*sig**2))*(x-mu)**2)\n",
    "    return y\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(30, 10))\n",
    "hep.cms.text(loc=0, ax=axes[0], text=\"Preliminary\", fontsize=25)\n",
    "axes[0].set_title(f'Board 0 Time Walk Correction', loc=\"right\", size=25)\n",
    "\n",
    "bins, edges = np.histogram(diff_b01_nn, range=(-1,1), bins=50, density=True)\n",
    "centers = 0.5*(edges[1:]+edges[:-1])\n",
    "popt, _ = curve_fit(Gauss, centers, bins)\n",
    "fit_params.append(popt)\n",
    "\n",
    "axes[0].hist(diff_b01_nn, range=(-1,1), bins=50, density=True, label='')\n",
    "axes[0].plot(np.linspace(-1,1,500), Gauss(np.linspace(-1,1,500), *popt), 'r-', label=fr'$\\mu:{popt[1]:.3f}, \\sigma: {abs(popt[2]):.3f}$')\n",
    "axes[0].set_xlabel(r'Time Walk Corrected $\\Delta$TOA [ns]')\n",
    "axes[0].set_ylabel('Arbitrary Units')\n",
    "axes[0].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[1], text=\"Preliminary\", fontsize=25)\n",
    "axes[1].set_title(f'Board 1 Time Walk Correction', loc=\"right\", size=25)\n",
    "\n",
    "bins, edges = np.histogram(diff_b03_nn, range=(-1,1), bins=50, density=True)\n",
    "centers = 0.5*(edges[1:]+edges[:-1])\n",
    "popt, _ = curve_fit(Gauss, centers, bins)\n",
    "fit_params.append(popt)\n",
    "\n",
    "axes[1].hist(diff_b03_nn, range=(-1,1), bins=50, density=True, label='')\n",
    "axes[1].plot(np.linspace(-1,1,500), Gauss(np.linspace(-1,1,500), *popt), 'r-', label=fr'$\\mu:{popt[1]:.3f}, \\sigma: {abs(popt[2]):.3f}$')\n",
    "axes[1].set_xlabel(r'Time Walk Corrected $\\Delta$TOA [ns]')\n",
    "axes[1].set_ylabel('Arbitrary Units')\n",
    "axes[1].legend()\n",
    "\n",
    "hep.cms.text(loc=0, ax=axes[2], text=\"Preliminary\", fontsize=25)\n",
    "axes[2].set_title(f'Board 3 Time Walk Correction', loc=\"right\", size=25)\n",
    "\n",
    "bins, edges = np.histogram(diff_b13_nn, range=(-1,1), bins=50, density=True)\n",
    "centers = 0.5*(edges[1:]+edges[:-1])\n",
    "popt, _ = curve_fit(Gauss, centers, bins)\n",
    "fit_params.append(popt)\n",
    "\n",
    "axes[2].hist(diff_b13_nn, range=(-1,1), bins=50, density=True, label='')\n",
    "axes[2].plot(np.linspace(-1,1,500), Gauss(np.linspace(-1,1,500), *popt), 'r-', label=fr'$\\mu:{popt[1]:.3f}, \\sigma: {abs(popt[2]):.3f}$')\n",
    "axes[2].set_xlabel(r'Time Walk Corrected $\\Delta$TOA [ns]')\n",
    "axes[2].set_ylabel('Arbitrary Units')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_resol_b3 = np.sqrt(0.5)*(np.sqrt(fit_params[2][2]**2 + fit_params[1][2]**2 - fit_params[0][2]**2))\n",
    "time_resol_b3*1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_resol_b1 = np.sqrt(0.5)*(np.sqrt(fit_params[2][2]**2 + fit_params[0][2]**2 - fit_params[1][2]**2))\n",
    "time_resol_b1*1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_resol_b0 = np.sqrt(0.5)*(np.sqrt(fit_params[0][2]**2 + fit_params[1][2]**2 - fit_params[2][2]**2))\n",
    "time_resol_b0*1e3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Time Walk Correction -  Triple Input Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_big_dense_model(numpars=3, print_summary=False):\n",
    "    input  = Input(shape=(numpars,), name='input')\n",
    "    dense1 = Dense(8, activation='relu', name='dense1',kernel_initializer=initializers.RandomNormal(),bias_initializer=initializers.Zeros())(input)\n",
    "    dense2 = Dense(8, activation='relu', name='dense2',kernel_initializer=initializers.RandomNormal(),bias_initializer=initializers.Zeros())(dense1)\n",
    "    output = Dense(1, activation='linear', name='output',kernel_initializer=initializers.RandomNormal(),bias_initializer=initializers.Zeros())(dense2)\n",
    "    model  = Model(inputs=[input], outputs=output, name=\"big_dense_NN\")\n",
    "    model.compile(loss='mse', optimizer='adam')\n",
    "    if(print_summary): print(model.summary())\n",
    "    return model\n",
    "model = return_big_dense_model(print_summary=True)\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_count = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_training = False\n",
    "if(do_training):\n",
    "    for en_idx in range(ensemble_count):\n",
    "        model_b130 = return_big_dense_model(numpars=1)\n",
    "        checkpointer = ModelCheckpoint(f'models/sep28_weights_{en_idx}_b130.hdf5', verbose=0, save_best_only=True,monitor=\"val_loss\")\n",
    "        term = tf.keras.callbacks.TerminateOnNaN()\n",
    "        escb = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, verbose=0)\n",
    "        history_b130 = model_b130.fit(\n",
    "            df_in_time[['tot_b0']].values, \n",
    "            ((df_in_time['toa_b1']+df_in_time['toa_b3']).values/2.) - df_in_time['toa_b0'].values, \n",
    "            validation_split=0.4, \n",
    "            epochs=150,\n",
    "            callbacks=[checkpointer,term,escb],\n",
    "            verbose=0)\n",
    "        del model_b130\n",
    "        \n",
    "        #plot the loss and validation loss of the dataset\n",
    "        fig, ax = plt.subplots(figsize=(15, 10), dpi=50)\n",
    "        hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "        ax.set_title(f'Model {en_idx}, TWC: Board 0', loc=\"right\", size=25)\n",
    "        plt.plot(history_b130.history['loss'], label='mse')\n",
    "        plt.plot(history_b130.history['val_loss'], label='val_mse')\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"models/\"+f\"sep28_weights_{en_idx}_b130_loss\"+\".png\")\n",
    "        plt.show()\n",
    "\n",
    "model_b130 = return_big_dense_model(numpars=1)\n",
    "for en_idx in range(ensemble_count):\n",
    "    model_b130.load_weights(f'models/sep28_weights_{en_idx}_b130.hdf5')\n",
    "    if(en_idx==0): Y_pred = model_b130.predict(df_in_time[['tot_b0']].values, verbose=0).flatten()\n",
    "    else: Y_pred += model_b130.predict(df_in_time[['tot_b0']].values, verbose=0).flatten()\n",
    "del model_b130\n",
    "Y_pred = Y_pred/ensemble_count\n",
    "  \n",
    "data_b0 = df_in_time['toa_b0'].values + Y_pred\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "ax.set_title(f'Board 0 Time Walk Correction NN', loc=\"right\", size=25)\n",
    "ax.scatter(df_in_time['tot_b0'].values,  ((df_in_time['toa_b1']+df_in_time['toa_b3']).values/2.) - df_in_time['toa_b0'].values, label='data')\n",
    "ax.plot(df_in_time['tot_b0'].values, Y_pred, 'r.', label='Neural Network')\n",
    "ax.set_xlabel('TOT time [ns]')\n",
    "ax.set_ylabel(r'$(TOA_{1} + TOA_{3})/2 - TOA_0$ [ns]' )\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_training = True\n",
    "if(do_training):\n",
    "    for en_idx in range(ensemble_count):\n",
    "        model_b031 = return_big_dense_model(numpars=1)\n",
    "        checkpointer = ModelCheckpoint(f'models/sep28_weights_{en_idx}_b031.hdf5', verbose=0, save_best_only=True,monitor=\"val_loss\")\n",
    "        term = tf.keras.callbacks.TerminateOnNaN()\n",
    "        escb = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, verbose=0)\n",
    "        history_b031 = model_b031.fit(\n",
    "            df_in_time[['tot_b1']].values, \n",
    "            ((df_in_time['toa_b0']+df_in_time['toa_b3']).values/2.) - df_in_time['toa_b1'].values, \n",
    "            validation_split=0.4, \n",
    "            epochs=150,\n",
    "            callbacks=[checkpointer,term,escb],\n",
    "            verbose=0)\n",
    "        del model_b031\n",
    "        \n",
    "        #plot the loss and validation loss of the dataset\n",
    "        fig, ax = plt.subplots(figsize=(15, 10), dpi=50)\n",
    "        hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "        ax.set_title(f'Model {en_idx}, TWC: Board 1', loc=\"right\", size=25)\n",
    "        plt.plot(history_b031.history['loss'], label='mse')\n",
    "        plt.plot(history_b031.history['val_loss'], label='val_mse')\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"models/\"+f\"sep28_weights_{en_idx}_b031_loss\"+\".png\")\n",
    "        plt.show()\n",
    "\n",
    "model_b031 = return_big_dense_model(numpars=1)\n",
    "for en_idx in range(ensemble_count):\n",
    "    model_b031.load_weights(f'models/sep28_weights_{en_idx}_b031.hdf5')\n",
    "    if(en_idx==0): Y_pred = model_b031.predict(df_in_time[['tot_b1']].values, verbose=0).flatten()\n",
    "    else: Y_pred += model_b031.predict(df_in_time[['tot_b1']].values, verbose=0).flatten()\n",
    "del model_b031\n",
    "Y_pred = Y_pred/ensemble_count\n",
    "  \n",
    "data_b1 = df_in_time['toa_b1'].values + Y_pred\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "ax.set_title(f'Board 1 Time Walk Correction NN', loc=\"right\", size=25)\n",
    "ax.scatter(df_in_time['tot_b1'].values,  ((df_in_time['toa_b0']+df_in_time['toa_b3']).values/2.) - df_in_time['toa_b1'].values, label='data')\n",
    "ax.plot(df_in_time['tot_b1'].values, Y_pred, 'r.', label='Neural Network')\n",
    "ax.set_xlabel('TOT time [ns]')\n",
    "ax.set_ylabel(r'$(TOA_{0} + TOA_{3})/2 - TOA_1$ [ns]' )\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "do_training = True\n",
    "if(do_training):\n",
    "    for en_idx in range(ensemble_count):\n",
    "        model_b013 = return_big_dense_model(numpars=1)\n",
    "        checkpointer = ModelCheckpoint(f'models/sep28_weights_{en_idx}_b013.hdf5', verbose=0, save_best_only=True,monitor=\"val_loss\")\n",
    "        term = tf.keras.callbacks.TerminateOnNaN()\n",
    "        escb = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=15, verbose=0)\n",
    "        history_b013 = model_b013.fit(\n",
    "            df_in_time[['tot_b3']].values, \n",
    "            ((df_in_time['toa_b0']+df_in_time['toa_b1']).values/2.) - df_in_time['toa_b3'].values, \n",
    "            validation_split=0.4, \n",
    "            epochs=150,\n",
    "            callbacks=[checkpointer,term,escb],\n",
    "            verbose=0)\n",
    "        del model_b013\n",
    "        \n",
    "        #plot the loss and validation loss of the dataset\n",
    "        fig, ax = plt.subplots(figsize=(15, 10), dpi=50)\n",
    "        hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "        ax.set_title(f'Model {en_idx}, TWC: Board 3', loc=\"right\", size=25)\n",
    "        plt.plot(history_b013.history['loss'], label='mse')\n",
    "        plt.plot(history_b013.history['val_loss'], label='val_mse')\n",
    "        plt.yscale(\"log\")\n",
    "        plt.legend()\n",
    "        plt.savefig(\"models/\"+f\"sep28_weights_{en_idx}_b013_loss\"+\".png\")\n",
    "        plt.show()\n",
    "\n",
    "model_b013 = return_big_dense_model(numpars=1)\n",
    "for en_idx in range(ensemble_count):\n",
    "    model_b013.load_weights(f'models/sep28_weights_{en_idx}_b013.hdf5')\n",
    "    if(en_idx==0): Y_pred = model_b013.predict(df_in_time[['tot_b3']].values, verbose=0).flatten()\n",
    "    else: Y_pred += model_b013.predict(df_in_time[['tot_b3']].values, verbose=0).flatten()\n",
    "del model_b013\n",
    "Y_pred = Y_pred/ensemble_count\n",
    "  \n",
    "data_b3 = df_in_time['toa_b3'].values + Y_pred\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "hep.cms.text(loc=0, ax=ax, text=\"Preliminary\", fontsize=25)\n",
    "ax.set_title(f'Board 1 Time Walk Correction NN', loc=\"right\", size=25)\n",
    "ax.scatter(df_in_time['tot_b3'].values,  ((df_in_time['toa_b0']+df_in_time['toa_b1']).values/2.) - df_in_time['toa_b3'].values, label='data')\n",
    "ax.plot(df_in_time['tot_b3'].values, Y_pred, 'r.', label='Neural Network')\n",
    "ax.set_xlabel('TOT time [ns]')\n",
    "ax.set_ylabel(r'$(TOA_{0} + TOA_{1})/2 - TOA_3$ [ns]' )\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_b01_nn = data_b0 - data_b1\n",
    "diff_b03_nn = data_b0 - data_b3\n",
    "diff_b13_nn = data_b1 - data_b3\n",
    "\n",
    "fit_params_NN = []\n",
    "fit_errors_NN = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_hist = hist.Hist(hist.axis.Regular(50, -1, 1, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "time_hist.fill(diff_b01_nn)\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "grid = fig.add_gridspec(2, 1, hspace=0, height_ratios=[3, 1])\n",
    "main_ax = fig.add_subplot(grid[0])\n",
    "subplot_ax = fig.add_subplot(grid[1], sharex=main_ax)\n",
    "plt.setp(main_ax.get_xticklabels(), visible=False)\n",
    "main_ax_artists, sublot_ax_arists = time_hist.plot_pull(\n",
    "    \"normal\",\n",
    "    eb_ecolor=\"steelblue\",\n",
    "    eb_mfc=\"steelblue\",\n",
    "    eb_mec=\"steelblue\",\n",
    "    eb_fmt=\"o\",\n",
    "    eb_ms=6,\n",
    "    eb_capsize=1,\n",
    "    eb_capthick=2,\n",
    "    eb_alpha=0.8,\n",
    "    fp_c=\"hotpink\",\n",
    "    fp_ls=\"-\",\n",
    "    fp_lw=2,\n",
    "    fp_alpha=0.8,\n",
    "    bar_fc=\"royalblue\",\n",
    "    pp_num=3,\n",
    "    pp_fc=\"royalblue\",\n",
    "    pp_alpha=0.618,\n",
    "    pp_ec=None,\n",
    "    ub_alpha=0.2,\n",
    "    fit_fmt= r\"{name} = {value:.4g} $\\pm$ {error:.4g}\",\n",
    "    ax_dict= {\"main_ax\":main_ax,\"pull_ax\":subplot_ax},\n",
    ")\n",
    "hep.cms.text(loc=0, ax=main_ax, text=\"Preliminary\", fontsize=25)\n",
    "main_ax.set_title(f'Board 0 - Board 1', loc=\"right\", size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params_NN.append([741.1, -0.325, 0.1123])\n",
    "fit_errors_NN.append([12.85, 0.00156, 0.001173])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_hist = hist.Hist(hist.axis.Regular(50, -1, 1, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "time_hist.fill(diff_b03_nn)\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "grid = fig.add_gridspec(2, 1, hspace=0, height_ratios=[3, 1])\n",
    "main_ax = fig.add_subplot(grid[0])\n",
    "subplot_ax = fig.add_subplot(grid[1], sharex=main_ax)\n",
    "plt.setp(main_ax.get_xticklabels(), visible=False)\n",
    "main_ax_artists, sublot_ax_arists = time_hist.plot_pull(\n",
    "    \"normal\",\n",
    "    eb_ecolor=\"steelblue\",\n",
    "    eb_mfc=\"steelblue\",\n",
    "    eb_mec=\"steelblue\",\n",
    "    eb_fmt=\"o\",\n",
    "    eb_ms=6,\n",
    "    eb_capsize=1,\n",
    "    eb_capthick=2,\n",
    "    eb_alpha=0.8,\n",
    "    fp_c=\"hotpink\",\n",
    "    fp_ls=\"-\",\n",
    "    fp_lw=2,\n",
    "    fp_alpha=0.8,\n",
    "    bar_fc=\"royalblue\",\n",
    "    pp_num=3,\n",
    "    pp_fc=\"royalblue\",\n",
    "    pp_alpha=0.618,\n",
    "    pp_ec=None,\n",
    "    ub_alpha=0.2,\n",
    "    fit_fmt= r\"{name} = {value:.4g} $\\pm$ {error:.4g}\",\n",
    "    ax_dict= {\"main_ax\":main_ax,\"pull_ax\":subplot_ax},\n",
    ")\n",
    "hep.cms.text(loc=0, ax=main_ax, text=\"Preliminary\", fontsize=25)\n",
    "main_ax.set_title(f'Board 0 - Board 3', loc=\"right\", size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params_NN.append([831.9, -0.3442, 0.09955])\n",
    "fit_errors_NN.append([14.53, 0.001384, 0.001056])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_hist = hist.Hist(hist.axis.Regular(50, -1, 1, name=\"TWC_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "time_hist.fill(diff_b13_nn)\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "grid = fig.add_gridspec(2, 1, hspace=0, height_ratios=[3, 1])\n",
    "main_ax = fig.add_subplot(grid[0])\n",
    "subplot_ax = fig.add_subplot(grid[1], sharex=main_ax)\n",
    "plt.setp(main_ax.get_xticklabels(), visible=False)\n",
    "main_ax_artists, sublot_ax_arists = time_hist.plot_pull(\n",
    "    \"normal\",\n",
    "    eb_ecolor=\"steelblue\",\n",
    "    eb_mfc=\"steelblue\",\n",
    "    eb_mec=\"steelblue\",\n",
    "    eb_fmt=\"o\",\n",
    "    eb_ms=6,\n",
    "    eb_capsize=1,\n",
    "    eb_capthick=2,\n",
    "    eb_alpha=0.8,\n",
    "    fp_c=\"hotpink\",\n",
    "    fp_ls=\"-\",\n",
    "    fp_lw=2,\n",
    "    fp_alpha=0.8,\n",
    "    bar_fc=\"royalblue\",\n",
    "    pp_num=3,\n",
    "    pp_fc=\"royalblue\",\n",
    "    pp_alpha=0.618,\n",
    "    pp_ec=None,\n",
    "    ub_alpha=0.2,\n",
    "    fit_fmt= r\"{name} = {value:.4g} $\\pm$ {error:.4g}\",\n",
    "    ax_dict= {\"main_ax\":main_ax,\"pull_ax\":subplot_ax},\n",
    ")\n",
    "hep.cms.text(loc=0, ax=main_ax, text=\"Preliminary\", fontsize=25)\n",
    "main_ax.set_title(f'Board 1 - Board 3', loc=\"right\", size=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_params_NN.append([899.9, -0.01758, 0.09358])\n",
    "fit_errors_NN.append([15.36, 0.001289, 0.0009443])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_b3,err_b3 = return_resolution_ps(fit_params_NN[1][2], fit_errors_NN[1][2], \n",
    "                                     fit_params_NN[2][2], fit_errors_NN[2][2], \n",
    "                                     fit_params_NN[0][2], fit_errors_NN[0][2])\n",
    "print(res_b3,err_b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_b1,err_b1 = return_resolution_ps(fit_params_NN[0][2], fit_errors_NN[0][2], \n",
    "                                     fit_params_NN[2][2], fit_errors_NN[2][2], \n",
    "                                     fit_params_NN[1][2], fit_errors_NN[1][2])\n",
    "print(res_b1,err_b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_b0,err_b0 = return_resolution_ps(fit_params_NN[0][2], fit_errors_NN[0][2], \n",
    "                                     fit_params_NN[1][2], fit_errors_NN[1][2], \n",
    "                                     fit_params_NN[2][2], fit_errors_NN[2][2])\n",
    "print(res_b0,err_b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del diff_b01_nn,diff_b03_nn,diff_b13_nn,data_b3,data_b1,data_b0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
