{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import beamtest_analysis_helper as helper\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chip_labels = [0, 1, 2, 3]\n",
    "chip_names = [\"ET2_EPIR_Pair1\", \"ET2_BAR_4\", \"ET2_BAR_6\", \"ET2_CNM_1-3\"]\n",
    "offsets = [15, 5, 15, 5]\n",
    "high_voltages = [260, 260, 260, 200]\n",
    "board_to_analyze = [0,1,2]\n",
    "ignore_boards = [3]\n",
    "\n",
    "run_name = \"run13\"\n",
    "\n",
    "chip_fignames = chip_names\n",
    "chip_figtitles = [\n",
    "    f\"(Trigger) EPIR Pair1 HV{high_voltages[0]}V OS:{offsets[0]}\",\n",
    "    f\"(DUT1) Barcelona 4 HV{high_voltages[1]}V OS:{offsets[1]}\",\n",
    "    f\"(Reference) Barcelona 6 HV{high_voltages[2]}V OS:{offsets[2]}\",\n",
    "    f\"(DUT2) CNM (HPK Sensor) 1-3 HV{high_voltages[3]}V OS:{offsets[3]}\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_df = pd.read_csv(f\"./{run_name}_good_track_candidates.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering data based on track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob(f'./desy_TB_{run_name}/*.feather')\n",
    "\n",
    "last_evt = 0\n",
    "dataframes = []\n",
    "last_idx = -1\n",
    "tmp_df = None\n",
    "min_file_count = 8\n",
    "track_pivots = {i:[] for i in range(len(track_df))}\n",
    "\n",
    "for idx, ifile in enumerate(tqdm(files)):\n",
    "\n",
    "    ## Skip all files once they've already been accomodated in a previous batch\n",
    "    if(last_idx==-2):\n",
    "        continue\n",
    "\n",
    "    ## load file and alter evt\n",
    "    run_df = pd.read_feather(ifile)\n",
    "    run_df.drop(columns=['evt_number', 'bcid', 'l1a_counter', 'ea'], inplace=True)\n",
    "\n",
    "    if idx > 0:\n",
    "        run_df['evt'] += last_evt\n",
    "    last_evt += run_df['evt'].unique()[-1]\n",
    "\n",
    "    ## Check if this is the first file of the batch\n",
    "    if last_idx == -1:\n",
    "        tmp_df = run_df.copy()\n",
    "        last_idx = idx\n",
    "        continue\n",
    "\n",
    "    ## Check if the current file falls into the current batch but doesn't complete it\n",
    "    elif idx-last_idx+1<min_file_count:\n",
    "        tmp_df = pd.concat([tmp_df, run_df])\n",
    "        continue\n",
    "\n",
    "    ## Check if the current file completes the current batch and pass the batch on\n",
    "    else:\n",
    "        tmp_df = pd.concat([tmp_df, run_df])\n",
    "        last_idx = idx\n",
    "\n",
    "        ## Check if there are files that don't complete a batch leftover after this file\n",
    "        if((len(files)-last_idx-1<min_file_count)and(len(files)-last_idx-1>0)):\n",
    "            for idx_inner, innerfile in enumerate(files):\n",
    "                if(idx_inner<=last_idx): continue\n",
    "                run_df = pd.read_feather(innerfile)\n",
    "                run_df.drop(columns=['evt_number', 'bcid', 'l1a_counter', 'ea'], inplace=True)\n",
    "                if idx_inner > 0:\n",
    "                    run_df['evt'] += last_evt\n",
    "                last_evt += run_df['evt'].unique()[-1]\n",
    "                tmp_df = pd.concat([tmp_df, run_df])\n",
    "\n",
    "            ## Flag to skip all these files that have already been taken into account\n",
    "            last_idx = -2\n",
    "            print(\"Working on an extended batch of files\")\n",
    "\n",
    "        ## Completed a batch nominally and now passing it on\n",
    "        else:\n",
    "            last_idx = -1\n",
    "            print(f\"Working on a clean batch of {min_file_count} files\")\n",
    "\n",
    "    ## Restrict to events with only one hit on the boards of interest\n",
    "    tmp_df = helper.singlehit_event_clear(tmp_df, ignore_boards=ignore_boards)\n",
    "\n",
    "    for i in tqdm(range(len(track_df))):\n",
    "\n",
    "        ## Filter only the pixels of interest, dropping other hits on the boards of interest as well as boards not of interest\n",
    "        pix_dict = {}\n",
    "\n",
    "        for idx in board_to_analyze:\n",
    "            pix_dict[idx] = [track_df.iloc[i][f'row_{idx}'], track_df.iloc[i][f'col_{idx}']]\n",
    "\n",
    "        track_tmp_df = helper.pixel_filter(tmp_df, pix_dict)\n",
    "\n",
    "        ## Selecting good hits with TDC cuts\n",
    "        tdc_cuts = {}\n",
    "        for idx in board_to_analyze:\n",
    "            # board ID: [CAL LB, CAL UB, TOA LB, TOA UB, TOT LB, TOT UB]\n",
    "            if idx == 0:\n",
    "                tdc_cuts[idx] = [track_tmp_df.loc[track_tmp_df['board'] == idx]['cal'].mode()[0]-3, track_tmp_df.loc[track_tmp_df['board'] == idx]['cal'].mode()[0]+3,  100, 500, 0, 600]\n",
    "            else:\n",
    "                tdc_cuts[idx] = [track_tmp_df.loc[track_tmp_df['board'] == idx]['cal'].mode()[0]-3, track_tmp_df.loc[track_tmp_df['board'] == idx]['cal'].mode()[0]+3,  0, 1100, 0, 600]\n",
    "        track_tmp_df = helper.tdc_event_selection(track_tmp_df, tdc_cuts_dict=tdc_cuts)\n",
    "\n",
    "        ## Restrict to events with only one hit on the boards of interest, needed again as we may have dropped hits\n",
    "        track_tmp_df = helper.singlehit_event_clear(track_tmp_df, ignore_boards=ignore_boards)\n",
    "\n",
    "        ## Pivot Table to make tracks\n",
    "        pivot_table = track_tmp_df.pivot(index=[\"evt\"], columns=[\"board\"], values=[\"row\", \"col\", \"toa\", \"tot\", \"cal\"])\n",
    "        track_pivots[i].append(pivot_table)\n",
    "\n",
    "    del tmp_df, track_tmp_df, pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_pivots_concat = { i: pd.concat(track_pivots[i]) for i in range(len(track_df)) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_list = []\n",
    "table_dir = Path(f\"./{run_name}_track_pivot_tables/\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "for key,val in tqdm(track_pivots_concat.items()):\n",
    "    len_list += [len(val)]\n",
    "    val.reset_index(drop=True,inplace=True)\n",
    "    val.to_csv(f\"./{run_name}_track_pivot_tables/track_{key}.csv\",index=False)\n",
    "\n",
    "print(np.amax(len_list), np.amin(len_list))\n",
    "del len_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Bootstrapping!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = {}\n",
    "\n",
    "for idx in board_to_analyze:\n",
    "    final_dict[f'row{idx}'] = []\n",
    "    final_dict[f'col{idx}'] = []\n",
    "    final_dict[f'res{idx}'] = []\n",
    "    final_dict[f'err{idx}'] = []\n",
    "\n",
    "for ikey, itable in tqdm(track_pivots_concat.items()):\n",
    "\n",
    "    sum_arr = {}\n",
    "    sum_square_arr = {}\n",
    "    iteration = 100\n",
    "    sampling_fraction = 0.75\n",
    "    counter = 0\n",
    "\n",
    "    for idx in board_to_analyze:\n",
    "        sum_arr[idx] = 0\n",
    "        sum_square_arr[idx] = 0\n",
    "\n",
    "    for iloop in tqdm(range(iteration)):\n",
    "\n",
    "        tdc_filtered_df = itable.reset_index()\n",
    "\n",
    "        n = int(sampling_fraction*tdc_filtered_df.shape[0])\n",
    "        indices = np.random.choice(tdc_filtered_df['evt'].unique(), n, replace=False)\n",
    "        tdc_filtered_df = tdc_filtered_df.loc[tdc_filtered_df['evt'].isin(indices)]\n",
    "\n",
    "        if tdc_filtered_df.shape[0] < iteration/(3.*(1-sampling_fraction)):\n",
    "            print('Warning!! Sampling size is too small. Skipping this track')\n",
    "            break\n",
    "\n",
    "        d = {\n",
    "            'evt': tdc_filtered_df['evt'].unique(),\n",
    "        }\n",
    "\n",
    "        for idx in board_to_analyze:\n",
    "            bins = 3.125/tdc_filtered_df['cal'][idx].mean()\n",
    "            d[f'toa_b{str(idx)}'] = 12.5 - tdc_filtered_df['toa'][idx] * bins\n",
    "            d[f'tot_b{str(idx)}'] = (2*tdc_filtered_df['tot'][idx] - np.floor(tdc_filtered_df['tot'][idx]/32)) * bins\n",
    "\n",
    "        df_in_time = pd.DataFrame(data=d)\n",
    "        del d, tdc_filtered_df\n",
    "\n",
    "        corr_toas = helper.three_board_iterative_timewalk_correction(df_in_time, 5, 3, board_list=board_to_analyze)\n",
    "\n",
    "        diffs = {}\n",
    "        for board_a in board_to_analyze:\n",
    "            for board_b in board_to_analyze:\n",
    "                if board_b <= board_a:\n",
    "                    continue\n",
    "                name = f\"{board_a}{board_b}\"\n",
    "                diffs[name] = np.asarray(corr_toas[f'toa_b{board_a}'] - corr_toas[f'toa_b{board_b}'])\n",
    "\n",
    "        hists = {}\n",
    "        for key in diffs.keys():\n",
    "            hists[key] = hist.Hist(hist.axis.Regular(80, -1.2, 1.2, name=\"TWC_delta_TOA\", label=r'Time Walk Corrected $\\Delta$TOA [ns]'))\n",
    "            hists[key].fill(diffs[key])\n",
    "\n",
    "        try:\n",
    "            fit_params_lmfit = {}\n",
    "            for key in hists.keys():\n",
    "                params = helper.lmfit_gaussfit_with_pulls(diffs[key], hists[key], std_range_cut=0.4, width_factor=1.25, fig_title='',\n",
    "                                                    use_pred_uncert=True, no_show_fit=False, no_draw=True, get_chisqure=False)\n",
    "                fit_params_lmfit[key] = params\n",
    "            del params, hists, diffs, corr_toas\n",
    "\n",
    "            resolutions = helper.return_resolution_three_board(fit_params_lmfit, var=list(fit_params_lmfit.keys()), board_list=board_to_analyze)\n",
    "\n",
    "            if any(np.isnan(val) for key, val in resolutions.items()):\n",
    "                print('fit results is not good, skipping this iteration')\n",
    "                continue\n",
    "\n",
    "            for key in resolutions.keys():\n",
    "                sum_arr[key] += resolutions[key]\n",
    "                sum_square_arr[key] += resolutions[key]**2\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "        except:\n",
    "            print('Failed, skipping')\n",
    "            del hists, diffs, corr_toas\n",
    "\n",
    "    if counter != 0:\n",
    "        for idx in board_to_analyze:\n",
    "            final_dict[f'row{idx}'].append(itable['row'][idx].unique()[0])\n",
    "            final_dict[f'col{idx}'].append(itable['col'][idx].unique()[0])\n",
    "\n",
    "        for key in sum_arr.keys():\n",
    "            mean = sum_arr[key]/counter\n",
    "            std = np.sqrt((1/(counter-1))*(sum_square_arr[key]-counter*(mean**2)))\n",
    "            final_dict[f'res{key}'].append(mean)\n",
    "            final_dict[f'err{key}'].append(std)\n",
    "    else:\n",
    "        print('Track is not validate for bootstrapping')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(final_dict)\n",
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_tag = \"_trigTOA100_500_oneHitTrigDut1Ref\"\n",
    "final_df.to_csv(f'./{run_name}{csv_tag}_resolutions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draw final resolution plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_resolution_with_pulls(final_df, chipLabels=board_to_analyze, fig_title=chip_figtitles, fig_tag=\"\", hist_bins=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot_resolution_table(final_df, chipLabels=board_to_analyze, fig_title=chip_figtitles, fig_tag=\"\", slides_friendly=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "packages",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
